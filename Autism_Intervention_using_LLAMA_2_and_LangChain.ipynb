{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Somya000/Data-Science/blob/main/Autism_Intervention_using_LLAMA_2_and_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCkAeGAE-ZoD"
      },
      "source": [
        "# **Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MvweCetv9cTB",
        "outputId": "75421ed7-82f8-466d-caa7-5d4d26672dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zyo_7ltveHFE",
        "outputId": "5991ccb9-9552-442c-e9a9-be97840b02ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.41-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.6-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core==0.10.41 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.41-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.21-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading openai-1.30.5-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (8.3.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (4.11.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.41->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.41->llama-index) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.41->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.41->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.41->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.41->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.41->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.41->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.41->llama-index) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.41->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.41->llama-index) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.41->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.41->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.41->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.41->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.41->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.41->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.41->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.41->llama-index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.41->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.41->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.41->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.41->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.41->llama-index)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.41->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.41->llama-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.41->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.41->llama-index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.41->llama-index) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.41->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.41->llama-index) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.41->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, dirtyjson, pypdf, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed dataclasses-json-0.6.6 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-0.10.41 llama-index-agent-openai-0.2.6 llama-index-cli-0.1.12 llama-index-core-0.10.41 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.21 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.4 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.30.5 pypdf-4.2.0 striprtf-0.0.26 tiktoken-0.7.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-llms-huggingface\n",
            "  Downloading llama_index_llms_huggingface-0.2.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.1)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.41 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.10.41)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers[torch]<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.11.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.30.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.14.1)\n",
            "Requirement already satisfied: pydantic<3,>2 in /usr/local/lib/python3.10/dist-packages (from text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.3)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.30.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.21.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.16.0)\n",
            "Installing collected packages: text-generation, llama-index-llms-huggingface\n",
            "Successfully installed llama-index-llms-huggingface-0.2.2 text-generation-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index\n",
        "%pip install llama-index-llms-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wkd_QUiPbjYb",
        "outputId": "ce1ccbc2-719f-4d3f-f57e-b146c396132f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: install in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "## Embedding:\n",
        "!pip install install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "yGhvYwYTbcbq"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "__GKNWmdOaKK",
        "outputId": "15fbaaf3-3e31-4c8b-f1e5-984426fd38e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Installing collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.5 PyMuPDFb-1.24.3\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZPatxW9b9Ee"
      },
      "source": [
        "**Data Preprocessing and Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9hB_KysncPUW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJBLzpLhfA-P"
      },
      "source": [
        "**Extract Text from PDFs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uZDkOOYffAHN"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file using PyMuPDF (fitz).\"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc.load_page(page_num)\n",
        "            text += page.get_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to read {pdf_path}: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "drb0UEw6fPgN"
      },
      "outputs": [],
      "source": [
        "#Function to remove References\n",
        "def remove_references(text):\n",
        "    \"\"\"Remove references from the text by identifying the 'References' section.\"\"\"\n",
        "    # Pattern to identify the start of the references section\n",
        "    references_patterns = [\n",
        "        r'\\bReferences\\b',\n",
        "        r'\\bBibliography\\b',\n",
        "        r'\\bWorks Cited\\b',\n",
        "        r'\\bCitations\\b',\n",
        "    ]\n",
        "    for pattern in references_patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            text = text[:match.start()]\n",
        "            break\n",
        "    return text\n",
        "\n",
        "\n",
        "# Function to remove figures,tables and in-text citations\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove figure and table captions and related text from the text.\n",
        "    \"\"\"\n",
        "    # Regular expression to find figure captions\n",
        "    text = re.sub(r'Figure \\d+:.*?(?=\\n\\n|\\Z)', '', text, flags=re.DOTALL)\n",
        "    # Regular expression to find table captions\n",
        "    text = re.sub(r'Table \\d+:.*?(?=\\n\\n|\\Z)', '', text, flags=re.DOTALL)\n",
        "\n",
        "    \"\"\"\n",
        "    Remove in-text citations from the text.\n",
        "    \"\"\"\n",
        "    # Regular expression to find in-text citations, e.g., (Author, Year) or [1]\n",
        "    text = re.sub(r'\\(.*?\\)', '', text)  # Removes citations like (Author, Year)\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)  # Removes citations like [1], [2], etc.\n",
        "    return (text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "drxoL4LBhRVO"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess the text by tokenizing, removing stopwords, and applying lemmatization and stemming.\"\"\"\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Convert to lower case\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Remove punctuation\n",
        "    tokens = [token for token in tokens if token not in string.punctuation]\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Lemmatize tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Stem tokens (optional, often not used with lemmatization)\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dbTvbA3hdpz"
      },
      "source": [
        " **Main Function to Process Files in Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PfPMt8D9hcF4",
        "outputId": "b1470939-c703-4d2e-d475-8e3f1f2e7b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/drive/MyDrive/Autism already exists.\n",
            "Reading /content/drive/MyDrive/dataset/zhao2020.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/zhao2020_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Young_Behavior.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Young_Behavior_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Tariq2018.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Tariq2018_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Qiu.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Qiu_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Tariq_2019.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Tariq_2019_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Patten_Audio.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Patten_Audio_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Asd_Cry_patterns.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Asd_Cry_patterns_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Abbas_2018.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Abbas_2018_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/22_Ouss_ASD.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/22_Ouss_ASD_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Abbas_2020.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Abbas_2020_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/Dawson.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/Dawson_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/LEE.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/LEE_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/1_Ramırez-Duque_.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/1_Ramırez-Duque__cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/15_Nazneen.pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/15_Nazneen_cleaned.txt\n",
            "Reading /content/drive/MyDrive/dataset/carpenter2020 (1).pdf...\n",
            "Preprocessed text written to /content/drive/MyDrive/Autism/carpenter2020 (1)_cleaned.txt\n",
            "All files have been processed.\n"
          ]
        }
      ],
      "source": [
        "# Ensure you have downloaded the necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def process_files_in_directory(input_directory, output_directory):\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "        print(f\"Directory {output_directory} created.\")\n",
        "    else:\n",
        "        print(f\"Directory {output_directory} already exists.\")\n",
        "\n",
        "    # List all PDF files in the input directory\n",
        "    pdf_files = [file for file in os.listdir(input_directory) if file.endswith('.pdf')]\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(input_directory, pdf_file)\n",
        "        print(f\"Reading {pdf_path}...\")\n",
        "\n",
        "        # Extract text from the PDF\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        if text is None:\n",
        "            continue\n",
        "\n",
        "        # Remove references from the text\n",
        "        text_without_references = remove_references(text)\n",
        "\n",
        "        # Clean the text\n",
        "        cleaned_text = clean_text(text_without_references)\n",
        "\n",
        "        # Preprocess the text\n",
        "        preprocessed_text = preprocess_text(cleaned_text)\n",
        "\n",
        "        # Define the path for the cleaned text file\n",
        "        clean_file_path = os.path.join(output_directory, os.path.splitext(pdf_file)[0] + '_cleaned.txt')\n",
        "\n",
        "        # Write the cleaned text to the new file\n",
        "        with open(clean_file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(preprocessed_text)\n",
        "            print(f\"Preprocessed text written to {clean_file_path}\")\n",
        "\n",
        "    print(\"All files have been processed.\")\n",
        "\n",
        "\n",
        "input_directory = '/content/drive/MyDrive/dataset'  # Replace with your input directory path\n",
        "output_directory = '/content/drive/MyDrive/Autism'  # Replace with your output directory path\n",
        "\n",
        "process_files_in_directory(input_directory, output_directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj2uY6Nzxl-F"
      },
      "source": [
        "**Reading Clean File for Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "CO3GR8LBl1Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47098712-acf1-4122-bfd4-2baaf7b66244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 15 documents.\n"
          ]
        }
      ],
      "source": [
        "documents= SimpleDirectoryReader(\"/content/drive/MyDrive/Autism\").load_data()\n",
        "print(f\"Loaded {len(documents)} documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NBWAauIfmq0L",
        "outputId": "4624eec8-c4dc-407d-be68-1dcaa955e4e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id_='602aca2e-2b9d-4952-9625-f18713c06082', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/15_Nazneen_cleaned.txt', 'file_name': '15_Nazneen_cleaned.txt', 'file_type': 'text/plain', 'file_size': 0, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d51f3dde-190b-4c22-89f1-cfd7b38ff62b', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/1_Ramırez-Duque__cleaned.txt', 'file_name': '1_Ramırez-Duque__cleaned.txt', 'file_type': 'text/plain', 'file_size': 30917, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='http //doi.org/10.1007/s10846-018-00975-i robot-assist autism spectrum disord diagnost base artiﬁci reason andr´ e a. ram´ ırez-duque1 · anselmo frizera-neto1 · teodiano freir bastos1 receiv 25 april 2018 accept 20 decemb 2018 © springer natur b.v. 2019 abstract autism spectrum disord neurodevelopment disord affect peopl birth whose symptom found earli development period asd diagnosi usual perform sever session behavior observ exhaust screen manual code behavior earli detect asd sign naturalist behavior observ may improv child-robot interact technological-bas tool autom behavior assess robot-assist tool use cri theori interest intervent child autism spectrum disord elucid faster signific gain diagnosi therapeut intervent compar classic method addit use comput vision analyz child ’ behavior autom video code summar respons would help clinician reduc delay asd diagnosi articl cri enhanc tradit tool asd diagnosi propos system reli comput vision unstructur scalabl network rgbd sensor built upon robot oper system machin learn algorithm autom face analysi also proof concept present particip three typic develop child three child risk suffer asd keyword child-robot interact · autism spectrum disord · convolut neural network · robot reason model · statist shape model 1 introduct research child-robot interact aim provid necessari condit interact child robot devic take account fundament featur child ’ neurophys physic condit child ’ mental health robot-assist therapi use cri theori interest intervent cwasd elucid faster signific gain therapeut intervent compar tradit therapi 2–4 asd neurodevelopment disord affect peopl birth symptom found earli \\x02 andr´ e a. ram´ ırez-duqu aaramirezd gmail.com 1 universidad feder espir´ ıto santo. av fernando ferrari 514 vitoria brazil development period individu suffer asd exhibit persist deficit social commun social interact repetit pattern behavior interest activ asd sign may observ age 10 month although reliabl diagnosi perform 18 month age accord 24 month accord use comput vision analyz child ’ behavior autom video code summar intervent help clinician reduc delay asd diagnosi provid cwasd access earli therapeut intervent addit cri-bas intervent transform tradit diagnosi method robot devic systemat elicit child ’ behavior exhibit asd sign first system develop assist asd therapist make diagnosi base robot devic primarili open loop remot oper sys- tem howev approach unabl perform autonom feedback enhanc interact 9–11 journal intellig robot system 96:267–281 publish onlin 29 2019 march content courtesi springer natur term use appli right reserv nevertheless differ system abl modifi behavior robot accord environment interac- tion child ’ respons use closed-loop artifici cognit approach 12–16 system hypothes offer technolog mechan support flexibl potenti naturalist interact fact literatur report automat robot ’ social behavior modul accord specif scenario strong effect child ’ social behavior howev despit increas posit evid technolog rare appli specif asd diagnosi work aim present robot-assist framework use artifici reason modul assist clinician asd diagnost process framework compos respons robot platform flexibl scalabl vision sensor network autom face analysi algorithm base machin learn model research take advantag neural model avail open sourc project build complet new pipelin algorithm global recognit track child ’ face among mani face present typic unstructur clinic intervent order estim child ’ visual focu attent along time propos system use differ behavior analysi scenario typic asd diagnost process order illustr feasibl propos system paper experiment trial ass joint- attent behavior present employ in-clin setup main contribut paper develop new artifici reason modul upon flexibl scalabl ros-bas vision system use state-of-the-art machin learn neural model propos implement supervis cri child- robot interact base open sourc social robot platform enhanc tradit tool asd diagnosi use in-clin setup protocol best knowledg open sourc project avail face analysi base multi-camera approach use ro characterist describ research 2 relat work recent research shown accept effici technolog use auxiliari tool therapi teach individu asd 18–21 technolog may also use peopl surround asd individu exampl use artifici vision system measur analyz child ’ behavior lead altern screen monitor tool help clinician get feedback effect intervent addit social robot great potenti aid diagnosi therapi child asd 18 23 higher degre control predict simplic may achiev interact robot impact directli frustrat reduc anxieti individu respect use comput vision techniqu previou studi alreadi analyz child ’ behavior visual attent eye gaze eye contact smile event visual explor use camera eye tracker 25 26 rgbd camera 27 28 studi shown potenti vision system improv behavior code asd therapi howev studi implement techniqu cri enhanc intervent hand studi cwasd respond robot mediat compar human mediat report intervent scenario imit game 29 30 tell stori free play task 12 31 work use featur proxem bodi gestur visual contact eye gaze behavior descriptor wherea behavior analysi estim use manual video code research vanderbilt univers publish seri research show experiment protocol ass joint attent task defin capac coordin orient two peopl toward object event protocol consist direct attent child toward object locat room adapt prompt bekel et al infer particip ’ eye gaze head pose calcul real-tim ir camera array last work zheng et al warren et al use commerci eye tracker estim child ’ eye gaze around robot manual behavior code global evalu 10 33 howev eye tracker devic requir pre-calibr may limit movement individu result work show robot attract child ’ attent cwasd reach ja task nevertheless develop ja task difficult robot human anzalon et al develop cri scenario use nao robot perform ja task author use rgbd camera estim bodi head movement result show ja perform child asd similar perform td child interact human mediat howev robot mediat child asd present lower perform td child i.e child asd need social cue final task chevali et al analyz studi featur propriocept visual integr cwasd use rgbd sensor record intervent session manual behavior code analyz particip ’ perform none previou work closed-loop subsystem j intel robot syst 96:267–281 268 content courtesi springer natur term use appli right reserv implement provid level artifici cognit enabl autom robot behavior contrast aforement research work implement autom face analysi artifici cognit robot-medi comput vision analyz child ’ engag 36 37 emot recognit capabl 13 15 38 child ’ intent 14 16 work two differ strategi implement common base mono- camera approach use extern rgb rgbd sensor 15 36 37 use on-board rgb camera mount robotic-platform 13 16 strategi base highli structur environ compos extern camera plu on-board camera network vision sensor attach small tabl strategi base multi-camera method improv system ’ perform remain constrain relat desir featur flexibl scalabl modular thu despit potenti techniqu shown achiev autom child ’ behavior analysi naturalist way unstructur clinical-setup robot interact accordingli remain challeng cri 3 system architectur overview ro system use work flexibl scalabl open framework write modular robot- center system similar comput oper system ro manag interfac robot hardwar softwar modul provid common devic driver data structur tool-bas packag visual debug tool addit ro us interfac definit languag describ messag sent process node featur facilit multi- languag develop overal system develop built use node graph architectur take advantag princip ro design criterion ro system consist number node local video process togeth robot ’ behavior estim distribut around number differ host connect runtim peer-to- peer topolog inter-nod connect implement hand-shak occur xml-rpc protocol along web-socket commun robot ’ web- base node node structur flexibl scalabl dynam modifi i.e. node start left run along experiment session resum connect runtim addit gener perspect robot platform web-socket commun integr develop system compos two interconnect modul shown fig 1 artifici reason modul cri-channel modul modul architectur detail follow subsect 3.1 architectur reason modul modul distribut architectur local video process implement data rgbd sensor multi-camera system process two node first driver level node second process node driver1 node transform stream data rgbd sensor ro messag format driver address data special transport provid pluge publish imag compress represent receptor node see sensor msgs/imag messag data process node execut face analysi algorithm node us imag transport subscrib ro packag call cvbridg turn data imag format support typic comput vision algorithm later node publish head pose eye gaze direct mean ro navig messag defin nav msgs/odometri addit node host power workstat carri data fusion navig messag gener local process stage addit fusion node comput visual focu attent publish std msgs/header time stamp target name vfoa estim regist 3.2 architectur cri-channel system propos two bidirect communi- cation channel robot-devic web-bas applica- tion interact child therapist robot devic interact cwasd execut differ- ent physic action facial express upper limb pose verbal commun thu accord child ’ perform reason modul modifi robot ’ behavior automat gaze shift chang- ing facial express provid sound reward client-sid applic develop allow therapist control regist step intervent proto- col interfac also use supervis control robot ’ behavior offer feedback therapist child ’ perform along intervent app two channel commun interact reason modul first connect us web- socket protocol rosbridg suit packag support interpret ro messag well json-bas command ro second one us ro modul 1tool use kinect one ro http //github com/code-iai/iai kinect2 j intel robot syst 96:267–281 269 content courtesi springer natur term use appli right reserv fig 1 node graph architectur propos ros-bas system system compos two interconnect modul artifici reason modul cri-channel modul ono web server two way bidirect commun websocket standard ro subscrib develop server-sid applic directli run ro node commun standard ro publish subscrib 4 robot platform ono cri implement open sourc platform social robot ,2 promis straightforward system develop face face commun compos low-cost modular robot call ono web-bas applic import requir characterist make ono interest cri strategi explain follow section 4.1 appear ident robot cover foam also fabric invit huggabl appear child robot overs head make facial express promin highlight import communica- tion emot interact consequ size pose child interact robot eye height robot place tabl robot ono predefin ident element previous conceiv name unlik robot well-defin ident probo kaspar work ono ’ ident built particip child co-creat process reason neutral appear initi use 2open sourc platform social robot http //www opsoro.com intervent therapist provid child cloth accessori defin ident ono 4.2 mechan platform initi design ono compos actuat face work need provid ono bodi languag purpos motor arm design implement new design ono fulli face two arm actuat give total 17 degre freedom ono abl perform facial express nonverb cue wave shake hand point toward object move arm eye 2 dof x 2 eyelid eyebrow mouth robot also sound modul allow explicit posit feedback well reinforc learn play word convers sound 4.3 social express order improv social interact child ono abl exhibit differ facial express ono ’ express base facial action code system develop dof compos ono ’ face link set action unit defin fact facial express determin specif au valu facial express repres 2d vector f e emot circumplex model defin valenc arous context basic facial express specifi unit circl neutral express correspond origin space f e0 relat dof posit au valu resolv lookup tabl algorithm use predefin configur file j intel robot syst 96:267–281 270 content courtesi springer natur term use appli right reserv fig 2 ono robot develop open sourc platform social robot 4.4 adapt reproduc applic do-it-yourself concept princip featur ono ’ design facilit dissemin use research area engin health care characterist allow ono build person without special engin knowledg addit possibl replic ono without need high-end compon manufactur machin electron system base raspberri pi single-board comput combin custom opsoro modul circuitri control 32 servo drive speaker touch sensor sensor actuat compat embed commun protocol implement raspberri pi use platform 4.5 control autonomi inform deliv autom reason modul possibl autom ono ’ behavior robot infer interpret child ’ intent react accur action perform thu enabl effici dynam interact ono work autom ono ’ behavior partial implement i.e. framework modifi physic action ono use feedback inform child ’ behavior action suitabl modifi gaze shift toward child specif event chang neutral posit facial express child look toward target provid sound reward also aliv behavior modul implement improv cri consist blink robot ’ eye chang arm among predefin pose also robot manual oper remot control host client- side applic 5 reason modul machin learn method child ’ face analysi autom child ’ face analysi consist monitor nonverb cue head bodi movement head pose eye gaze visual contact visual focu attent work pipelin algorithm implement use machin learn neural model face analysi chosen method develop use state-of-art train neural model avail dlib3 openface4 modif turn neural model attribut ro node class evalu topic callback need run neural model common ro node algorithm propos child ’ face analysi involv face detect recognit segment track landmark detect track head pose eye gaze visual focu attent estim addit architectur propos also implement new method asynchron match fusion local data visual focu attent estim base hidden markov model direct connect cri-channel influenc robot ’ behavior scheme pipelin algorithm shown fig 3 3dlib c++ librari http //dlib.net/ 4a open sourc facial behavior analysi http //github.com/ tadasbaltrusaitis/openfac j intel robot syst 96:267–281 271 content courtesi springer natur term use appli right reserv fig 3 pipelin algorithm autom child ’ face analysi 5.1 child ’ face detect recognit in-clin setup requir differenti child ’ face face detect found scene reason face recognit process also implement work first face detect execut initi face recognit process subsequ initi landmark detect work detect recognit implement use deep learn model describ section detect process convolut neural network base face detector max-margin object detect loss layer use cnn consist first block compos three downsampl layer appli convolut 5x5 filter size 2×2 stride reduc size imag eight time origin size gener featur map 16 dimens later result process one block compos four convolut layer get final output network three first layer last block 5×5 filter size 1x1 stride last layer 1 channel 9×9 filter size valu last channel larg network think found face particular locat convolut block implement two addit layer among convolut layer pointwis linear transform rectifi linear unit appli non-satur activ function f max train dataset use creat model compos 6975 face avail dlib ’ homepage.5 face recognit algorithm use work inspir deep residu model 5http //dlib.net/files/data/dlib face detect dataset-2016-09-30.tar gz residu network model develop et al reformul convolut layer learn residu function f h −x refer layer input x instead learn unreferenc function practic implement previou formul mean insert shortcut connect turn network counterpart residu version cnn model transform face detect 128d vector space imag person close face differ peopl far apart final face classifi child ’ face caregiv ’ face therapist ’ face detect recognit cnn model implement train releas dlib 19.6 5.2 face analysi landmark head pose eye gaze work us techniqu landmark detect head pose eye gaze estim develop baltruˇ saiti et al. name condit local neural field techniqu extens constrain local model algorithm use special local detector patch expert cnlf model consist statist shape model learn data exampl parametr compon linear deform control possibl shape variat non-rigid object approach base clm 49 50 clnf model object appear local fashion i.e featur point appear model describ amount misalign clnf-base landmark detect consist three main part shape model local detector patch expert fit algorithm detail j intel robot syst 96:267–281 272 content courtesi springer natur term use appli right reserv 5.2.1 shape model clnf techniqu us linear model describ non- rigid deform call point distribut model pdm use estim likelihood shape specif class given set featur point import model fit shape recognit shape face n landmark point describ x x1 x2 xn y1 y2 yn z1 z2 zn class describ valid instanc face use pdm repres x ¯ x \\x02q ¯ x mean shape face \\x02 describ princip deform mode shape q repres non-rigid deform paramet ¯ x \\x02 learn automat label data use princip compon analysi probabl densiti distribut instanc shape class express zero mean gaussian covari matrix \\x03 evalu q p n 1 √m |\\x03|exp \\x02 −1 2 \\x03 model defin necessari place 3d pdm imag space follow equat use transform 3d space imag space use weak perspect project xi · r2d · ¯ xi \\x02iq ¯ xi ¯ xi ¯ yi ¯ zi mean valu ith landmark instanc face imag therefor control use paramet vector p w q q repres local non-rigid deform scale term w rotat term control 2 × 3 matrix r2d translat term global paramet use estim head pose refer camera space use orthograph camera project solv perspective-n-point problem respect detect landmark pdm use train two public dataset 51 52 result model 34 non-rigid 6 rigid shape paramet 5.2.2 patch expert patch expert scheme main novelti implement clnf model new local neural field patch expert take advantag non linear relationship pixel valu patch respons map lnf captur two kind spatial characterist pixel similar sparsiti lnf patch expert interpret three layer perceptron sigmoid activ function follow weight sum hidden layer also similar first layer convolut neural network new lnf patch expert abl learn multipl illumin retain accuraci becom import creat landmark detector tracker expect work unseen environ unseen peopl learn infer process develop use gradient-bas optim method help find local optim model paramet faster accu- rate clnf model implement 28 set total lnf patch expert train seven view four scale framework us patch expert specif train recogn eyelid iri pupil order estim eye gaze 5.2.3 fit algorithm new imag video frame fit algorithm clnf-base landmark detect process attempt find valu local global deform model paramet p minim follow function e r n \\x04 i=1 di r weight penal unlik shape depend shape model repres misalign ith landmark imag function paramet p patch expert probabilist point view solut equival maxim posteriori probabl deform model paramet p p \\x05 p li 1 n i=1 \\x06 ∝p n \\x07 i=1 p li ∈ 1 −1 discret random variabl indic whether ith landmark align misalign p prior probabl deform paramet p p probabl landmark align particular pixel locat xi quantifi respons map creat patch therefor last term repres joint probabl patch expert respons map map problem solv use optim strategi design specif clnf fit call non-uniform j intel robot syst 96:267–281 273 content courtesi springer natur term use appli right reserv regular landmark mean shift us two step process first step evalu patch expert around current landmark use gaussian kernel densiti estim second step iter updat model paramet maxim nu-rlm us expect maxim algo- rithm e-step involv evalu posterior probabl candid m-step find paramet updat mean shift vector v. mean shift vector point direct featur point go motion restrict statisti- cal shape model r. interpret lead new updat function argmin \\x06p \\x08 ∥j\\x06p −v∥2 w r ∥p \\x06p∥2 ˜ \\x03−1 r regular term j jacobian describ landmark locat chang base infinitesim chang paramet p ˜ \\x03−1 diag 0 0 0 0 0 0 λ−1 1 ... λ−1 w allow weight mean-shift vector non-linear least squar lead follow updat rule \\x06p − j wj r\\x03−1 r\\x03−1p −j wv construct w perform patch expert train data use 5.3 data fusion fusion local result head pose estim done appli consensu rotat algorithm algorithm consist calcul weight averag pose camera estim immedi sensor ’ estim neighbor use axis- angl represent local pose penal two weight align confid landmark detect procedur mahalanobi distanc head pose neutral pose 5.4 field view visual focu attent vfoa estim model implement dynam bayesian network hidden markov model model assum specif set child ’ attent attractor target f. estim process decod sequenc child ’ head pose ht h yaw h pitch ∈r2 term vfoa state ft ∈f time probabl distribut head pose refer given vfoa target repres gaussian distribut wherea transit among target repres transit matrix hmm equat written follow p ht ft f μh n ht| μh \\x07h p ft f ft−1 ˆ f af ˆ f gaussian covari defin manual reflect target size head pose estim variabl moreov gaussian mean correspond specif target μh calcul gaze model set paramet fix linear combin target direct head refer direct μh α ⋆μt ⋆rt ⋆denot compon wise product 12 α adjust constant describ fraction gaze shift correspond child ’ head rotat μt ∈k direct given k target rt ∈ r2 repres refer direct averag head pose time window w r. assumpt describ bodi orient behavior child tend orient himself/herself toward set gaze target make comfort rotat his/her head toward differ target rt 1 w r \\x04 i=t−w r hi final estim vfoa sequenc classic viterbi algorithm hmm implement 6 case studi case studi vision system compos three kinect v2 sensor sensor connect workstat equip processor intel core i5 famili geforc gtx gpu board two workstat gtx960 board one workstat gtx580 board workstat connect local area network synchron use ntp protocol.6 sensor intrins extrins calibr convent calibr process use standard black- white chessboard.7 6.1 in-clin setup multidisciplinari team psychologist doctor engin develop case studi use psycholog room equip unidirect mirror perform behavior 6network time protocol homepag http //www.ntp.org 7tool use kinect one ro http //github com/code-iai/iai kinect2 j intel robot syst 96:267–281 274 content courtesi springer natur term use appli right reserv fig 4 represent intervent room in-clin setup observ appropri room prepar tabl three chair one child anoth caregiv third one therapist robot place tabl follow toy helicopt truck train attach room ’ wall rgbd sensor locat close wall addit camera place robot tabl attract child ’ attent represent intervent room in-clin setup shown fig 4 6.2 intervent protocol work technology-bas system use tool variou stage asd diagnost process framework implement extract differ behavior featur assess e.g. eye contact stereotyp movement head concentr excess interest object event howev scope research specif clinic setup intervent ass joint attent behavior present intervent aim evalu capac ja divid three class initi joint attent respond joint attent bid initi request behavior therapist guid intervent time leverag robot devic altern channel commun child specialist robot remain room intervent child accompani throughout session caregiv orient help child execut fig 5 child ’ nonverb cue elicit cri look toward therapist toward robot point self occlus j intel robot syst 96:267–281 275 content courtesi springer natur term use appli right reserv fig 6 perform child ’ face analysi pipelin case studi face detect recognit landmark detect head pose eye gaze estim execut task exercis develop aim direct attent child toward object locat room stimulu look point speak stimulu gener first therapist later robot 6.3 subject three child without confirm asd diagnosi evid risk factor three typic develop child control group particip experi volunt particip parent ’ consent five boy one td girl 36 month 48 month volunt particip one singl session goal analyz based-lin child ’ behavior establish differ behavior reaction td asd child stimulu gener cri leverag novelti effect rais robot mediat 7 result discuss child ’ nonverb cue elicit cri observ fig 5 exampl child ’ behavior tag perform behavior code shown six pictur tag behavior look toward object toward robot toward therapist point respond prompt mediat self occlus typic occlus problem occlus hair hand robot detect perform video process proof concept session report fig 6 case studi session child ’ face detect recognit fig 7 evolut time child ’ head/neck rotat td group j intel robot syst 96:267–281 276 content courtesi springer natur term use appli right reserv fig 8 evolut time child ’ head/neck rotat td volunt vfoa estim result landmark detect head pose eye gaze estim differ viewpoint shown fig 3 recognit process abl detect face session success case child ’ head pose captur throughout session analyz automat estim evolut time child ’ head vfoa along session child ’ neck right/left rotat movement predomin neck flexion/extens neck r/l later flexion movement roll axi remain approxim constant yaw rotat td child group report fig 7 vertic light blue stripe indic intervent period therapist- mediat vertic light green stripe repres period robot-medi continu blue line repres raw data record continu red line describ averag data trend observ three plot td child start intervent look toward robot evid robot naturalist attent attractor subsequ therapist begin protocol explain task child attent shift toward therapist child remain behavior therapist introduc robot- mediat transit child ’ behavior rja ija toward therapist observ therapist chang mediat robot child turn his/her attent robot object room detail analysi one td volunt shown fig 8 plot show overal intervent session plot plot zoom period therapist robot mediat respect color convent three plot fig 8 describ result gener autom estim vfoa scenario essenti aspect alreadi emerg therapist-medi interv child respond ja task use one repetit prompt level child ’ behavior rja accord protocol i.e. child look toward therapist wait instruct rapidli child search target next look toward therapist color sequenc light blue yellow light blue orang light blue red behavior prompt contrast robot-medi child look toward robot among indic consecut target color sequenc light green yellow orang red orang yellow happen protocol mediat execut instruct order j intel robot syst 96:267–281 277 content courtesi springer natur term use appli right reserv fig 9 evolut time child ’ head/neck rotat asd group child memor command object ’ posit robot mediat interv fact affect intervent ’ aim robot mediat succeed elicit child ’ behavior rja ija addit highlight plot fig 8 session final robot mediat said goodby rja ija behavior perceiv pictur show event first child said goodby toward robot look therapist confirm session end look toward robot final child took robot ’ hand analysi three td volunt report behavior perceiv howev analysi child asd group show differ behavior pattern concern comfort visual contact novelti stimulu effect session evolut time child ’ head/neck rotat asd group shown fig 9 one hand three child asd group maintain visual contact robot compar therapist exhibit interest robot platform compar td child howev perform child activ ja improv significantli robot execut prompt hand clinician manifest case first visual contact toward occur instant robot enter scene start interact i.e. ono mediat elicit behavior ija toward therapist addit cwasd exhibit le discomfort regard session first moment robot initi mediat room case show appear verbal non-verb pro-soci behavior fact aris td child first visual contact therapist occur enter room addit td child show abil divid attent robot therapist begin end intervent exhibit comfort everi moment behavior modul cwasd observ fig 9 period robot-medi child exhibit discomfort period head movement tend stabl novelti robot-medi diagnost session analyz addit stimulu cri accordingli case studi child asd group show behavior modif attent comfort produc robot interact begin cri remain end session hand child td group respond novelti effect robot mediat time child enter room saw robot begin therapist present despit novelti j intel robot syst 96:267–281 278 content courtesi springer natur term use appli right reserv stimulu effect seem affect social interact td child therapist contrast stimulu seem enhanc cwasd social interact therapist along intervent result impress sinc show potenti cri intervent systemat elicit differ pattern behavior td asd child identifi rja ija toward therapist begin intervent transit therapist robot mediat end td child contrast identifi ija toward therapist transit mediat asd child fact show clear differ behavior pattern cwasd td child analyz use ja task protocol fact pattern differ use evid improv asd diagnosi 8 conclus work present robot-assist tool assist enhanc tradit practic asd diagnosi design framework combin vision system autom analysi nonverb cue addit robot platform develop upon open sourc project research contribut state-of-the-art innov flexibl scalabl architectur capabl automat regist event joint attent pattern visual contact robot-bas mediat well pattern behavior relat comfort discomfort along asd intervent addit artifici vision pipelin base multi- camera approach propos vision system perform face detect recognit track landmark detect track head pose gaze estim visual focu attent propos perform consid suitabl use convent asd intervent least one camera captur child ’ face sampl frame furthermor feedback inform child ’ perform success use modul supervis behavior ono improv perform cri visual attent child regard vfoa estim algorithm abl estim target fov differ situat recurr also robot abl react accord estim howev algorithm fail occlus child ’ hand gener hand occlus therapist robot compens use multi-camera approach child ’ face recognit system show imper analyz child ’ behavior clinic setup implement work requir caregiv ’ attent room despit limit number child studi preliminari result case studi show feasibl identifi quantifi differ pattern behavior td child cwasd elicit cri intervent proof concept evidenc system abil improv tradit tool use asd diagnosi futur work recommend studi replic protocol propos paper ten cwasd ten td child anoth suggest quantifi kind behavior addit assess paper verbal utter pattern physic emot engag object event prefer gather evid improv assist therapist asd diagnosi process acknowledg work support googl latin america research award program first author scholar- ship support part coordenac ¸˜ ao de aperf ¸oamento de pessoal de n´ ıvel superior brasil financ code 001 disclosur statement potenti conflict interest report author', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1bf59310-e871-42a1-93ef-b038fcde2835', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/22_Ouss_ASD_cleaned.txt', 'file_name': '22_Ouss_ASD_cleaned.txt', 'file_type': 'text/plain', 'file_size': 18329, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ouss et al translat psychiatri 10:54 http //doi.org/10.1038/s41398-020-0743-8 translat psychiatri r c l e p e n c c e behavior interact imag 9 month age predict autism/intellectu disabl high-risk infant west syndrom lisa ouss1 giusepp palestra 2 catherin saint-georges2,3 marluc leitgel gille1 moham afshar4 hugu pellerin2 kevin bailly2 moham chetouani2 laurenc robel1 bernard golse1 rima nabbout5 isabel desguerre5 mariana guergova-kuras4 david cohen 2,3 abstract autom behavior analysi promis tool overcom current assess limit psychiatri 9 month age record 32 infant west syndrom 19 typic develop control standard mother–inf interact comput infant hand movement speech turn take partner motheres assess whether multimod social signal interact synchroni 9 month could predict outcom intellectu disabl infant w 4 year follow-up 10 infant develop asd/id best machin learn reach 76.47 accuraci classifi w vs. td 81.25 accuraci classifi ws+ vs. ws− 10 best featur distinguish ws+ ws−includ combin infant vocal hm featur combin synchroni vocal featur data indic behavior interact imag abl predict asd/ id high-risk child w introduct behavior interact imag promis domain affect comput explor psychiatr conditions1–3 regard child psychiatri mani research attempt identifi reliabl indic neurodevelop- mental disord high-risk popul e.g. sib- ling child autism ﬁrst year life recommend earli interventions4,5 howev social signal alter difﬁcult identifi young age6 addit explor qualiti dynam earli interact complex endeavor usual requir percept integr mul- timod social signal understand two interact partner synchron proceed turn taking7,8 affect comput offer possibl simulta- neousli analyz interact sever partner consid multimod natur dynam social signal behaviors9 date semin studi attempt appli social signal process mother–inf interact without speciﬁc condit studi focus speech turn motherese11 head movements12 hand movements13 movement kinematics2 facial expressions3 focus west syndrom rare epi- leptic encephalopathi earli onset high risk ndd outcom includ one-third w child show later autism spectrum disord and/or intellectu disabl recruit 32 infant w 19 typic develop control particip standard earli mother–inf © author 2020 openaccessthisarticleislicensedunderacreativecommonsattribution4.0internationallicens whichpermitsus share adapt distributionandreproduct medium format long give appropri credit origin author sourc provid link creativ common licens indic chang made imag third parti materi articl includ articl ’ creativ common licens unless indic otherwis credit line materi materi includ articl ’ creativ common licens intend use permit statutori regul exce permit use need obtain permiss directli copyright holder view copi licens visit http //creativecommons.org/licenses/by/4.0/ correspond lisa ouss david cohen 1servic de psychiatri de l ’ enfant ap-hp hôpital necker 149 rue de sèvre 75015 pari franc 2institut de systèm intellig et de robotiqu cnr umr 7222 sorbonn université 4 place jussieu 75252 pari cedex franc full list author inform avail end articl 1234567890 1234567890 1234567890 1234567890 interact protocol follow infant w ass outcom 4 year age aim explor whether multimod social signal interperson synchroni infant–moth interact 9 month could predict outcom materi method design particip clinic measur perform prospect follow-up studi infant ws14 institut review board comité de protect de personn groupe-hospitali necker enfant malad approv studi parent gave written inform consent receiv verbal written inform studi ask particip follow-up studi ass out- come w take account develop earli interact genet respons pharmacolog treatment14 studi conduct novemb 2004 march 2010 neuro-pediatr depart center rare epilepsia necker enfants-malad hospit pari 41 patient screen studi period enrol two case w seven patient drop age 3 lead sampl 32 patient detail follow-up data typic develop infant recruit matern infant prevent institut pediatr consult proxi ass neurodevelopment outcom focus id asd id assess brunet-lézin development examin perform child age 3 year brunet-lézin development examin estim development quotient base upon norm data avail 3-year-old french toddlers15 diagnosi autism base upon sever measur expert assess blind variabl 3 year age parent complet autism diagnost interview- revis ass autism sign dimens development delay16 2 3 year age patient assess child ’ autism rate scale 17 expert clinician blind child histori assess autism id 20-min videotap child/moth play 2 year age final diagnosi asd and/or id age 4 base upon consensu approach use direct assess child clinician expertis autism well clinic inform car adi-r dq video record infant–moth interact assess 9 12 month age play session two synchron camera recor- ded movement two dimens infant sit babi chair audio interact also around 9 month e r n e w n e r l h c l c p g n p l e v e control lab record infant-moth interac\\x02on mother infant free interac\\x02on interac\\x02on giraﬀ mother sing 3 sequenc interac\\x02on w id/asd w without id/asd typic develop control 4 year machin learn classiﬁca\\x02on west syndrom vs. td w id/asd vs. w without id/asd audio featur extrac\\x02on infant typic vocaliza\\x02on atyp vocaliza\\x02on paus mother vocaliza\\x02on motheres paus synchroni overlap silenc infant synchroni ra\\x02o video featur extrac\\x02on infant ’ hand movement veloc accelera\\x02on curvatur spa\\x02al paus fig 1 pipelin machin learn approach classifi w vs. td ouss et al translat psychiatri 10:54 page 2 7 record standard situat encompass three sequenc 3 min free play instruct- ing mother interact “ usual ” without toy free play use help toy sophi giraff mother sing babi due posit babi chair ﬂoor mother ’ seat posit mother posit slightli higher record mother ’ indic posit left child shown pictur except sometim observ record infant hand movement featur 1 min extract 3-min video record accord two criterion child ’ hand visibl least part sequenc e.g. mother lean child minut repres greatest amount interact mother child audio speech turn- take comput use 3-min audio record sequenc 1 vision comput process infant hand movement use method develop ouss et al.13 summar success step calcul hm featur step 1 two- dimension coordin hand extract video record track wristband right hand yellow fig s1a video-audio record panel track framework compris three step predict observ estim propos ref 18 hand motion highli nonlinear develop approach use bootstrap-bas particl ﬁlter ﬁrst-order model address abrupt chang direct speed19,20 address hand occlus implement approach combin track detect ad boolean variabl state vector associ particle18 extract trajectori consist 1500 pair x coordin 25 frame per second gener 1500 pair coordin 60 see fig s1 left panel vision comput frame hand visibl clearli indic trajectori miss coordin time point account differ- enc camera zoom paramet trajectori obtain normal use ﬁxed refer system present set video record nor- maliz perform trajectori 95 normal factor rang 0.8 1.22 outlier trajectori requir greater cor- rection forty-on percent trajectori requir 5 correct although record two camera synchron principl allow 3d reconstruct trajectori accumul miss data prevent reconstruct howev 2d motion captur appropri deﬁn movement descriptor power detect clinic rele- vant changes21 therebi justifi independ ana- lysi 2d-trajectori video see fig s1b vision comput 2d panel left step 2 descriptor hm calcul planar trajectori fig s1b tabl shown vision comput panel descriptor cover alreadi report literatur import char- acter infant ’ hm21 describ space explor hand calcul maximum dis- tanc observ two ax standard deviat x coordin observ 60 also calcul max- imum distanc two point trajectori use farthestpair java librari http //algs4.c princeton.edu/code/ fig s1b vision comput panel red line third panel left evalu hm dynam calcul veloc accelera- tion also relat hm dynam calcul hm paus deﬁn part trajectori veloc lower speciﬁc threshold mini- mum durat 4 s. final curvatur trajectori calcul use standard deﬁnit curvatur plane curv cartesian coordin γ curvatur calcul point trajectori present right panel fig s1b ﬁrst 1.2 trajectori plot associ calcul curvatur point present column audio comput extract two type audio social signal audio channel mother–inf interact speech turn take motheres stt extract follow method develop weisman et al.22 bourvi et al.23 first use elan segment infant ’ mother ’ speech turn annot dialog act mother ’ audio interact categor mother vocal meaning vocal laugh sing anim sound nois clap hand snap ﬁnger snap tongu mouth nois etc. similarli infant ’ audio product deﬁn infant vocal babbl vocal laugh cri atyp vocal nois “ rale ” infant ’ mother ’ utter label two annot cohen ’ kappa two annot calcul dyad task item grid item kappa valu 0.82 1 annot extract speech turn infant mother speech turn con- tinuou stream speech 150 m silenc ouss et al translat psychiatri 10:54 page 3 7 obtain list tripl speaker label start time durat speech turn tripl also deduc start time durat time segment mother infant speak therefor extract mother vocal mother nois infant vocal infant atyp vocal mother paus infant paus also extract three dyadic featur silenc deﬁn sequenc time neither particip speak 150 m overlap ratio deﬁn durat vocal overlap mother infant divid durat total interact ratio measur proport interact time partici- pant simultan vocal infant syn- chroni ratio deﬁn number infant ’ respons mother ’ vocal within time limit 3 divid number mother vocal time paradigm 3- window base avail- abl literatur synchrony7,24 mother vocal also comput affect speech analysi previou work shown motheres may shape parent-inf interactions25 segment mother vocal analyz use computer classiﬁ categor “ motheres ” “ non-motherese/oth speech ” initi develop analyz home movies11 system exploit fusion two classiﬁ name segment suprasegmental26 consequ utter character segment suprasegmental/prosod e.g. statist regard fundament frequenc energi durat featur detector use gmm classiﬁ segment suprasegment featur number gaussian gmm classiﬁ 12 15 respect λ weight coefﬁcient use equat fusion λ 0.4 purpos current studi explor perform motheres classiﬁ french mother analyz 200 sequenc french mother 100 motheres vs. 100 speech blindli valid two psycholinguist calcul intraclass correl two rater expert algo- rithm found good signiﬁc icc icc 0.79 p 0.001 level predic- tion made suitabl analysi entir data set base automat detect motheres creat two subclass mother vocal mother- ese vs. non-motheres two variabl deriv motheres ratio durat motheres vocalization/ durat interact non-motheres ratio dura- tion non-motheres vocalization/dur interac- tion also deriv two synchroni ratio synchroni motheres ratio synchroni non-motheres ratio reﬂect ratio time infant vocal respons his/her mother motheres speech predict outcom use machin learn pipelin approach shown fig 1 first data qualiti analysi perform ensur valid data expect data avail audio analysi howev substanti proport data discard due video record vision com- pute issu ﬁnalli kept 18 video record w 17 video td group second given number featur 21 infant hm camera sequenc 16 stt compar data set 32 w 19 td reduc data use princip compon analysi third test sever algorithm classifi w vs. td base whole data set avail vision audio comput featur best algorithm deci- sion stump27 result present base classiﬁc decis stump algorithm also analyz w id/asd vs. w without id/ asd classiﬁc also extract confus matrix explor individu featur contribut given classiﬁc use pearson correl result tabl s2 summar demograph clinic characterist child w follow-up 10 infant 32 child w develop asd/id eight child asd id wherea 2 id expect variabl relat asd id signiﬁcantli differ ws+ compar ws− figur 2a summar best classiﬁc model use decis stump algorithm shown multimod classiﬁc outperform unimod classiﬁc distinguish w td therefor use multimod approach classifi ws+ vs. ws− best model reach 76.47 accuraci classify- ing w vs. td 81.25 accuraci classifi ws+ vs. ws−base multimod featur extract earli interact interestingli confus matrix fig 2b show classifi w vs. td error came td misclassiﬁ w clas- sifi ws+ vs. ws− error came ws+ misclassiﬁ ws− tabl 1 list best featur multimod classiﬁc base pearson correl valu best featur distinguish w td includ four infant hm featur 1 mother audio featur contrast best featur distinguish ws+ ws−includ combin infant vocal featur ouss et al translat psychiatri 10:54 page 4 7 0 10 20 30 40 50 60 70 80 90 mu\\x02mod video audio west vs. td west id/asd vs. west id/asd classiﬁ west td west 32 0 td 12 7 classiﬁ west id/asd west id/asd west id/asd 5 5 west id/asd 1 21 machin learn classiﬁca\\x02on decis stump confus matrix b fig 2 machin learn classiﬁc w vs. td ws+ vs. ws−base uni- multimod featur extract earli infant–moth interact tabl 1 best featur classiﬁc featur characterist pearson r p-valu west v typic develop ratio matern audio intervent free interact audio mother 0.35 0.012 total number infant hm paus free interact video infant 0.34 0.014 total number infant hm paus mother sing video infant 0.32 0.023 vertic amplitud giraff video infant −0.30 0.032 movement acceler max free interact video infant 0.29 0.034 west asd/id vs. west without asd/id total number infant vocal free interact audio infant −0.56 0.001 synchroni ratio audio synchroni −0.55 0.001 ratio infant vocal free interact audio infant −0.55 0.001 motheres synchroni ratio audio synchroni −0.54 0.002 non-motheres synchroni ratio audio synchroni −0.48 0.005 hm acceler sd giraff interact video infant −0.46 0.008 hm acceler max giraff interact video infant −0.45 0.01 hm veloc sd giraff interact video infant −0.43 0.014 curvatur max giraff interact video infant −0.37 0.039 rel time spent motionless free interact video infant 0.36 0.04 hm hand movement asd autism spectrum disord id intellectu disabl sd standard deviat ouss et al translat psychiatri 10:54 page 5 7 synchroni vocal featur infant hm featur last show lower correla- tion score discuss best knowledg ﬁrst studi appli multimod social signal process mother–inf interact context w com- bine speech turn infant hm infant–moth interact 9 month signiﬁcantli pre- dict develop asd sever moder id 4 year age high-risk child w confus matrix show classiﬁc error random enhanc interest compu- tation method propos addit best contribut featur perform classiﬁc differ classifi w vs. td ws+ vs. ws− infant hm signiﬁc featur distin- guish w versu td probabl reﬂect motor impact due acut w encephalopathi classifi ws+ vs. ws− contribut infant audio featur synchroni featur becam much relev combin sever hm featur believ import synchroni reciproc earli interact line recent studi investig risk asd ndd ﬁrst year life home movi prospect follow-up high-risk infant sibl infant w prospect studi assess tool screen risk autism ﬁeld asd synchroni reciproc parent sensit emot engag propos target earli interventions30 could prevent earli inter- activ viciou circl parent at-risk infant tri compens lack interact child modifi stimul therefor sometim reinforc dysfunct interactions24 earli identiﬁc interact target especi use among babi neurolog comorbid delay development mileston impair earli social interact sufﬁ- cient predict asd similarli believ import hm distinguish w vs. td one hand ws+ vs. ws−on hand also line studi investig import non-soci behavior investig risk asd ndd ﬁrst year life exampl studi home movi purpura et al found bilater hm ﬁnger movement infant later develop asd31 similarli sever prospect follow-up studi high-risk siblings32–35 retrospect studi home movies36,37 report spe- ciﬁc motor atyp repertoir infant asd asd earli social signal previous assess automat comput procedur focus eye track earli stages38–40 vocal pro- ductions41 analysi acoust ﬁrst utter cri episodes42 none done interact set studi propos paradigm shift assess infant behavior dyadic assess interact previous achiev retrospect approach use home movies24 aim implement studi social signal process routin clinic work rather decompos clinic intuit sign valid relev cue clinic featur clinic work back clinic social signal process rigor step help clinician better identifi ass earli target intervent given exploratori natur approach method result interpret caution take account strength prospect follow-up automat multimod social signal process ecolog standard assess limit limit includ overal sampl size know w rare diseas high rate miss data video record due ecolog condit infant–moth interact mother interpos camera infant ﬁnal sampl size ws+ limit power machin learn method conclud method propos combin multimod automat assess social signal pro- cess earli interact infant risk ndd promis tool deciph clinic featur remain difﬁcult identifi ass context w show method propos label ‘ behavior interact imag ’ abl sig- niﬁcantli predict develop asd id 4 year age high-risk child w assess 9 month age acknowledg author thank patient famili particip studi studi fund ead foundat agenc national de la recherch groupement de recherch en psychiatri partial perform labex smart support french state fund manag anr investiss ’ avenir program refer anr-11-idex-0004-02 sponsor involv studi design data analysi interpret result author detail 1servic de psychiatri de l ’ enfant ap-hp hôpital necker 149 rue de sèvre 75015 pari franc 2institut de systèm intellig et de robotiqu cnr umr 7222 sorbonn université 4 place jussieu 75252 pari cedex franc 3département de psychiatri de l ’ enfant et de l ’ adolesc ap-hp hôpital pitié-salpêtrièr 47-83 boulevard de l ’ hôpital 75651 pari cedex 13 franc 4ariana pharmaceut research depart pari franc 5servic de neuropédiatri ap-hp hôpital necker 136 rue de vaugirard 75015 pari franc ouss et al translat psychiatri 10:54 page 6 7 conﬂict interest author declar conﬂict interest publish ’ note springer natur remain neutral regard jurisdict claim publish map institut afﬁliat supplementari inform accompani paper http //doi.org/ 10.1038/s41398-020-0743-8 receiv 7 decemb 2019 revis 13 januari 2020 accept 16 januari 2020', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5166a025-4d24-4cff-a52a-13d0611534ee', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Abbas_2018_cleaned.txt', 'file_name': 'Abbas_2018_cleaned.txt', 'file_type': 'text/plain', 'file_size': 25151, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='research applic machin learn approach earli detect autism combin questionnair home video screen halim abbas,1 ford garberson,1 eric glover,2 denni p wall1,3,4 1cognoa inc. palo alto ca usa www.linkedin.com/in/halimabba 2eric_g ericglover.com 3depart pediatr stanford univers stanford ca usa 4depart biomed data scienc stanford univers stanford ca usa correspond cognoa inc. palo alto ca usa halim cognoa.com receiv 19 septemb 2017 revis 16 march 2018 editori decis 25 march 2018 accept 2 april 2018 abstract background exist screen tool earli detect autism expens cumbersom time- intens sometim fall short predict valu work sought appli machin learn gold standard clinic data obtain across thousand child at-risk autism spectrum disord creat low-cost quick easi appli autism screen tool method two algorithm train identifi autism one base short structur parent-report ques- tionnair tag key behavior short semi-structur home video child com- binat algorithm use combin result singl assess higher accuraci over- come scarciti sparsiti imbal train data appli novel featur select featur engin featur encod techniqu allow inconclus determin appropri order boost screen accuraci conclus perform valid control clinic studi result multi-cent clinic studi n ¼ 162 child perform ascertain perform algorithm combin demonstr signiﬁc accuraci improv standard screen- ing tool measur auc sensit speciﬁc conclus ﬁnding suggest mobil machin learn process reliabl method detect autism outsid clinic set varieti confound factor clinic analysi discuss along solut engin algorithm final result statist limit beneﬁt fu- ture clinic studi extend sampl size key word supervis machin learn autism spectrum disord diagnost techniqu procedur mobil applic introduct diagnosi within first year life dramat improv outlook child autism allow treatment child ’ brain still rapidli developing.1,2 unfortun autism typic diagnos earlier age 4 unit state approxim 27 case remain undiagnos age 8.3 delay diagnosi driven primarili lack effect screen tool shortag specialist evalu at-risk child use higher accuraci screen tool priorit child seen specialist therefor essenti autism screener use today base question parent medic practition produc result com- pare sum answer score predetermin threshold notabl exampl modifi checklist autism toddler re- vise ,4 checklist-bas screen tool autism intend administ development screen child age 16 30 month child be- havior checklist .5 parent-complet screen tool instrument respons question sum question given equal weight total pre-determin threshold child consid high risk v c author 2018 publish oxford univers press behalf american medic informat associ right reserv permiss pleas email journals.permiss oup.com 1000 journal american medic informat associ 25 2018 1000–1007 doi 10.1093/jamia/ocy039 advanc access public date 7 may 2018 research applic autism case cbcl multipl scale base upon dif- ferent set question correspond differ condit “ autism spectrum problem ” scale cbcl use compar perform perform algorithm paper paper present two new machin learn screener reliabl cost-effect short enough complet minut achiev higher accuraci exist screener age span exist screener one base short questionnair child answer parent base iden- tific specif behavior train analyst watch two three short video child within natur environ captur parent use mobil devic parent questionnair screener key behavior pattern similar probe standard autism diagnost instrument autism diagnost interview – revis .6 clinic tool consist interview parent 93 multi-part ques- tion multipl choic numer respons deliv- ere train profession clinic set instrument consid gold-standard give consist result across examin cost time administ prohibit primari care set paper present approach use clinic adi-r instrument data creat screener base short questionnair present directli parent without supervis video screener key behavior pattern similar probe anoth diagnost tool autism diagnost observa- tion schedul .7 ado wide consid gold standard one common behavior instrument use aid diagnosi autism.8 consist interact struc- ture examin child train clinician tightli con- troll set ado multi-modular diagnost instrument differ modul subject differ level cognit de- velop paper present approach mine ado clinic record focu younger development age cre- ate video-bas screener reli analyst evalu short video child film parent home use behavior pattern commonli probe adi-r ado scoresheet input train autism screen classifi introduc studi clinic valid previou work.9–12 sever new aspect paper first algorithm de- tail present studi design accur robust confound bia train applic data next paper focu consider attent impact confound factor machin learn algorithm context exampl confound bia dis- cuss highlight tabl 2 label data usual origi- nate tightli control clinic environ henc clean spars unbalanc differ context data avail appli screen techniqu le formal en- viron paper also present combin algorithm power singl screener lastli paper gener algorithm non-binari sometim result “ inconclus ” determin present data challeng case allow higher screen accuraci child receiv conclus screen still pre- sent clinic action inconclus outcom challeng case classifi paper appli screen child clinic studi use cognoa13 app date cognoa use 250 000 parent u intern ma- joriti cognoa user parent young child 18 30 month clinic studi consist 162 at-risk child undergon full clinic examin receiv clinic diag- nosi center special neurodevelopment disord method feasibl amass larg train set child evalu mobil screener also receiv profession medic diagnosi approach start histor- ical medic instrument record previous diagnos subject use train data screener reli informa- tion acquir outsid clinic set expect perform deg- radat appli algorithm le control set would result inaccur screener convent machin learn- ing method use much paper outlin detail creativ machin learn method design overcom chal- leng creat reliabl screener set train data compil multipl repositori ado adi-r score-sheet child 18 84 month age includ boston autism consortium autism ge- netic resourc exchang autism treatment network simon sim- plex collect vanderbilt medic center sinc repositori highli imbalanc non-autist patient control across dataset supplement balanc data obtain conduct adi-r interview train clinician random sampl child deem low risk autism cognoa ’ user base algorithm smaller set optim featur select use method dis- cuss detail final select featur given supplementari materi clinic valid sampl consist 230 child pre- sent one three autism center unit state 18 72 month age particip refer clinic ’ typic referr program process english-speak parent consid studi three clinic center approv multisit irb project number 2202803 everi child receiv ado well standard screen- er like m-chat cbcl appropri diagnosi ul- timat ascertain licens health care provid 162 child parent also use mobil devic com- plete short parent questionnair submit short video requir screener discuss paper sampl break- age group diagnosi train clinic valid dataset shown tabl 1 approach train two independ ml classifi combin out- put singl screen assess parent questionnair classifi train use data histor item-level adi-r score-sheet label correspond establish clinic diagno- s video classifi train use ado instrument score- sheet diagnost label case progress sampl use verifi suffici train volum detail supple- mentari materi multipl machin learn algorithm eval- uat includ ensembl techniqu train data number algorithm perform well random forest chosen robust overfit adi-r ado instrument design administ train profession highli standard clinic set typi- calli take hour contrast screen method deliber journal american medic informat associ 2018 vol 25 8 1001 design administ home parent without expert super- vision take minut complet chang environ- ment caus signific data degrad bia result expect loss screen accuraci classifi present mind adjust ml methodolog mitig issu bia effort mitig discuss differ train applic environ screener train histor patient record corre- spond control lengthi clinic examin appli via web mobil app aim unsupervis parent home tabl 2 detail variou mechan confound bia may consequ creep applic data note inaccuraci introduc bia probe cross- valid similar analysi train data alon hyperparamet optim parent questionnair video model dis- cuss model hyperparamet tune boot- strap grid search case class label use stratifi fold pair use weight-bal sam- ple detail found supplementari materi parent questionnair multipl model variant repres increment improv gener ml classif approach discuss gener ml baselin variant random forest train adi-r instrument data instrument ’ 155 data column treat categor variabl one-hot encod subject ’ age gender in- clude featur well result set featur top 20 select use feature-import rank decis forest robust featur select variant due small size sparsiti train dataset gener fea- ture select robust select featur along perform result model fluctuat run run due stochast natur learner ’ underli bag ap- proach mani adi-r question highli correl lead multipl compet set featur select choic seem- ingli equal power train differ per- formanc characterist underli sampl bia expos via full bootstrap cross-valid result wide perform rang variant gener ml baselin method shown tabl 3 tabl 1 dataset breakdown age group condit type sourc train data clinic valid sampl neg class label includ normal develop child well child development delay condit autism number sampl age condit classif type questionnair video clinic valid train train 4 autism þ 414 1445 84 4 condit \\x02 133 231 18 4 neurotyp \\x02 74 308 3 \\x03 4 autism þ 1885 1865 37 \\x03 4 condit \\x02 154 133 11 \\x03 4 neurotyp \\x02 26 277 9 tabl 2 differ train applic environ differ expect caus bia cap- ture cross-valid studi aspect train set applic set sourc adi-r ado instrument administ train profession clinic eval-u short parent questionnair display smartphon behavior tag ana-lyst observ two three 1-minut home video upload parent proctor highli train medic profession parent answer questionnair un-train analyst evalu home video minim train result answer may consist object reliabl set clinic set highli standard semi-structur interact home possibl recreat structur clinic environ result undesir variabl output signal subject might also behav differ- entli clinic home amplifi bia durat adi-r take 4 hour com- plete ado take 45 minut direct observ train profession 10 minut complet parent questionnair minut home video result symptom behavior pattern might pre- sent observ also caus big uncertainti sever fre- quenci observ symptom questionnair sophist languag involv psycholog- ical concept term subtleti unfa- miliar nonexpert simpliﬁ question answer choic result le nuanc noisier input 1002 journal american medic informat associ 2018 vol 25 8 robust featur select overcam limit use two- step approach first 100-count bootstrap featur select run weight balanc 90 random sampl select iter top 20 featur select time rank-invari talli kept number time featur made top-20 list next top 30 featur talli kept candid featur discard final feature-select run use pick best subset can- didat featur approach found robust sta- tistic fluctuat usual select set featur run multipl time minim subset maxim perform fea- ture chosen lock clinic valid total 17 fea- ture young child 21 featur old detail select featur avail supplementari materi age silo variant variant built upon improv robust featur selec- tion method exploit dichotomi pre-phras fully-phras languag capabl at-risk child languag develop signific domain known affect natur autism present consequ kind be- havior clue look order screen variant achiev better perform train separ classifi child younger older age group tabl 1 age dichotomi 4 \\x034 chosen serv best proxi languag abil featur select model parameter- tune cross-valid run independ age group classifi silo age group classifi lim- ite select featur work well across child de- velopment stage silo enabl classifi special featur development appropri within age group severity-level featur encod variant build upon method includ age silo variant achiev better perform replac one-hot featur encod context-appropri techniqu one-hot encod distinguish valu correspond increas level sever behavior symptom valu convey clear concept sever especi troublesom sinc typic adi- r instrument question includ answer choic type val- ue exampl adi-r question 37 focu child ’ ten- denci confus mix pronoun allow answer code 0 1 2 3 7 8 9 among choic 0 3 denot increas degre sever pronomin confus 7 denot type pronomin confus cover 0-3 regardless sever code 8 9 denot non-applic question exam- ple child still incap phrasal speech lack answer respect code answer question gener one-hot encod would allow non-symptomat answer code select screen featur base phantom correl present dataset severity-level encod convert answer code con- vey relev semant concept common valu therebi reduc chanc useless featur select reduc number fea- ture choos addit severity-level encod condens signal accord increas rang sever exampl encod adi-r question 37 would map respons new fea- ture 1 follow case new featur would zero 0 “ ¼0 ” 1 “ 1 ” 2 “ 1 ” “ 2 ” 3 “ 1 ” “ 2 ” “ 3 ” 7 “ ¼ 7 ” 8 9 none close resembl way medic prac- tition interpret answer choic help allevi problem sparsiti one-hot encod featur dataset aggreg featur variant build upon method includ sever level encod variant achiev better perform incorpor aggreg tabl 3 perform increasingli effect classiﬁ variant base train data parent questionnair result top tabl base cross-valid train perform result bottomt avail variant use optim select featur base actual clinic result auc sensit specif age 4 year ¼ 4 year age 4 year ¼ 4 year age 4 year ¼ 4 year train scenario gener ml baselin 0.932 0.950 0.928 0.953 0.928 0.953 0.976 0.982 0.975 0.984 0.975 0.984 0.628 0.645 0.625 0.648 0.625 0.648 robust featur select variant 0.958 0.958 0.958 0.982 0.982 0.982 0.624 0.624 0.624 age silo variant 0.953 0.939 0.961 0.962 0.939 0.977 0.777 0.774 0.779 severity-level featur encod variant 0.965 0.950 0.974 0.962 0.912 0.993 0.748 0.833 0.692 aggreg featur variant 0.972 0.987 0.963 0.992 0.988 0.994 0.754 0.894 0.661 inconclus allow 25\\\\ 0.991 0.997 0.983 1.000 1.000 1.000 0.939 0.977 0.881 applic scenario age silo variant 0.62 0.68 0.54 0.65 0.62 0.52 0.48 0.46 0.24 severity-level featur encod variant 0.67 0.69 0.64 0.64 0.62 0.58 0.48 0.46 0.33 aggreg featur variant 0.68 0.73 0.68 0.68 0.69 0.65 0.57 0.62 0.48 inconclus allow 25\\\\ 0.72 0.72 0.73 0.70 0.72 0.67 0.67 0.71 0.53 journal american medic informat associ 2018 vol 25 8 1003 featur minimum maximum averag sever level well number answer choic sever level across question correspond 20 select featur new fea- ture especi help due spars shallow wide na- ture train set whereupon semant meaning condens signal use train classifi inconclus result variant child complex symptom present known pose challeng development screen child often screen fals posit fals neg result overal degrad screen accuraci observ standard method becom accept industri given low-cost instrument reli sophist observ differenti complex symptom case approach avoid assess altogeth tri instead spot label “ inconclusive. ” build upon method includ featur engin two method implement strategi devis first train binari classifi continu output score replac cutoff threshold cutoff rang valu within cut- rang consid inconclus grid search use deter- mine optim cutoff rang repres tradeoff inconclus determin rate accuraci conclus sub- ject second approach train cross-valid simpl binari classifi label correctli incorrectli predict sam- ple conclus inconclus respect build sec- ond classifi predict whether subject would incorrectli classifi first classifi runtim second classifi use spot label inconclus conclus sent classif third binari classifi train conclus sampl method label inconclus result yield similar perform therefor simpler method use threshold rang machin learn output use report inconclus result paper inconclus rate configur model paramet control tradeoff coverag accuraci throughout paper inconclus rate variant set 25 video second two-method approach autism screen ml classifi us input answer presenc sever target behavior among subject inform provid analyst upon view two three 1-minut home video child semi-structur set taken parent mobil phone classifi train item-level data two ado modul modul 1 preverb modul 2 phrase speech correspond clinic diagnosi two decis forest ml classifi train correspond ado modul classifi 10 question select use robust featur select method allow- anc inconclus outcom made parent ques- tionnair classifi model independ parameter-tun bootstrap grid search class label use stratifi cross-valid fold pair use weight- balanc sampl problem relat chang environ train applic especi signific case video screen ado involv 45 minut direct observ child expert wherea screen base unsupervis short home video specif expect likelihood inconclus unobserv behavior symptom much higher ap- plicat train data assess level sever frequenc observ symptom le reliabl applica- tion train data follow improv design help overcom limit presenc behavior encod minim potenti bia video analyst misread se- veriti symptom short cell phone video encod scheme improv featur reliabl expens featur infor- mation content collaps sever gradat question one binari valu repres presenc v absenc be- havior symptom question importantli valu 1 denot presenc behavior regardless whether behavior indic- ativ autism normalci rule ensur valu 1 correspond reliabl observ wherea 0 necessar- ili indic absenc symptom possibl failur ob- serv symptom within short window observ miss valu inject balanc nonpres featur video screener train data collaps sever gradat singl categori over- come noisi sever assess help problem symptom present unnotic short home video reason import learn algorithm treat valu 1 semant meaning valu 0 inconse- quential end augment train set duplic sampl featur valu flip 1 0 injec- tion 0 randomli perform probabl sample-weight ratio posit neg sampl valu particular featur 0 50 ratio ensur tree random forest much le like draw conclus absenc featur combin desir combin questionnair video screener achiev higher accuraci howev need overlap train set avail instead clinic valid dataset use train combin model numer respons parent questionnair video classifi combin use l2-regular logist regres- sion advantag reduc concern overfit particularli given logist model three free paramet bootstrap cross -valid studi show overfit- ting may present procedur detect within statist limit sinc individu method silo age separ combin algorithm train per age group silo combin algorithm optim inconclus output criterion chosen use logist regress respons use techniqu parent questionnair video classifi perform characterist overal screen process compar standard altern screener shown result parent questionnair perform train data bootstrap cross-valid perform metric optim parameter-tun version variant parent 1004 journal american medic informat associ 2018 vol 25 8 questionnair report top tabl 3 result baselin variant report rang rather singl valu unreli gener featur select lead differ- ent set featur select run run vari perfor- manc result parent child includ clinic studi answer short age-appropri question chosen use robust featur select method discuss clinic perform metric classif variant build upon featur select scheme shown bottom tabl 3 differ perform be- tween train valid dataset driven differ emphas tabl 2 see result tabl 4 discuss statist signific result roc curv figur 1 show parent questionnair clas- sific approach outperform establish screen tool like mchat cbcl clinic sampl sinc clinic center usual interest screen tool high sensitiv- iti drawn shade region 70 90 sensitiv- iti aid eye combin screen perform clinic data roc curv figur 2 show combin questionnair video classifi singl assess boost perfor- manc clinic studi sampl 25 challeng case allow determin inconclus per- formanc remain case shown figur 3 note roc curv figur m-chat contain younger chil- dren due fact instru- ment intend older child same-sampl comparison m-chat ml screener seen age bin figur result young child young child particular interest given desir identifi autism earli possibl result restrict child le four year old shown figur 4 5 statist signific train data sampl size larg enough statist limit minim howev result report clinic data signific statist limit section com- pare perform screen algorithm clinic data discuss paper questionnaire- base algorithm of,13 m-chat cbcl questionnaire-bas algorithm paper combin questionnair plu video algorithm paper direct comparison perform mani algorithm report along statist signific tabl 4 discuss introduc novel machin learn algorithm base parent questionnair anoth base short home video record parent score minim train analyst discuss pitfal data sparsiti mix ordin categor natur question train data also identifi sever import confound factor aris differ train applic set algorithm shown novel featur encod featur selec- tion featur aggreg techniqu address challeng quantifi benefit shown benefit allow subject lower certainti output algo- rithm classifi inconclus also shown bene- fit combin result two algorithm singl determin special machin learn model dichotomi age group found screener younger child capital- ize non-verb behavior featur eye contact gestur facial express screener older child focus verbal commun interact child detail pleas refer supplementari materi method result improv shown paper expect translat well clinic scienc applic tabl 4 perform comparison variou algorithm clinic data base model model paper auc improv mean recal improv 2012 public questionnair 0.07 \\x020.03 0.17 0.1 0.02 0.17 m-chat questionnair 0.01 \\x020.11 0.12 0.06 \\x020.04 0.17 cbcl questionnair 0.06 \\x020.04 0.17 0.11 0.03 0.2 2012 public questionnair video 0.16 0.07 0.25 0.12 0.04 0.2 m-chat questionnair video 0.08 \\x020.03 0.19 0.1 \\x020.01 0.21 cbcl questionnair video 0.15 0.04 0.26 0.14 0.04 0.24 2012 public questionnair þ inconclus 0.16 0.02 0.28 0.09 \\x020.02 0.2 m-chat questionnair þ inconclus \\x020.01 \\x020.39 0.31 0.08 \\x020.18 0.29 cbcl questionnair þ inconclus 0.15 0.01 0.29 0.11 \\x020.02 0.24 2012 public questionnair video þ inconclus 0.21 0.1 0.32 0.19 0.1 0.28 m-chat questionnair video þ inconclus 0.09 \\x020.05 0.23 0.15 0.04 0.27 cbcl questionnair video þ inconclus 0.2 0.09 0.32 0.2 0.09 0.31 questionnair questionnair video 0.09 0.02 0.15 0.03 \\x020.04 0.09 questionnair questionnair þ inconclus 0.09 \\x020.01 0.17 \\x020.0 \\x020.09 0.08 questionnair questionnair video þ inconclus 0.14 0.06 0.23 0.09 0.01 0.17 q. video questionnair video þ inconclus 0.06 0.01 0.11 0.06 0.0 0.13 row evalu improv one algorithm paper “ base model ” algorithm auc metric averag autism non-aut recal respons threshold point achiev approxim 80 sensit neg valu would repres worsen perform given algorithm compar base model averag valu improv 5 95 conﬁdenc interv report algo- rithm label “ inconclus ” allow 25 difﬁcult sampl discard metric evalu note m-chat instru- ment intend use younger child therefor older child exclud preform comparison m-chat tabl journal american medic informat associ 2018 vol 25 8 1005 figur 1 roc curv clinic sampl variou questionnair base autism screen techniqu order least sophist note unlik figur 2 3 4 168 child includ sampl figur 2 roc curv clinic sampl questionnair video base algorithm separ combin establish screen tool mchat cbcl includ baselin figur 3 roc curv clinic sampl questionnair video base algorithm separ combin inconclus determin allow 25 case establish screen tool mchat cbcl includ baselin figur 4 roc curv clinic result child four year age questionnair video base algorithm well combin comparison establish screen tool mchat cbcl also shown 1006 journal american medic informat associ 2018 vol 25 8 includ screen cognit condit dementia elderli physic condit concuss adult fur- ther expect method would appli well survey base domain applic context differ train context signific improv may possibl initi studi identifi probabl improv machin learn methodolog well improv method handl bia train data applic set new clinic trial larger sampl size underway make possibl valid new improv result studi well improv confid high perform algorithm conclus machin learn play import role improv ef- fectiv behavior health screener achiev sig- nific improv establish screen tool autism child demonstr multi-cent clinic trial also shown import pitfal appli machin learn domain quantifi benefit appli proper solu- tion address fund research receiv specif grant fund agenc pub- lic commerci not-for-profit sector compet interest author affili cognoa inc. employ and/or advisori capac contributor list author contribut studi design well draft- ing revis paper author approv final ver- sion paper publish agre account aspect work supplementari materi supplementari materi avail journal american medic informat associ onlin', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='58b9a4cb-98c0-413a-8a0a-4d409425c232', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Abbas_2020_cleaned.txt', 'file_name': 'Abbas_2020_cleaned.txt', 'file_type': 'text/plain', 'file_size': 22873, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport multi-modular ai approach streamlin autism diagnosi young child halim abba 1 ford garberson 1 stuart liu-mayo 1 eric glover1 denni p. wall 2 autism becom press healthcar challeng instrument use aid diagnosi time labor expens requir train clinician administ lead long wait time at-risk child present multi-modular machin learning-bas assess autism compris three complementari modul unifi outcom diagnostic-grad reliabl 4-minut parent- report questionnair deliv via mobil app list key behavior identifi 2-minut semi- structur home video child 2-minut questionnair present clinician time clinic assess demonstr assess reliabl blind multi-sit clinic studi child 18-72 month age unit state outperform baselin screener administ child 0.35 auc 0.69 specif oper 90 sensit compar baselin screener evalu child le 48 month age assess outperform accur 0.18 90 ci 0.08 0.29 90 auc 0.30 specif oper 90 sensit idiopath form autism spectrum disord known biolog caus may correspond multipl condit similar symptom incid asd increas recent year impact 1 59 child accord latest studies1 asd diagnos clinic observ accord standard criteria2 relat child ’ social behavior symptom autism said spectrum due vari sever symptom rang rel mild social impair debilit intellectu disabil- iti inabl chang routin sever sensori reactions2 approxim 25–50 3 autist child non-verb sever symptom notabl diagnosi within first year life dramat improv outlook child autism allow treatment key window development plasticity4,5 unfortun latest studi show although 85 parent child autism report development concern chil- dren 36 month age median age diagnosi unit state 52 months1 complex diagnost procedur shortag train specialist result child asd get diag- nosi earli enough receiv behavior therapi time effect diagnos autism unit state gener take two step development screen follow com- prehens diagnost evalu screen positive6 screen instrument typic use questionnair answer parent teacher clinician7,8 gener easi inexpens administ use flag at-risk child howev alway accur enough help inform diagnosis9 standard autism screener also high fals posit rate lead unnecessari referr healthcar costs10 comprehens diagnost evalu instrument hand accur requir long expens interact highli train clinicians11,12 paper present improv two previous published13 autom autism assess modul underli cognoa14 softwar first modul base brief questionnair child present directli parent without supervis second modul base lightli train analyst evalu short video child within natur environ captur parent use mobil devic also present new third modul intend complet primari care set pediatrician ’ offic clinic visit third modul base upon questionnair answer clinician examin child talk parent demonstr three modul fast easi 1cognoa inc. palo alto ca usa 2depart pediatr biomed data scienc psychiatri behavior scienc stanford univers stanford ca usa email eri_g ericglover.com open 2 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/ administ typic screen instrument yet combin assess accuraci shown work significantli higher may use aid diagnosi autism present approach select maxim predict featur modul parent clinician questionnair modul key behavior pattern similar probe standard autism diagnost instrument autism diagnost interview revis 11 adi-r administ train clinician typic give consist result across examin 93 point questionnair often span 2.5 hour interview parent ’ time make larg impract primari care setting15 video assess modul key behavior pattern similar probe anoth diagnost instrument autism diagnost observ schedul 12 ado multi-modular diagnost instrument differ modul subject differ level cognit develop wide consid gold standard one common behavior instrument use aid diagnosi autism16 consist interact structur examin child train clinician tightli control set valid three modul appli ass child clinic studi use cognoa14 softwar to-dat cognoa use 300,000 parent u intern major cognoa user parent young child 18 48 month clinic studi underli valid result discuss result section consist total 375 at-risk child undergon full clinic examin receiv clinic diagnosi center special neurodevelopment disorders17 output assess modul compar three screen instrument modifi checklist autism toddler revis 7 parent-complet questionnair autism intend administ development screen child age 16 30 month commonli use autism screen instrument social respons scale second edit anoth standard asd screener base upon questionnair fill examiner18–20 sr preschool form intend child age 30 month 54 month school age form intend chil- dren age 48 month 18 year age use sr “ total score ” scale baselin autism assess child behavior checklist 8 parent-complet questionnair provid risk assess mani categori use “ autism spectrum problem ” scale cbcl comparison case answer question compris screener code code sum sum compar threshold determin whether child risk method base approach de-identifi histor patient record collect medic instrument score sheet data pertain child test suspicion autism process train set predict model underli three autism assess modul sinc appli said predict model significantli differ set clinic correspond- ing train data gener expect consequenti perform degrad result unaccept diagnost accuraci convent machin learn method used13 counteract effect appli custom machin learn techniqu detail section build upon previou experiment work13 new techniqu discuss empir post-hoc featur select train data nois inject overfitting-resili probabilist combin modul outcom data train data compil multipl repositori de-identifi ado adi-r score sheet child 18 84 month age includ boston autism consortium autism genet resourc exchang autism treatment network simon simplex collect vanderbilt medic center counteract class imbal sampl set neg class supplement 59 low risk child random-sampl cognoa ’ user-bas adi-r administ addit control diagnost accuraci modul measur use data multi-sit blind clinic valid studi 17 studi perform 2016 2017 three tertiari care center unit state inform consent obtain guardian child relev regul guidelin follow child enrol studi 18 72 month age english-speak household refer typic referr process sus- picion autism everi child measur use autism assess instrument ado m-chat-r and/or cbcl appropri age diagnosi ultim ascertain licens health care provid prior clinic assess parent use cognoa mobil app complet parent question- nair video assess modul start 2017 clinician also complet cognoa clinician ques- tionnair clinician blind result assess render cognoa detail step clinic studi shown fig. 1 enrol process 2016 yield 162 valid sampl use valid parent ques- tionnair video modul clinic enrol cohort use valid dataset previou public subject13 given learn dataset prior extens studi 2017 sever improv made algorithm includ tune model threshold train combin modul perform featur select clinician modul newli introduc 2017 enrol process 2017 yield 213 addit valid particip bring total n 375 sampl cours two year sampl breakdown cohort age group diagnosi data use train valid shown tabl 1 train valid dataset major “ autism ” class label compos mostli child diagnos altern development delay e.g. adhd speech languag disord sinc condit share mani symptom autism particularli challeng- ing sampl classif seven child valid sampl neurotyp suggest sampl harder perform correct classif gener popul 3 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/ algorithm methodolog section explain import aspect machin learn methodol- ogi common classifi underli three assess modul train procedur classifi train featur select optim done separ child four year age four year age parent questionnair clinician questionnair clas- sifier make predict base answer question probe similar concept adi-r questionnair train use answer question histor item-level adi-r score sheet label corre- spond establish clinic diagnosi video modul make predict base answer question probe similar concept ado instrument record video analyst train use ado instrument score sheet diagnost label progress sampl use verifi suffici train volum detail supplementari materi gradient boost decis tree use three modul consist perform better option consid neural network support vector machin logist regress model hyper-paramet tune bootstrap grid search case true class label use stratifi fold pair use weight-bal sampl detail found supplementari materi case machin learn model train use histor patient record correspond con- troll clinic examin focus applic non-clin set aim breviti ease-of-us and/or unsupervis parent usag home differ introduc bia signific enough ruin perform algorithm properli address probe cross valid see supplementari materi detail new strategi address bia discuss result big improv accuraci compar previou work13 figur 1 detail step perform clinic studi describ document age condit number sampl parent/clinician modul train video modul train clinic valid 2016 clinic valid 2017 4 autism 414 1445 75 91 4 autism 207 539 20 30 ≥4 autism 1885 1865 46 60 ≥4 autism 180 410 21 32 tabl 1 dataset breakdown age group condit sourc train data clinic valid sampl machin learn model train stratifi age group clinic valid 2016 2017 sampl use togeth evalu perform parent video modul paper clinician modul avail clinic 2017 dataset 4 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/ inconclus outcom three modul predict one three assess outcom posit neg inconclus outlin fig 2 support inconclus determin incorpor use process involv three separ machin learn train run first model train make predict use label sampl train data like misclassifi second model train use label predict likelihood new sampl misclassifi final sampl like classifi correctli use train final binari autism classifi latter two model use predict time one identifi filter sampl label “ inconclus ” make binari predict whether child autist like correctli label detail model train avail supplementari materi parent modul initi featur select parent questionnair probe minim set highli relev child behavior pattern maxim predict autism combin care taken phrase question answer reliabl signal input everyday parent undertak questionnair via mobil app without clinic assist effect custom featur select method devis involv robust bootstrap-driven backward subtract detail discuss previou publication13 initi set 93 question consider produc optim set 17 novel question child le four year old 21 question child four older empir post-hoc featur select refin follow conclus 2016 clinic valid studi enrol studi differ distribut answer question train data valid data collect 2016 clinic studi question quit good agree- ment other show strong bia toward higher sever answer choic clinic data train data question mean absolut sever differ statist greater three standard error reject requir result exclus 4 17 question younger cohort 8 21 question older cohort model re-train reduc featur set refin select featur minim signific bia due differ train applic environ see supplementari materi detail differ featur refin lead larger boost perform compar with13 improv size perform improv valid held-out sampl child collect 2017 new model show statist equival increas perform compar 2016 sampl video modul video assess modul consist parent upload 2 3 mobil video 1 2 minut length child play meal time home underli algorithm produc autism assess base upon respons least three minimally-train analyst watch video respond behavior questionnair data avail train video modul ’ classif model taken ado session admin- ister clinician standard clinic set gradient boost decis tree train key featur identifi analysi ado record questionnair video analyst answer creat probe similar behavior featur observ train data challeng method- olog modul must make predict face miss featur observ short video upload parent video analyst allow skip question answer base figur 2 illustr methodolog train diagnost assess algorithm capabl output one three possibl outcom “ posit ” “ neg ” “ inconclus ” first binari classifi use assist train never runtim train predict binari “ autism ” v “ autism ” label compar true asd result label sampl incorrectli classifi sampl “ correct ” “ incorrect ” label use train classifi runtim “ indetermin ” classifi train predict sampl asd diagnosi misclassifi serf filter identifi “ inconclus ” case runtim predict “ correct ” sampl use train final binari asd diagnosi classifi 5 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/ post video averag analyst skip question 15 time big variat among particular question effect combin larg discrep observ time window origin clinic examin brief home-video version would result big assessment-accuraci degrad unless step taken correct bia varianc tackl problem introduc bia varianc train data manner design make statis- tical similar video analyst answer assess run data 2016 clinic study13 use develop methodolog perform algorithm data child enrol 2017 use valid generaliz improv child particip clinic studi also administ full ado provid pair ado video data use determin nois pattern add use pair data construct probabl map question-respons set describ way video analyst like respond given “ true ” ado respons use map stochast transform build new train data set thought result hypothet experi technician watch parent-suppli video child train data respond accordingli addit simul “ set nois ” classifi train data lead larger boost perform compar with13 improvement13 addit optim paramet result decis tree model favor larger tree depth expect sinc new model expect make determina- tion featur reliabl present well featur fall back best featur miss clinician modul introduc modul screen autism use questionnair respons cli- nician pediatrician might answer question regular checkup question clinician select similar manner use parent modul respons parent clinician use machin learn modul manner describ parent questionnair key behavior probe via question direct parent clinician clinician question nuanc allow subtl answer choic case parent clinician give contradictori answer question clinician ’ answer overrid parent clinician modul introduc clinic valid studi begin 2017 result therefor base smaller sampl size modul featur select order creat brief clinician questionnair appropri primari care set multipl list candid question compil order use differ strategi list intersect priorit top featur intersect set shortlist first list candid question prepar consid question origin medic instrument exclud parent questionnair deem difficult parent answer reliabl list rank featur import valu measur rank dedic offlin machin learn train cross valid run manner perform initi parent modul featur select second list prepar parent questionnair question simul effect parent underestim answer sever child machin learn respons near decis threshold child train data model respons 0 0.1 asd-vs-non asd decis threshold question sever drop one time one sever valu child 0 0.1 decis threshold question sever rais one sever categori question list rank base upon averag size result shift model respons procedur repeat child train data 0.1 0.3 decis threshold case top 7 question select result total 9 candid question young chil- dren 10 older child third list prepar consult domain expert assess likelihood candid question benefit clinician ’ input complement parent ’ input method conduct separ two age-silo group result overal clinician questionnair 13 question child 18 47 month old 15 question child 4 six year old modul combin due limit avail train data possibl train singl combin model us input featur parent video clinician modul instead respons modul consid probabl combin mathematically21 use equat σ ∗ σ − − − r r comb 1 1 1 rcomb result combin vector 1 r vector respons modul combin σ covari matrix respons residu compar true diagnosi “ train ” combin modul consist calcul valu σ use equat done use respons modul data clinic studi child σ valu rcomb equat calcul child exclud process similar leave-one-out cross valid ensur result report combin procedur suffer overfit sinc eq produc singl model respons determin “ inconclus ” outcom proce differ manner individu assess modul lower upper threshold appli combin respons child respons le threshold consid non-asd child respons two threshold consid inconclus child respons greater threshold consid asd singl model case two threshold tune independ optim sensit specif model coverag 6 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/ result individu cognoa assess modul combin well 3 baselin base commonly-us autism screen instrument evalu data collect blind clinic studi inconclus determin featur turn sampl requir assess conclus cognoa assess modul achiev roc auc 0.83 sensi- tiviti specif 80 75 respect turn inconclus determin featur allow 30 inconclus outcom result accuraci improv conclus sampl auc 0.92 sensit specif 90 83 respect perform shown statist signific improv baselin use comparison roc curv fig 3 show parent modul perform individu well combin video clinician modul 30 inconclus rate allow figur 4 show similar comparison variant consist restrict child four year age roc curv correspond assess- ment modul inconclus allow turn found supplementari materi statist model perform comparison assess modul baselin shown tabl 2 comparison subset child screener administ select n tabl 10,000 bootstrap experi run n child select replac averag 5 95 confid interv improv auc specif screener evalu across bootstrap experi case specif calcul improv perform use threshold set achiev 90 sensit tabl 2 show cognoa modul show improv least 0.26 auc least 0.52 spec- ific compar cbcl srs-2 screener 95 confid level due fact m-chat-r screener evalu younger child statist uncertainti comparison larger howev also show improv least 0.08 auc 0.11 specif 95 confid level comparison allow cognoa assess modul decid hold asid 30 hardest case inconclus comparison forc classif hardest case found tabl 3 supplementari materi figur 3 roc curv clinic sampl parent video clinician modul separ combin inconclus determin allow 30 case establish screen tool m-chat-r srs-2 cbcl compar baselin roc curv m-chat-r baselin instrument includ child four year age sinc m-chat-r applic older child figur 4 roc curv kid 4 year age clinic sampl parent video clinician modul separ combin inconclus determin allow 30 case establish screen tool m-chat-r srs-2 cbcl compar baselin 7 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/ time complet comparison random sampl 529 cognoa user use order measur time complet cognoa autism assess modul median time complet parent modul 4 minut median time complet clinician modul 1.2 minut median time per video analyst score video 20 minut detail found supple- mentari materi result indic parent clinician modul complet littl time establish autism screener case much faster achiev significantli higher accuraci time requir video analyst score video lengthi howev turnaround time faster ado administration12 perform minim train analyst oppos certifi clinic practition discuss present multi-modular assess consist three machin learn modul identif autism via mobil app well evalu perform time-to-complet blind clinic studi assess modul outperform convent autism screener shown tabl 2 fig. 3 accuraci combin assess similar gold-standard instrument ado adi-r22 without requir hour time certifi clinic practition suggest potenti cognoa assess use autism diagnost high perform modul benefit use techniqu describ paper identifi set asid 30 challeng sampl inconclus supplementari materi paper show outperform convent autism screener without techniqu well import open question remain first case paper assess modul valid child preselect high risk autism child pre-select way tend autism-lik characterist regardless true diagnosi increas challeng distinguish true asd case modul expect perform better gener popul sampl child work need verifi hypothesi conduct clinic studi child gener popul second clinician modul newli present work appear promis far appli secondary-car set test primari care clinic need valid accuraci set addit two wider avenu explor interest step first assess mod- ule shown effect identifi presenc absenc autism goal extend identifi sever condit well second techniqu present paper could potenti use build algorithm child behavior condit autism well behavior condit affect adult senior receiv 12 march 2019 accept 20 februari 2020 publish xx xx xxxx age group baselin screener assess modul δauc 0.05 0.95 c.i δspecif 90 sensit 0.05 0.95 c.i n age cbcl parent 0.17 0.10 0.23 0.21 0.13 0.30 370 age srs-2 parent 0.20 0.12 0.28 0.21 0.12 0.31 307 age cbcl parent video 0.29 0.22 0.36 0.41 0.30 0.52 363 age srs-2 parent video 0.32 0.24 0.40 0.41 0.30 0.52 302 age cbcl parent video clinician 0.35 0.26 0.43 0.69 0.58 0.81 200 age srs-2 parent video clinician 0.42 0.33 0.50 0.65 0.52 0.78 175 1.5 3 y.o m-chat-r parent −0.01 −0.10 0.07 0.09 −0.02 0.21 209 1.5 3 y.o cbcl parent 0.12 0.03 0.22 0.20 0.07 0.34 214 1.5 3 y.o srs-2 parent 0.15 0.03 0.27 0.24 0.12 0.38 161 1.5 3 y.o m-chat-r parent video 0.14 0.06 0.22 0.20 0.07 0.34 204 1.5 3 y.o cbcl parent video 0.28 0.18 0.38 0.33 0.18 0.49 209 1.5 3 y.o srs-2 parent video 0.31 0.20 0.42 0.37 0.21 0.55 157 1.5 3 y.o m-chat-r parent video clinician 0.18 0.08 0.29 0.30 0.11 0.50 107 1.5 3 y.o cbcl parent video clinician 0.34 0.22 0.45 0.46 0.25 0.67 111 1.5 3 y.o srs-2 parent video clinician 0.40 0.27 0.53 0.50 0.28 0.73 91 1.5 3 y.o cbcl parent 0.21 0.11 0.30 0.23 0.11 0.35 156 1.5 3 y.o srs-2 parent 0.25 0.15 0.36 0.18 0.06 0.31 146 4 6 y.o cbcl parent video 0.30 0.20 0.39 0.49 0.34 0.64 154 4 6 y.o srs-2 parent video 0.33 0.22 0.44 0.44 0.29 0.59 145 4 6 y.o cbcl parent video clinician 0.35 0.23 0.47 0.93 0.83 1.00 89 4 6 y.o srs-2 parent video clinician 0.43 0.30 0.55 0.79 0.66 0.91 84 tabl 2 statist test perform improv model paper standard baselin screen model δauc tell u increas auc found screener paper across bootstrap experi δspecif tell u increas specif bootstrap experi threshold design achiev 90 sensit δ calcul show averag valu improv along 0.05 0.95 confid interv 8 scientif report 10:5014 http //doi.org/10.1038/s41598-020-61213-w www.nature.com/scientificreport www.nature.com/scientificreports/', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9e7850a1-1978-4039-b419-a0c2b286bec6', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Asd_Cry_patterns_cleaned.txt', 'file_name': 'Asd_Cry_patterns_cleaned.txt', 'file_type': 'text/plain', 'file_size': 37729, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='research articl earli screen autism spectrum disord use cri featur aida khozaeiid1 hadi moradiid1,2 reshad hosseiniid1 hamidreza pouretemad3 bahareh eskandari3 1 school electr comput engin univers tehran tehran iran 2 intellig system research institut skku suwon south korea 3 depart psycholog shahid beheshti univers tehran iran moradih ut.ac.ir abstract increas number child autism import earli autism inter- vention prompt research perform automat earli autism screen conse- quentli present paper cry-bas screen approach child autism spectrum disord introduc would provid earli automat screen studi realiz asd specif featur necessarili observ child asd instanc collect child therefor propos new classif approach abl determin featur correspond instanc test propos approach set data relat child 18 53 month record use high-qual voic record devic typic smartphon variou locat home daycar studi preprocess approach use train classifi use data 10 boy asd 10 typic develop boy train classifi test data 14 boy 7 girl asd 14 td boy 7 td girl sensi- tiviti specif precis propos approach boy 85.71 100 92.85 respect measur 71.42 100 85.71 girl respec- tive shown propos approach outperform common classif method furthermor demonstr better result studi use voic fea- ture screen asd pilot practic propos approach earli autism screen train classifi test 57 particip 10 18 month 57 particip consist 28 boy 29 girl result encourag- ing use approach earli asd screen introduct child autism spectrum disord defin abnorm impair develop social interact commun well restrict repetit behavior interest activ rapid growth asd past 20 year inspir mani research effort toward diagnosi rehabilit asd 2–5 field plo one plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 1 21 a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 open access citat khozaei moradi h hosseini r pouretemad h eskandari b earli screen autism spectrum disord use cri featur plo one 15 e0241690 http //doi.org/ 10.1371/journal.pone.0241690 editor zhishun wang columbia univers unit state receiv novemb 26 2019 accept octob 19 2020 publish decemb 10 2020 peer review histori plo recogn benefit transpar peer review process therefor enabl public content peer review author respons alongsid final publish articl editori histori articl avail http //doi.org/10.1371/journal.pone.0241690 copyright © 2020 khozaei et al open access articl distribut term creativ common attribut licens permit unrestrict use distribut reproduct medium provid origin author sourc credit data avail statement origin clean voic extract featur data set research implement code propos method deposit follow repositori codeocean 10.24433/co diagnosi sever well-establish manual method diagnos child 18 month howev practic averag age diagnosi 3 year due lack knowledg asd lack expertis diagnos autism 7 8 utmost import earli diagnosis/screen order provid earli intervent effect first year life later 7 9–11 shown earli inter- vention improv development perform child asd also report earli intervent would cost save famili treatment servic system 13 14 consequ two main question 1 autism screen earlier 18 month reduc typic diagnosi intervent age 2 possibl employ intellig method screen autism elimin widespread need expert mention goal answer question respect screen child may clear symptom screen child go diagnosi procedur acquir confirm and/or cautious work fortun studi literatur show age diagnosi lower 18 month exampl thabtah peebl review sever questionnaire- base approach may abl screen asd 6 month age howev approach like autism diagnost interview-revis autism diagnost observ schedul clinic proven effect ade- quat time-consum instrument need train practition use reduc depend human expertis need use questionnair sev- eral studi propos machin learn method classifi child asd 18 19 use questionnair goal autom process and/or find optimum subset question featur instanc abba et al propos multi-modular assess sys- tem combin three modul parent questionnair clinician questionnair video assess modul although author use machin learn autom improv classif process need human involv still exist order answer question ass video hand emerson et al show fmri use predict diagno- si autism age 2 high-risk 6-month-old infant denisova zhao use movement data rs-fmri 1–2 month-old infant predict futur atyp develop- mental trajectori biolog featur furthermor bosl tager-flusberg nelson suggest use biomark extract eeg signal earli detect autism blood-bas marker 24 25 prenat immun marker also propos diagnos asd use right birth although approach suggest new direct toward earli asd diagnosis/screen costli requir expert dedi- cate equip would limit usag furthermor method still earli stage research requir approv final approach involv meth- od fmri eeg difficult use child especi child autism may troubl follow instruct appropri atyp behavior excess head movement 29 30 studi use vocalization-bas analysi screen child autism instanc brisson et al show differ voic featur child asd typic develop child sever studi like use speech-rel featur screen child older 2 reach goal earli asd screen vocaliza- tion infant 2 year age investig 33–35 santo et al use vocal babbl screen asd child age 18 month collect data 23 20 asd td child respect report high accuraci around 97 due fact use k-fold cross-valid without consid- ere subject-wis hold order unseen subject test fold oller et al plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 2 21 0622770.v1 harvard datavers contain rar file sound 10.7910/dvn/lstbqw fund hm receiv small fund collect data diagnos subject grant number 123 cognit scienc technolog council iran cogc.ir funder role studi design data collect analysi decis publish prepar manuscript compet interest author declar compet interest exist propos anoth vocalization-bas classif method includ age exclud cri appli method 106 td child 77 child asd 16 48 month reach 86 accuraci pokorni et al extract egemap paramet set includ 88 acoust paramet 10 month old child set consist statist calcul 25 frequency-rel energy-rel spectral low-level descriptor reach 75 accuraci popul 10 td child 10 child asd esposito hiroi scattoni show cri promis biomark screen asd child sheinkopf et al orlandi et al shown differ cri child asd compar td child best knowledg group ’ preliminari studi research use cri sound screen child asd use dataset 5 child asd 4 td child older two year accuraci propos method 96.17 use k- fold cross valid without consid subject-wis hold shortcom studi word overfit avail data may fail correctli clas- sifi new sampl thorough examin use unseen test set cri featur neces- sari evalu result note data previou studi could use studi present paper due differ data collect procedur studi assum specif sound featur distinguish chil- dren asd td child common among asd case howev may case featur instanc tipto walk one repetit behavior child asd appear approxim 25 child conse- quentli current studi propos new cry-bas approach screen child asd screen approach make use assumpt discrimin charac- terist autism may appear asd child assumpt contrast assumpt put forward ordinari instance-bas machin learn method assum instanc class includ discrimin featur need classif propos method first discrimin instanc cri exist subset chil- dren asd found us instanc select featur distinguish asd instanc td instanc mention final select featur studi common among set child asd 18 53 month age select featur support experienti knowledg expert state variat cri child asd td child approach dif- ferent approach either use dataset child specif age 33 35 use age inform classif propos approach imple- ment test 62 particip result show effect approach respect accuraci sensit specif method sinc studi perform human subject first approv ethic commit- tee shahid beheshti univers medic scienc health servic parent particip inform studi sign agreement form includ studi particip 62 particip age 18 53 month divid two group i.e 31 asd 31 td 24 boy 7 girl group sinc expect plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 3 21 differ vocal characterist boy girl train set assembl boy includ 10 td 10 asd word want elimin gender effect featur extract model train unfortun due lower number girl asd real world enough data girl asd could collect nonetheless model also test girl see would gener even inclus criterion asd particip recent diagnos asd base dsm-5 neurodevelopment mental intellectu disord b known medic genet condit environment factor c receiv treatment medic receiv treatment le month two girl fall criterion sinc diag- nose year particip ’ averag languag develop time particip assess base 43–46 equal child 6 12 month old autism diagnosi procedur start gilliam autism rate scale-sec- ond edit questionnair answer parent parent interview base dsm-5 particip evalu observ two child clinic psychologist ph.d. degre addit diagnosi asd separ confirm least one child psychiatrist differ set note ado common diagnost tool administ wide iran sinc offici translat ado farsi td child select age rang similar asd particip volunt famili home health center evid offici diagnosi neurolog psycholog disord time record voic child asd older 20 month mean standard deviat rang 35.6 8.8 33 month respect td child younger 51 month mean standard devia- tion rang 30.8 10.3 33 month respect mention diagnosi child 3 year mainli base expert ’ evalu gar score furthermor td particip 3 year age follow studi pass age 3 make sure initi td assign correct still valid use set expert-select question base ass interview parent tabl 1 2 show detail particip train test set respect tabl number voic instanc particip total durat instanc second shown column 3 4 respect record devic cate- gori i.e high-qual record typic cell phone given devic cat- egori column next two column includ gars-2 score languag development mileston particip asd time record six case gar score avail time studi demonstr nd column label ‘ place ’ show locat record home autism cen- ter health center total number 359 sampl child 53.44 sampl asd particip 46.56 td particip two group 10 td 10 asd child select train classifi two group balanc possibl respect age record devic thu child td group correspond child asd group around age result data balanc obtain train particip age 20 51 month mean age train set 32.7 35.2 month asd td particip respect standard deviat 9 9.9 month rang 25 30 month asd td particip respect plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 4 21 although approach train test child older 18 month test propos approach 57 particip 10 18 month investig work chil- dren 18 month 57 particip consist 28 boy 29 girl mean age 15.2 standard deviat 2.8 2.9 respect particip eval- uat later date age 3 older follow-up procedur use expert- select questionnair time initi voic collect 55 particip evid diagnos disord two refer expert due posit result screen use method diagnosi concern two mention particip well particip evid abnorm development mileston follow-up procedur summar tabl 3 summari disord given last column tabl 3 base parent interview expert ’ evalu unfortu- nate child5 child6 child7 ’ parent cooper obtain expert evalu data collect preprocess mention earlier data record use high-qual devic typic smart- phone high-qual devic ux560 soni voic record soni ux512f voic record use typic smartphon voice-record archiv applic devel- ope use variou type smartphon voic applic high-qual record record wav format 16 bit sampl rate 44.1 khz reason use variou devic avoid bias approach spe- cific devic similarli place record restrict one place order make result applic place parent train voic collector ask record voic quiet environ- ment furthermor ask keep record smartphon 25 cm particip ’ mouth despit propos two recommend record tabl 1 train set data particip id age instanc total durat devic gar score languag mileston place reason cri asd asd1 20 9 7.8 cp 104 0–6 c1 annoyed/uncomfort asd2 24 3 1.5 hqr 83 0–6 c2 unwil asd3 26 5 2.1 hqr 120 0–6 c1 annoyed/uncomfort asd4 28 13 9.1 hqr 121 0–6 c2 annoyed/uncomfort asd5 29 14 26 hqr 89 6–12 c2 unwilling/complain asd6 31 4 2.4 hqr 87 0–6 c2 unwilling/complain asd7 36 11 11 hqr 87 6–12 c2 unwilling/complain asd8 43 2 0.7 cp nd nd c2 unwil asd9 45 3 2.6 cp 72 6–12 c2 complain asd10 45 4 3.4 cp nd nd h sleepi td td1 21 11 14 hqr na na h complain td2 24 12 12 hqr na na c4 scared/unwil td3 26 2 2.3 hqr na na c5 unwil td4 28 6 13 cp na na c5 scared/unwil td5 36 3 2.6 cp na na h unwilling/complain td6 38 3 1.5 hqr na na c6 complain td7 41 3 2.4 hqr na na h unwil td8 43 3 2.2 cp na na h sleepi td9 44 2 1.2 cp na na h complain td10 51 2 1.7 cp na na h complain http //doi.org/10.1371/journal.pone.0241690.t001 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 5 21 voic recommend follow requir qualiti consequ record elimin studi also cri sound due pain remov studi sinc similar td asd group tabl 2 test set inform id age instanc total durat devic gar score languag mileston place reason cri asd boy asd11 28 12 7.2 hqr 102 0–6 c2 unwilling/ uncomfort asd12 30 18 17.1 hqr nd nd c3 separ mother asd13 30 3 2.9 cp nd nd h unwilling/sleepi asd14 31 5 2.3 hqr 73 0–6 c2/ h separ mother/hungri asd15 33 3 2.5 hqr 91 0–6 c2 unwil asd16 33 2 2.5 hqr 104 0–6 c1 annoyed/uncomfort asd17 34 1 0.6 hqr 91 0–6 c2 unwilling/complain asd18 35 2 1.7 hqr 81 nd c1 annoyed/uncomfort asd19 37 1 0.6 hqr 94 12–18 c2 unwilling/complain asd20 40 19 14 hqr 91 0–6 c1 annoy asd21 45 1 0.3 hqr 81 6–12 c2 unwilling/complain asd22 48 2 1.6 hqr 100 6–12 c2 annoyed/complain asd23 52 6 3.1 hqr 113 12–18 c2 unwilling/complain asd24 53 7 5.2 hqr 78 6–12 c1 annoyed/uncomfort girl asd25 25 12 14 hqr 85 0–6 c2 unwilling/complain asd26 26 5 2 cp 102 0–6 c1 scare asd27 31 3 1.7 hqr 94 0–6 c2 unwilling/complain asd28 32 2 1.3 hqr 100 0–6 c2 unwilling/complain asd29 41 8 3 hqr 102 0–6 c2 unwilling/complain asd30 45 2 1.2 cp nd nd h thirsti asd31 49 7 12 cp nd nd h unwilling/complain td boy td11 18 4 2 hqr na na c4 scare td12 18 7 5.1 hqr na na c4 scared/unwil td13 19 7 4.2 hqr na na c5 unwil td14 20 9 8 hqr na na c5 unwilling/complain td15 21 4 1.2 hqr na na h complain td16 24 3 2.7 hqr na na c5 scare /unwil td17 24 2 1.5 hqr na na c5 scared/unwil td18 24 6 5.1 hqr na na c4 unwilling/complain td19 24 4 2.4 hqr na na c5 unwilling/complain td20 24 5 4.2 hqr na na c5 unwilling/complain td21 29 11 10 hqr na na h unwilling/complain td22 30 4 2 hqr na na c5 scared/unwil td23 30 4 2 cp na na h unwil td24 43 12 11 hqr na na h complain girl td25 24 5 6 hqr na na c4 unwilling/complain td26 25 2 4.4 hqr na na c5 scare td27 29 5 5 hqr na na c5 scare td28 33 2 2.1 cp na na h complain td29 45 16 11 hqr na na h unwilling/complain td30 50 6 7 hqr na na h complain td31 51 2 0.7 cp na na h unwil http //doi.org/10.1371/journal.pone.0241690.t002 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 6 21 data collect preprocess phase pure cri part record type vocal select explain part cri sound accompani scream say words/oth vocal occur closed/non-empti mouth elimin segment elimin done manual use sound forg pro 11.0 select cri begin end contain voic rise fade remov order keep steadi part cri prevent much variat voic lead unsuit statist also uvular/guttur part cri remov reason believ part distort featur valu steadi part voic remain continu segment cri consid use sampl studi final sinc basic voic featur extract 20 millisecond frame gener statist featur basic featur minimum length cri seg- ment set 15 frame i.e 300 millisecond thu cri sampl 300 millisec- ond elimin studi studi final prepar sampl 320 millisecond 3 second featur extract previou studi work voic featur discrimin asd child use differ set featur method share sever common featur like f0 i.e fundament frequenc voic mel-frequ cepstral coeffici i.e coeffici repres short-term power spectrum sound f0 one common featur use 31 32 39 howev sinc age import factor affect f0 featur use particip similar age hand mfcc coeffici sever relat statist valu report use featur sever studi 35 41 53 consider- ing use featur report previou studi specif current studi sever featur select use work explain follow studi instanc divid 20 millisecond frame extract basic voic featur use sever featur propos motlagh moradi pouretemad belalca ´zar-bolaño et al featur use motlagh moradi pouretemad includ certain statist like mean covari frame-wis basic featur mfcc coeffici voic segment also use mean varianc frame-wis tempor deriv 55 56 basic featur frame-wis tempor deriv mean tabl 3 particip abnorm follow-up id gender age disord record time following-up time child1 11 11 development delaya sign genet diseas child2 17 17 unddb child3 12 40 asdb child4 12 36 sensori process disorderc sever adhd symptomsb child5 18 40 languag delay child6 15 46 development delay symptom child7 12 43 development delay symptom undd unspecifi neurodevelopment disord clinic observ expert base bclinic observ expert base c clinic observ expert base http //doi.org/10.1371/journal.pone.0241690.t003 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 7 21 differ two consecut frame sens rate chang fea- ture valu one frame step modifi spectral flat featur includ rang 125–250 hz besid 250–500 hz rang rang ad cover wider frequenc rang normal child frequenc rang show necessari process featur extract select rang divid 4 octav spectral flat comput octav remov uninform noisi featur set explain fol- low mean frame-wis tempor deriv basic featur remov meaning featur equal take differ valu last first frame mean featur relat energi audio power total loud sone first coeffici mfcc remov make classifi independ loudness/pow child ’ voic zero cross rate omit due depend nois environ second set featur use studi belalca ´zar-bolaño et al phonat featur like jitter shimmer jitter shimmer report discrimin asd link percept breathi hoars rough- ness featur use belalca ´zar-bolaño et al includ glottal featur relat vocal qualiti close veloc vocal fold mean logarithm energi featur omit reason energy-rel featur summari fea- ture ad remov set present tabl 4 propos subset instanc classifi explain propos classifi assum target group particip want distinguish rest particip call rest furthermor particip target group may sever instanc may use distinguish target group rest fig 1a show situat instanc particip target group differenti use common classifi call whole set instanc classifi figur circl repres target group triangl repres rest color code use differenti instanc particip group contrast situat fig 1a fig 1b target group easili dis- tinguish rest situat instanc two particip target group i.e red brown circl easili separ instanc rest furthermor particip instanc i.e orang circl easili tabl 4 featur statist ad remov two featur set featur removing/ad reason second set logarithm energi mean statist remov classif depend loudness/pow cri first set audio power total loud sone first mfcc coeffici zcr basic featur remov featur ’ depend environment nois basic featur applic mean frame-wis tempor deriv basic featur remov mean featur mfcc coeffici 14–24 ad higher-ord coeffici vocal cord inform well vocal tract spectral flat rang 125–250 hz ad cover low-frequ rang human voic http //doi.org/10.1371/journal.pone.0241690.t004 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 8 21 separ rest exampl case 1 tipto walk child asd common 25 child time exampl case 2 child asd tipto walk word child asd distinguish td child use tipto walk behavior factor appli wsi classifi may fail data type shown fig 1b consequ propos subset instanc classifi first find differenti instanc train classifi instanc exampl propos ssi classifi first tri find circl left line fig 1b use cluster method us circl exclus instanc specif featur common subset target group train classifi separ subset target group step common wsi classifi shown fig 2a step propos ssi classifi shown fig 2b ssi classif approach featur extract cluster step cluster classifi train separ exclus instanc instanc rest particip test phase particip one instanc classifi target group classifi target group ’ particip pseudo-cod propos approach given algorithm 1 2 algorithm 1 train ssi classifi set target group instanc r set rest instanc f set classifi ρ threshold number sampl cluster number minimum sampl need cluster abl train classifi cj jth cluster n number cluster f 1 9j |cj| ρ cluster bigger threshold n 1 2 n n 1 increas number cluster 3 cluster r n cluster cj j 1 n 4 ec cj \\x1a set cluster exclus instanc i.e exclus cluster fig 1 two differ hypothet type two-dimension data target group rest instanc shown warm-color circl cool-color triangl target group rest respect instanc belong particip color target group particip ’ instanc distinguish use classifi instanc target group particip separ instanc classifi http //doi.org/10.1371/journal.pone.0241690.g001 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 9 21 5 ec 6¼ check exclus cluster 6 cj ec |cj| 7 train classifi use posit label c \\x0f cj neg label r \\x0f r 8 add classifi f 9 ¼ \\x00 p cj\\x1aec cj remov instanc exclus cluster target group instanc 10 n 1 set 1 re-start cluster two group remain- ing instanc algorithm 2 test ssi classifi f set train classifi set subject instanc 1 instanc 2 p 2 a|9f classifi posit instanc 3 p 6¼ 4 particip target group 5 els 6 particip rest propos train algorithm ssi approach goal find cluster contain- ing asd instanc classifi train use instanc cluster fig 2 overal view wsi ssi method wsi method featur extract classifi train instanc major pool usual use test phase studi best-chanc threshold pool threshold-bas pool threshold give best accuraci test set also use give best chanc wsi classifi propos ssi classifi featur extract cluster appli find select exclus instanc contain instanc target group particip classifi train use exclus instanc particip classifi target group test phase classifi detect posit instanc http //doi.org/10.1371/journal.pone.0241690.g002 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 10 21 ad list train classifi shown loop algorithm start line 1 data cluster start two cluster num- ber cluster increas cluster contain target group instanc emerg exclus instanc cluster remov set target group ’ instanc loop restart restart loop number instanc cluster threshold new classifi use instanc train classifi ad set train classifi loop stop number sam- ple cluster le threshold test particip use train classifi instanc particip classifi one one use train classifi subject would classifi target group least one instanc classifi target group least one classifi otherwis instanc classifi among target group particip classifi rest detail implement classifi implement python use scikit-learn librari wsi classifi test sever common wsi classifi report result svm rbf kernel featur select give best averag accuraci note sever featur select approach like l1-svm back- ward elimin test reduc accuraci use group 5-fold cross- valid tune hyper-paramet group k-fold mean instanc partici- pant place one fold prevent particip ’ instanc train valid fold simultan fold two asd two td particip mention appli algorithm balanc number instanc two group use upsampl two approach exploit combin decis differ sampl partici- pant wsi approach first approach major pool classifi partici- pant asd number instanc classifi asd 50 percent instanc second approach threshold-bas pool similar first approach except threshold 50 use ssi classifi appli algorithm balanc number instanc two group upsampl threshold minimum number sampl need cluster abl train classifi set 10 mention agglom cluster decis tree method use cluster classif part algorithm 1 respect train ssi classifi run algorithm 1 data two exclus clus- ter enough instanc i.e least 10 instanc studi found two classifi- er train correspond cluster one exclus cluster 11 instanc 4 asd particip 11 instanc consist 6 9 instanc asd1 2 4 instanc asd10 1 2 instanc asd8 2 4 instanc asd6 explain algorithm cluster decis tree classifi train use asd instanc cluster versu td instanc interestingli one featur enough discrimin instanc cluster td instanc among featur discrimin cluster ’ instanc select varianc frame- wise tempor deriv 7th mfcc coeffici featur dis- crimin asd particip set particip simpl threshold classifi obtain set threshold base featur first classifi fea- ture support expert ’ report regard higher variat cri sound asd plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 11 21 child td child 10 asd child 8 discrimin use featur particip number instanc found classifi shown 2nd column tabl 5 exclud asd sampl first classifi second classifi train base second exclus cluster cluster includ instanc particip asd4 featur use classifi cluster vftd 6th sone coeffici sone unit loud subject percept sound pressur higher vftd 6th sone coeffici confirm experienti knowledg expert men- tion among asd particip eight instanc vftd 6th sone higher threshold result classifica- tion base two featur depict fig 3 mention propos method section particip least one instanc classifi cluster would consid- ere particip asd result part perform propos ssi classifi common wsi classifi evalu test set asd td particip particip multipl instanc clean use criterion explain data collect preprocess section particip least one accept instanc use train test phase shown tabl 1 2 output ssi approach two classifi work set thresh- old base featur number instanc asd particip train set cor- rectli detect first second classifi shown second third column tabl 5 respect hand best-result classifi wsi approach radial basi function-support vector machin classif result test set differ classifi shown tabl 6 portion particip ’ instanc correctli classifi classifi written percentag name classifi decis made wsi ssi classifi- er particip shown asd td classifi subject use wsi clas- sifier major pool best-chanc threshold pool approach use bp threshold-bas pool threshold give best accuraci test set male particip boy mp specif sensit precis equal 100 35.71 67.85 respect hand bp lead specif sensit precis equal 85.71 71.42 78.57 respect threshold tabl 5 number instanc particip train set classifi asd use train ssi classifi id first ssi classifi second ssi classifi asd1 8 3 asd2 1 2 asd3 3 1 asd4 10 9 asd5 0 0 asd6 1 3 asd7 1 0 asd8 1 2 asd9 0 1 asd10 2 4 http //doi.org/10.1371/journal.pone.0241690.t005 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 12 21 bp set 20 mean 20 instanc particip classifi asd instanc particip classifi asd result percentag instanc correctli classifi two classifi ssi approach shown c1 first ssi classifi c2 tabl 6 aggreg result decis c1 c2 make final decis ssi classifi shown decis column ssi classif section achiev specif sensit precis use propos method boy 100 85.71 92.85 respect show applic propos approach girl appli boy ’ train classifi test set girl result shown last row tabl 6 show mp approach specif sensit precis equal 100 71.42 85.71 respect furthermor bp approach give specif sensit precis equal 85.71 respect result propos ssi classifi 100 specif 71.42 sensit 85.71 precis two-dimension scatter plot two featur use c1 c2 classifi shown fig 4 seen figur instanc particip asd scatter area contain instanc td asd particip nevertheless instanc particip uniqu distinguish use select two featur compar result propos method method avail literatur train use cri featur base data result show superior method compar previous propos method investig train classifi particip 18 month ssi classifi train use train set tabl 1 also test data child younger 18 month 57 particip 18 month two boy classifi asd mention train classifi particip refer expert diagnosi two suspect neurodevelopment problem boy classifi td howev among child3 diagnos asd age 2 also child4 show fig 3 two classifi train two exclus cluster found ssi classifi train phase varianc frame-wis tempor deriv 7th mfcc coeffici separ 27 instanc 8 asd subject td instanc train set vftd 6th sone coeffici separ 17 instanc 7 asd particip td instanc train set http //doi.org/10.1371/journal.pone.0241690.g003 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 13 21 symptom adhd sensori process disord age 3 three child symptom suggest td child two girl 18 month old classifi asd use train classifi girl classifi td result test train ssi classifi data set summar tabl 8 origin clean voic extract featur research implement code propos method deposit follow repositori codeocean 10.24433/co.0622770.v1 harvard datavers 10.7910/dvn/lstbqw tabl 6 result classifi instanc particip test set td child child asd id portion instanc classifi td percentag decis id portion instanc classifi asd percentag decis wsi classif ssi classif wsi classif ssi classif svm dec. c1 c2 dec. svm dec. c1 c2 dec. mp bp mp bp boy td11 100 td td 100 100 td asd11 50 asd asd 17 50 asd td12 100 td td 100 100 td asd12 33 td asd 11 28 asd td13 100 td td 100 100 td asd13 33 td asd 33 0 asd td14 100 td td 100 100 td asd14 20 td asd 20 20 asd td15 100 td td 100 100 td asd15 0 td td 0 40 asd td16 100 td td 100 100 td asd16 50 asd asd 100 0 asd td17 100 td td 100 100 td asd17 0 td td 0 100 asd td18 83 td td 100 100 td asd18 50 asd asd 50 50 asd td19 100 td td 100 100 td asd19 0 td td 0 0 td td20 80 td asd 100 100 td asd20 42 td asd 42 16 asd td21 100 td td 100 100 td asd21 100 asd asd 0 0 td td22 100 td td 100 100 td asd22 0 td td 0 50 asd td23 75 td asd 100 100 td asd23 33 td asd 33 17 asd td24 92 td td 100 100 td asd24 86 asd asd 86 86 asd acc 100 85.71 100 35.71 71.42 85.71 girl td25 100 td td 100 100 td asd25 42 td asd 17 0 asd td26 100 td td 100 100 td asd26 60 asd asd 60 20 asd td27 100 td td 100 100 td asd27 50 asd asd 0 0 td td28 100 td td 100 100 td asd28 100 asd asd 0 50 asd td29 100 td td 100 100 td asd29 62 asd asd 50 50 asd td30 67 td asd 100 100 td asd30 100 asd asd 50 50 asd td31 100 td td 100 100 td asd31 0 td td 0 0 td acc 100 85.71 100 71.42 85.71 71.42 classifi result particip ’ instanc report percentag dec. decis mp major pool bc best-chanc threshold pool c1 classifier1 c2 classifier2 acc. accuraci http //doi.org/10.1371/journal.pone.0241690.t006 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 14 21 discuss conclus paper present novel cry-bas screen method distinguish chil- dren autism typic develop child propos method group chil- dren autism specif featur cri sound determin method base new classif approach call subset instanc classifi appeal properti propos ssi classifi case voice-bas autism screen high specif normal child detect error appli propos method group particip consist 24 boy asd 20 fig 4 instanc sever asd td particip scatter space two featur given propos ssi method instanc chosen asd particip illustr green show particip may instanc area common td instanc besid two area separ select threshold asd mention asd particip tag asd due least one instanc greater valu least one threshold two featur http //doi.org/10.1371/journal.pone.0241690.g004 tabl 7 comparison result test set use two method ssi approach baselin approach sensit specif precis boy ssi 85.71 100 92.85 baselin 50.58 81 65 girl ssi 71.42 100 85.71 baselin 21 86.48 53 http //doi.org/10.1371/journal.pone.0241690.t007 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 15 21 53 month age 24 td boy 18 51 month age two featur found studi use train classifi 10 boy asd 10 td boy classifi use distinguish 14 boy asd 14 td boy reach 92.8 accuraci due fact girl le like autism consequ harder collect enough data girl boy number girl asd suffici train separ classifi gender note test train system 7 girl asd 7 td girl seen train classifi screen girl 7 lower accuraci boy test set word seem gender differ consid train system test data particip 18 month one td girl classifi asd case td child male counterpart result also confirm aforement point gender effect howev futur work would tri collect data girl abl train system accur screen girl furthermor would also tri train singl classifi boy girl determin whether use mention train test data complet separ make train model gener featur found studi applic age rang particip 18 53 month contrast approach either use dataset child specif age 33 35 use age inform classifi- cation due age invari featur found studi claim marker voic child asd sustain least rang age two discrimin featur found studi coeffici mfcc sone coeffici mfcc sone relat power spectrum speech signal sone mea- sure loud specif bark band hand mfcc invers dft log-spectrum mel scale relat timbr voic therefor mfcc sone interpret relat timbr loud tone furthermor base feedback expert unpredict cri sound child autism case td child consequ use varianc tempor differ featur suitabl screen child autism due fact signal constant chang linearli time varianc tempor differ zero therefor varianc tempor differ seen amount ambigu unpre- dictabl sound hand heighten variabl two featur found studi child asd signific due report studi 22 61 show increas biolog signal variabl child asd infant high risk autism comparison td child featur statist featur cri instanc hold constant least across age rang studi research best knowledg studi screen child autism use voic featur child younger 2 year age propos method higher precis two i.e 6 17 use cri featur use cri featur suitabl biomark autism screen match claim tabl 8 classif particip 18 month use train ssi classifi boy girl asd td othersa asd td othersa classifi asd 0 0 2 0 1 0 classifi td 1 22 4 0 27 0 development mental disord http //doi.org/10.1371/journal.pone.0241690.t008 plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 16 21 present studi child asd td child test develop- mental disord health issu test see child disord would classifi use propos method decreas specif 100 howev approach propos use screen tool final diagnosi done expert ’ supervis approach appli gener screener autism spectrum disord train classifi also test 57 particip 10 18 month age classifi screen two boy rest i.e child1 child2 child1 show evi- denc genet diseas diagnos development delay child2 receiv undd classif expert suggest system use child 2 year age b may abl distinguish neurodevelopment disord hand 5 boy i.e child3 child7 evid mental development disord time record time approach distinguish child asd either howev older 3 year show symptom neurodevelopment disord child could manag collect new record child3 child4 classifi child asd use approach unfortun child5 child6 child7 cooper could evalu expert valid result expert-select questionnair furthermor parent refus cooper send u child ’ recent cri sound result studi 57 child age 18 month may suggest could symptom cri sound child neurodevelopment disord 18 month b approach may abl screen particip neurodevelopment disord age 18 month due possibl 1 particip among child neurodevelopment disord propos specif featur cri sound 2 particip ’ record cri sampl includ specif featur and/or 3 neurodevelopment disord featur develop child time initi record reason behind classifi child3 child4 child asd age 18 could b.2 b.3 clearli determin reason behind phenomenon investig need believ approach use perform earli autism screen 18 month age thu futur need collect data test approach data child 18 month valid result confid check propos approach extract featur neuro- development disord adhd evalu capabl approach distin- guish child disord td child furthermor without compar cri sound child asd without asd anoth disord realli know find specif autism gener atyp brain develop thu collect cri sound child neurodevelopment disord compar voic child asd voic child neurodevelopment disord see featur would abl separ demonstr cri consist intric motor activ hand shown child asd problem motor domain coordin motor capabl modal consequ possibl extract featur cri sound child asd come defi- ciency/problem motor domain requir investig final autom preprocess part technic issu address deem necessari cry-bas screen fulli autom import sinc plo one earli screen autism use cri featur plo one http //doi.org/10.1371/journal.pone.0241690 decemb 10 2020 17 21 screen system deploy system amazon alexa automati- calli screen problemat cri sound acknowledg would like thank center treatment autism disord mem- ber support studi would also like thank famili help research take time collect cri sound child author would also like express gratitud prof. h. sameti sharif univers technolog valuabl construct feedback data collect voic process author contribut conceptu aida khozaei hadi moradi reshad hosseini hamidreza pouretemad bahareh eskandari data curat aida khozaei formal analysi aida khozaei fund acquisit hadi moradi investig hadi moradi methodolog aida khozaei project administr hadi moradi softwar aida khozaei supervis hadi moradi valid aida khozaei visual aida khozaei write – origin draft aida khozaei hadi moradi reshad hosseini write – review edit aida khozaei hadi moradi reshad hosseini hamidreza poure- temad bahareh eskandari', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0c9eee70-e6f8-4b95-9a91-22ae15fffe39', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Dawson_cleaned.txt', 'file_name': 'Dawson_cleaned.txt', 'file_type': 'text/plain', 'file_size': 17145, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1 scientif report 8:17008 doi:10.1038/s41598-018-35215-8 www.nature.com/scientificreport atyp postur control detect via comput vision analysi toddler autism spectrum disord geraldin dawson 1 kathleen campbell2 jordan hashemi1,3 steven j. lippmann 4 valeri smith4 kimberli carpenter1 helen egger5 steven espinosa3 saritha vermeer1 jeffrey baker6 guillermo sapiro3,7 evid suggest differ motor function earli featur autism spectrum disord one aspect motor abil develop childhood postur control reflect abil maintain steadi head bodi posit without excess sway observ studi document differ postur control older child asd present studi use comput vision analysi ass midlin head postur control reflect rate spontan head movement state activ attent 104 toddler 16–31 month age mean 22 month 22 diagnos asd time-seri data reveal robust group differ rate head movement toddler watch movi depict social nonsoci stimulu toddler asd exhibit significantli higher rate head movement compar non-asd toddler suggest difficulti maintain midlin posit head engag attent system use digit phenotyp approach comput vision analysi quantifi variat earli motor behavior allow precis object quantit character earli motor signatur potenti provid new autom method earli autism risk identif although core symptom autism spectrum disord defin atyp pattern social inter- action presenc stereotyp repetit behavior interest evid suggest differ motor function also import earli featur autism motor delay could contribut earli hall- mark autism symptom includ difficulti orient name involv eye head turn coordinat- ing head limb movement involv gaze follow joint attent behavior point teitelbaum et al.1 found atyp movement present 4–6 month age infant later diagnos asd anoth studi videotap taken infant 12–21 week age detect lower level posit symmetri among infant later diagnos asd2 sug- gest atyp develop cerebellar pathway control balanc symmetri six-month-old infant later diagnos asd tend exhibit head lag pull sit reflect earli differ motor development3 studi home video taken birth six month age found infant later diagnos asd show postur stiff slump postur and/or head lag4 motor symptom observ infant later diagnos asd includ fluctuat muscl tone5 oral-motor abnor- maliti insuffici open mouth anticip approach spoon feeding6 longitudin research low birth weight infant reveal infant later diagnos asd poorer abil maintain midlin posit head 9–20 week age7 author use visual 1duke center autism brain develop depart psychiatri behavior scienc duke univers durham north carolina usa 2univers utah salt lake citi utah usa 3depart electr comput engin duke univers durham north carolina usa 4depart popul health scienc duke univers durham north carolina usa 5nyu langon child studi center new york univers new york new york usa 6depart pediatr duke univers durham nc usa 7depart biomed engin comput scienc mathemat duke univers durham nc usa correspond request materi address g.d receiv 26 juli 2018 accept 31 octob 2018 publish onlin 19 novemb 2018 open correct author correct www.nature.com/scientificreports/ 2 scientif report 8:17008 doi:10.1038/s41598-018-35215-8 inspect classifi head posit video frame yield measur midlin head posit number chang posit develop postur control index neuromuscular reaction motion bodi mass order retain stabil previou studi document development progress abil main- tain upright postur accompani decreas postur sway8 sever studi older child asd document defici postur control reflect presenc postur sway accentu child asd view arous stimulu includ complex multi-sensori social stimuli9–11 le known presenc postur sway young child asd studi motor behavior young child typic reli subject labor-intens human code rate measur behavior recent use digit phenotyp approach comput vision analysi videotap record behavior allow autom precis quantit measur subtl dynam differ motor behavior report previous result use cva precis measur toddler ’ orient respons name call note compar toddler without asd toddler asd orient le frequent orient head turn full second slower average12 differ motor speed would like detect nake eye typic clinic evalu anzulewicz et al.13 use smart tablet comput touch-sensit screen embed inerti movement sensor record movement kinemat gestur forc 3–6-year-old child without asd child asd use greater forc faster larger gestur kinemat machin learn analysi child ’ motor pattern classifi child asd high level accuraci anoth studi use autom method differ head movement dynam found 2.5–6.5-year-old child without asd watch movi social nonsoci stimulu child asd show frequent head turn especi watch social stimuli14 author suggest child asd might use head movement modul arous watch social stimulu wu et al.15 use electromagnet sensor analyz continu movement millisecond time scale older child asd versu typic develop appli triangular smooth algorithm 3d posit raw move- ment data preserv local speed fluctuat found individu asd exhibit signifi- cantli “ sensorimotor nois ” compar individu typic develop present studi use cva character head movement ’ involv spontan volit orient turn away stimulu rather interest subtler midlin head movement like relat postur stabil studi compar behavior toddler asd versu without asd child watch seri dynam movi involv differ type stimulu includ- ing stimulu social nonsoci natur child watch movi head movement automat detect track use landmark particip ’ face goal analysi quantifi rate spontan head movement determin whether differ motor featur young child without asd method particip particip 104 child 16–31 month age exclusionari criterion includ known vision hear deficit lack exposur english home and/or car- egiv speak read english suffici inform consent twenty-two child autism spectrum disord non-asd comparison group compris 96 typic develop child 8 child languag delay development delay clinic signific suffici qualifi speech development therapi particip comparison group mean age 21.91 month asd group mean age 26.19 month ethnic/raci composit asd comparison group respect 59 45 white 13 14 african american 6 5 asian 22 36 multi-racial/oth percent male 77 asd group 59 comparison group particip recruit primari care pediatr clinic research assist referr phy- sician commun advertis caregivers/leg guardian particip gave written inform consent studi protocol approv duke univers health system institut review board method carri accord institut state feder guidelin regul diagnost assess diagnost evalu confirm asd base autism diagnost observ scale-toddl conduct licens psychologist train research-reli examin overseen licens psychologist16 mean ados-t score 18.81 mean iq base mullen scale earli learn composit score asd group 63.58 development and/or languag delay determin base mullen scale 1 sd mean overal learn composit receptive/express languag stimulu seri stimulu compris brief movi shown smart tablet child sat caregiv ’ lap tablet place stand approxim 3 foot away child prevent child touch screen stimulu consist seri brief developmentally-appropri movi design elicit posit affect engag child ’ attent movi consist cascad bubbl mechan bunni anim puppet interact split screen show one side woman sing nurseri rhyme side dynam noise-mak toy length movi 30 second 60 second ∼70 second movi shown except bubbl shown begin end seri entir seri movi last 5 minut exampl stimulu experiment setup present fig 1 describ two previou publi- cations17 exampl clip movi provid supplementari materi three movi examin stand behind child call child ’ name failur orient name earli www.nature.com/scientificreports/ 3 scientif report 8:17008 doi:10.1038/s41598-018-35215-8 symptom autism result analysi orient result previous published12 howev segment child look away movi includ orient name well 5 second seg- ment post name-cal stimulu automat remov present analysi specif order remov influenc head movement due child orient name call remov time window start cue name call prompt subtl icon use prompt examin call name point 75 audibl name call actual occur plu 150 frame sinc previou studi shown orient tend occur within second name call elim- inat segment influenc name call parent ask attempt keep child seat lap allow child get lap child becam distress stay seat research stop task 1 child due cri research restart task three particip due noncompli comput vision analysi frontal camera tablet record video child ’ face throughout experi 1280 × 720 spatial resolut 30 frame per second fulli automat cva algorithm detect track 49 facial landmark child ’ face 18 estim head pose angl rel camera comput optim rotat paramet detect landmark 3d canon face model19 video frame algorithm output 2d posit coordin facial landmark 3 head pose angl yaw pitch roll yaw head pose angl use determin frame child engag movi stimulu frame exhibit yaw pose magnitud le 20° consid child engag follow work of17 quantifi head movement child engag per-fram pixel-wis displac 3 central facial landmark comput normal respect child ’ eye width thu head movement measur proport child ’ eye width per frame pixel-wis displac central facial landmark depend child ’ distanc camera tablet although tablet place approxim 3 foot away child start experi- ment child free move throughout experi thu affect magnitud landmark displace- ment child near camera pixel displac larger child movement farther away camera normal displac respect eye-width diminish distanc camera depend formal head movement frame n n-1 defin averag euclidean displac central nose left inner eye right inner eye landmark normal ± second windowed-averag center around frame n euclidean distanc inner left right eye landmark − − w n n n n 1 15 15 figur 1. ipad movi task facial landmark detect two exampl facial landmark point detect cva estim head pose landmark color red inner left inner right central nose landmark use head movement comput left exampl depict landmark head pose particip engag movi stimulu right exampl particip look away state automat detect exampl frame movi stimulu row display frame correspond movi stimulu show column bubbl bunni rhyme puppet show www.nature.com/scientificreports/ 4 scientif report 8:17008 doi:10.1038/s41598-018-35215-8 − dn n 1 averag landmark displac three central landmark frame n n-1 − w n n 15 15 averag euclidean distanc left right eye landmark child engag half-second frame n. result evalu valid cva method reli landmark identif track face previous publish one studi demonstr high reliabl automat method expert human rater head movement agreement comput expert clinic rater occur 92.5 time interrat reliabl base cohen ’ kappa 0.7520 second studi compar automat classif base landmark human coder head movement demonstr inter-rat reliabl base intraclass correl coeffici 0.8917 paper report high reliabl cva human code head turn respons name 12 posit affect express 21 origin dataset consist frame-by-fram measur head movement observ 1/30th second group interest direct use data via collabor author due privaci consent consider well backend design data store separ partit duke univers order prepar data statist analysi first aggreg move- ment measur calcul head movement rate defin move sum cumul frame-by-fram movement measur 10 frame period indi- vidual frame within 10-frame set set miss facial landmark visibl name-cal period move sum also set miss outlier address winsor 95th percentil prior aggreg statist analysi perform separ movi stimulu visual time seri calcul plot median head movement rate well 1st 3rd quartil 1/3 second time interv asd non-asd child unadjust adjust rate ratio associ asd diagnosi rate head move- ment 1/3 second time interv estim use gener linear mix log-gamma regress model adjust estim control ethnicity/rac age sex account potenti within-subject correl due repeat measur includ random intercept particip result time seri data depict rate head movement defin distanc travel per 1/3 second 10 videofram asd non-asd group shown fig. 2 base gener linear mix regress model log link gamma distribut adjust ethnicity/rac age sex signific associ diagnost group rate head movement found movi except bubbl 2 last movi bubbl 2 shorter durat might affect power detect result nevertheless trend toward group differ direct movi result analysi shown tabl 1 robust group differ rate head movement evid 4 5 movi exampl rate head movement among particip asd 2.22 time non-asd particip bunni movi adjust age ethnicity/rac sex rate ratio higher movi anim complex stimulu bunni puppet rhyme toy compar le complex bubbl video although ld/dd group small conduct independ analysi group sensit anal- ysi 8 patient ld/dd main regress model re-estim associ shown tabl 2 overal result consist report main analysi fact associ slightli stronger ld/dd group remov non-asd group discuss present studi add larg grow bodi literatur indic differ earli motor devel- opment import featur asd found highli signific differ postur control reflect differ rate spontan movement head toddler asd versu without asd use autom object approach analyz data compris video-frame-level measur head movement observ 1/30th second creat 10-frame move sum captur movement time-seri data reveal group differ rate head movement across movi repre- sent wide rang stimulu bubbl hop bunni woman sing nurseri rhyme pair dynam toy increas rate head movement observ young child asd state engag attent might indic underli differ abil maintain midlin postur con- trol and/or atyp engag attent system young toddler asd movement defin spontan look away stimulu report martin et al.14 rather character failur keep head still midlin posit view movi distinct featur studi martin et al. character greater yaw angular displac greater yaw roll angular veloc primarili present present social stimulu might reflect sensori modul movement describ paper may similar describ previou studi postur sway older child asd well school age child attent deficit hyperact disord heiser et al.22 heiser et al use infrar motion analysi record head movement continu perform task found boy adhd move head 2.3 time far typically-develop boy perform task studi sibl child asd reiersen colleagues23 found sibl impair motor coordin featur attent deficit hyperact disord much like asd sibl suggest www.nature.com/scientificreports/ 5 scientif report 8:17008 doi:10.1038/s41598-018-35215-8 identif nonspecif trait amplifi risk asd attent motor differ could allow earlier identif target therapi modifi trait potenti reduc later risk asd delay differ sensorimotor develop note across lifespan individu asd earli infanc adulthood24 exampl lim et al show postur sway attent demand postur control larger adult asd typic develop adults25 morri et al found adult asd use visual inform control stand postur contrast adult without asd26 brain imag studi suggest atyp motor function autism may relat increas figur 2 time seri head movement rate measur distanc travel per 1/3 second 10 video frame asd diagnosi solid line median valu time point band repres first third quartil time point blank section repres name call remov analysi movi unadjust adjust rate ratio 95 confid interv asd v non-asd p-valu rate ratio 95 confid interv asd v non-asd p-valu video bubbl 1 1.46 0.011 1.53 0.012 video bunni 2.13 0.0001 2.22 0.0001 video puppet 2.08 0.0001 2.30 0.0001 video rhyme toy 2.37 0.0001 2.45 0.0001 video bubbl 2 1.52 0.018 1.43 0.070 tabl 1 unadjust adjust rate ratio associ diagnost group rate head movement www.nature.com/scientificreports/ 6 scientif report 8:17008 doi:10.1038/s41598-018-35215-8 sensit propriocept error decreas sensit visual error aspect motor learn depend cerebellum27 atyp present motor function cerebellum note child asd young 14 month age esposito et al identifi signific differ gait pattern reflect postur asymmetri toddler asd compar without asd28 sampl toddler asd recruit primari pediatr care child suspect autism evalu use gold-standard diagnost method although method recruit- ment increas likelihood obtain repres population-bas sampl also result comparison group toddler without asd much larger asd sampl sampl asd toddler studi rel small import replic find larger group child larger sampl would also provid statist power examin whether differ postur control exist base individu characterist child asd age sex co-morbid intellectu disabl and/or adhd previou analysi motor differ associ asd often requir labor-intens code pattern behavior recogniz nake eye moreov studi typic use “ top ” approach specif behavior interest defin rate one person relia- biliti assess use digit phenotyp offer multipl advantag previou method reli human code name abil automat object measur dynam featur behavior spatiotempor scale easili percept nake eye digit approach scalabl also allow collect larger data set analyz use machin learn anticip use digit phenotyp reveal number object biomark head movement describ report use earli risk index target intervent combin multipl fea- ture reflect differ aspect sensorimotor function includ pattern facial expressiomn orient midlin head movement reach behavior other might possibl creat reliabl object autom risk profil asd neurodevelopment disord', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5d2f0e4f-2a06-4739-bba2-61398ecf501c', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/LEE_cleaned.txt', 'file_name': 'LEE_cleaned.txt', 'file_type': 'text/plain', 'file_size': 22856, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='sensor letter deep-learning-bas detect infant autism spectrum disord use auto-encod featur represent jung hyuk lee 1 geon woo lee 1 guiyoung bong 2 hee jeong yoo 2,3 hong kook kim 1 1 school electr engin comput scienc gwangju institut scienc technolog gwangju 61005 korea ljh0412 gist.ac.kr geonwoo0801 gist.ac.kr 2 depart psychiatri seoul nation univers bundang hospit seongnam-si gyeonggi-do 13620 korea 20409 snubh.org hjyoo snu.ac.kr 3 depart psychiatri colleg medicin seoul nation univers seoul 03980 korea correspond hongkook gist.ac.kr receiv 29 octob 2020 accept 24 novemb 2020 publish 26 novemb 2020 \\x01\\x02\\x03\\x01\\x04\\x05\\x06\\x07\\x08\\x01 \\x01\\x02\\x03\\x04\\x05\\x06\\x07 abstract autism spectrum disord development disord life-span disabl diagnost instrument develop qualiﬁ base accuraci discrimin child asd typic develop child stabil procedur disrupt limit pertain time expens subject clinician consequ autom diagnost method develop acquir object measur autism variou ﬁeld research vocal characterist report distinct characterist clinician also shown promis perform sever studi util deep learn model base autom discrimin child asd child td howev diﬃculti still exist term characterist data complex analysi lack arrang data caus low access diagnosi need secur anonym order address issu introduc pre-train featur extract auto-encod model joint optim scheme achiev robust wide distribut unreﬁn data use deep-learning-bas method detect autism util variou model adopt auto-encoder-bas featur extract joint optim extend version geneva minimalist acoust paramet set speech featur data set acquir improv perform detect asd infant compar raw data set keyword auto-encod bidirect long short-term memori joint optim acoust featur extract autism spectrum disord 1 introduct autism spectrum disord development disord high probabl caus diﬃculti social interact peopl accord diagnost statist manual mental disord fifth edit asd involv sever characterist conﬁn speciﬁc interest behavior delay linguist develop poor function term commun function social situat wide variat term type sever asd base characterist disord refer spectrum asd characterist development disord life-span disabl preval also increasing—from 1 150 child 2000 1 54 child 2016 divers evid obtain previou research show chanc improv sensor 2020 20 6762 doi:10.3390/s20236762 www.mdpi.com/journal/sensor sensor 2020 20 6762 2 11 social abil peopl asd increas earlier clinic intervent perform earli detect asd characterist becom key point current asd research variou instrument discrimin asd develop commonli accept gold standard scheme behavior assess time-consum procedur requir multidisciplinari team howev behavior assess suﬀer term stabil asd diagnosi result issu access subject interpret bia profess therefor sever attempt develop object precis diagnost method made multipl ﬁeld genet determin principl analysi brain imag physiolog approach one promin area behavior observ infant ’ vocal characterist child asd known abnorm prosodi result deﬁcit abil recogn inher mental condit other atyp vocal known monoton exagger reveal use variou acoust characterist follow engin approach discrimin asd typic develop child base vocal acoust featur exampl research estim deﬁcit vocal child asd averag age 18 month “ ﬂat ” inton atyp pitch control volum base variabl pitch long-term averag spectrum use fast fourier transform signiﬁc diﬀer observ spectral compon low-band frequenc well spectral peak larger pitch rang standard deviat develop linguist abil also consid distinguish featur delay develop child asd earlier vocal pattern age 6–18 month proven diﬀerenti studi aim conﬁrm hypothet vocal pattern social qualiti vocal behavior order diﬀerenti asd td cohort group child age 0–6 6–12 12–18 month term categor speech pattern consist vocal long redupl babbl two-syl babbl ﬁrst word evid abnorm child asd shown case signiﬁc decreas vocal ﬁrst word rate diﬀer babbl abil child asd td neglig given develop improv machin learn algorithm achiev perform state-of-the-art classiﬁc discrimin task recent attempt develop autom classiﬁc method base machin learn techniqu base distinct vocal characterist shown promis altern convent method mani public exampl machin learn classiﬁc research employ variou acoustic–prosod featur includ fundament frequenc formant frequenc harmon root mean squar signal energi research support vector machin probabilist neural network adopt classiﬁ show eﬀectu accuraci discrimin child asd child td meanwhil author employ recent deep learn techniqu convolut neural network recurr neural network spectral featur short-tim fourier transform constant q transform classifi child diagnos use autism diagnost observ schedul also show promis result multipl outcom svm rnn combin cnn rnn classiﬁ gener acoust featur set extend version geneva minimalist acoust paramet set bidirect long short-term memori model adopt diﬀerenti child asd child td show 75 subject ’ utter correctli classiﬁ simpl applic deep learn model featur set qualiti previou research base variou acoust featur proven eﬀect acoust featur classiﬁc algorithm detect abnorm child ’ voic asd group compar td group complex relationship inher featur remain uncertain larg amount data accumul furthermor limit still remain term problem regard data collect sinc sensor 2020 20 6762 3 11 diﬃculti pertain need secur anonym infant subject well unintend ignor parent earlier stage infant ’ develop data infant accordingli dispers gender age number vocal consist compar small volum audio engin data gener problem typic overlook previou research control small amount data order provid suggest method overcom abovement restrict focu examin feasibl neural network featur extractor employ auto-encod modifi acoust featur lower separ featur dimens construct simpl six-lay stack ae contain input layer three fulli connect layer output layer one auxiliari output layer categor target asd td optim latent featur space ae train ae deep learn model compar result model base svm vanilla blstm adopt model paramet method suggest remaind paper organ follow section 2 describ speciﬁc particip ’ data data process featur extract statist analysi experiment setup section 3 present perform evalu algorithm svm vanilla blstm lastli section 4 conclud paper 2 propos method 2.1 data collect acoust featur extract studi base audio data video record asd diagnosi collect 2016 2018 seoul nation univers bundang hospit receiv approv institut review board snubh use fulli anonym data retrospect analysi exist research collect audio data 39 infant assess use seven multipl instrument consist ado second edit autism diagnost interview revis behavior develop screen toddler interview behavior develop screen toddler play korean version childhood autism rate scale reﬁn cars-2 social commun questionnair social respons scale 19–22 ﬁnal diagnosi base best clinic estim diagnosi accord dsm-5 asd criterion licens child psychiatrist use avail particip inform particip ’ age rang 6 24 month averag age 19.20 month standard deviat 2.52 month note age mean age time infant visit hospit undergo initi diagnosi examin four male six femal diagnos asd whose averag age 14.72 month sd 2.45 remain particip consist td child tabl 1 display collect data distribut tabl 2 show detail inform collect data infant tabl 1 distribut age gender age subject diagnos asd subject diagnos td infant subject 6–12 month 0 5 m/1 f 5 m/1 f 12–18 month 1 m/3 f 14 m/9 f 15 m/12 f 18–24 month 3 m/3 f 0 3 m/3 f age 19.20 ± 2.52 14.72 ± 2.45 15.92 ± 3.17 sensor 2020 20 6762 4 11 tabl 2 detail inform age gender initi deﬁnit diagnosi date infant tabl 1 infant id age initi diagnosi date gender initi diagnosi date deﬁnit final diagnosi date asd/td 1 18 male 2018/07/28 2018/08/28 td 2 18 male 2017/07/27 2017/08/27 td 3 10 male 2018/08/10 2018/09/10 td 4 13 male 2017/06/10 2017/07/10 td 5 22 femal 2018/01/31 2018/02/28 asd 6 16 male 2018/03/17 2018/04/17 td 7 17 femal 2018/06/30 2018/07/30 td 8 14 femal 2018/01/06 2018/02/06 td 9 18 male 2018/07/17 2018/08/17 td 10 14 male 2017/11/04 2017/12/04 td 11 17 femal 2017/06/29 2017/07/29 asd 12 12 femal 2018/01/20 2018/02/20 td 13 9 male 2017/02/18 2017/03/18 td 14 18 femal 2017/03/04 2017/04/04 asd 15 18 male 2018/05/19 2018/06/19 td 16 24 femal 2018/08/08 2018/09/08 asd 17 19 male 2018/02/24 2018/03/24 asd 18 19 male 2017/04/18 2017/05/18 asd 19 18 femal 2017/03/04 2017/04/04 td 20 12 male 2016/12/31 2017/01/31 td 21 16 femal 2018/03/16 2018/04/16 td 22 20 male 2017/10/14 2017/11/14 asd 23 15 male 2018/05/09 2018/06/09 asd 24 17 femal 2017/02/04 2017/03/04 td 25 16 male 2018/03/17 2018/04/17 td 26 12 male 2018/03/29 2018/04/29 td 27 17 femal 2017/01/25 2017/02/25 td 28 17 male 2018/02/08 2018/03/08 asd 29 14 male 2018/01/13 2018/02/13 td 30 16 male 2016/11/30 2016/12/30 td 31 12 male 2017/03/22 2017/04/22 td 32 15 male 2017/03/11 2017/04/11 td 33 16 male 2017/12/05 2018/01/05 td 34 13 femal 2017/12/13 2018/01/13 td 35 15 femal 2017/03/25 2018/04/25 td 36 13 male 2018/08/25 2018/09/25 td 37 21 male 2017/06/24 2017/07/24 asd 38 14 male 2017/02/22 2017/03/22 td 39 14 male 2018/01/27 2018/02/27 td infant ’ audio data record clinic procedur elicit behavior infant attend one doctor clinician one parent child clinic area audio compon consist variou speech child clinician parent well nois toy drag chair note record done one two typic clinic room snubh room dimens 365 cm × 400 cm × 270 cm 350 cm × 350 cm × 270 cm hospit nois level around 40 db order analyz vocal characterist infant audio clip process split audio segment contain infant ’ voic disturb music clatter nois toy overlap voic clinician parent segment classiﬁ one ﬁve categori label 0 4 measur data distribut label intend show diﬀerenti characterist rel child ’ linguist develop 0 one syllabl short sensor 2020 20 6762 5 11 momentari singl vocal “ ah ” “ ba ” 1 two syllabl commonli denot canon babbl redupl clear babbl two ident variant syllabl “ baba ” “ baga ” 2 babbl contain syllabl 3 ﬁrst word “ mother ” “ father ” 4 atyp voic includ scream cri distribut type vocal second shown tabl 3 number vocal per categori present along ration valu consid diﬀer asd td group data unbalanc small distribut asd td vocal show tendenc report asd group show signiﬁcantli lower ratio ﬁrst word increas ratio atyp vocal reveal development delay linguist abil tabl 3 amount type vocal second vocal label asd td 0 80.134 267.897 1 314.405 443.498 2 33.241 34.766 3 8.311 57.286 4 333.400 266.794 total 769.491 1070.241 acquir qualiﬁ eﬀect featur set vocal data egemap employ voic featur extract gemap popular featur set provid minimalist speech featur gener util automat voic analysi rather larg brute forc paramet set extend version egemap contain 88 acoust featur fulli util experi record set audio data store 48 khz stereo ﬁle down-sampl down-mix 16 khz mono-audio ﬁle take consider usabl resolut mel-frequ cepstral coeﬃcient extract speech featur asd classiﬁc infant ’ utter segment 25 m frame 10 m overlap frame 88 diﬀer featur egemap extract frame open sourc speech music interpret use large-spac extract toolkit featur normal mean standard deviat normal scale acquir ﬁxed normal factor train data set featur group ﬁve frame consid time-relev characterist speech data 2.2 pre-train ae acoust featur process reﬁn acoust data feature-extract ae introduc ae hierarch structur train regress model reproduc input paramet ae take input convert latent represent reconstruct input paramet latent valu consid input ae x ∈rd latent represent z ∈rd′ reconstruct input ∈rd obtain appli nonlinear activ function f weight sum z use weight matrix w ∈rd×d′ bia vector b ∈rd′ z f \\x10 wtx b \\x11 f \\x10 wtz b′\\x11 matrix transpos oper latent dimens d′ output latent layer consid compress meaning valu extract input also note bottleneck featur normal egemap featur appli train feature-extract ae appli data input target ae model contain latent layer lower compact featur dimens compar input layer achiev use bottleneck featur sensor 2020 20 6762 6 11 model symmetr structur center around latent layer model could divid two compon encod consist layer input latent layer decod consist layer bottleneck output layer ae structur depict figur 1 ae model consist fc layer dimens 88 70 54 70 88 node input hidden latent hidden output layer respect hidden dimens select experiment bottleneck featur dimens use comparison previou research 54 featur select consid statist dissimilar distribut asd td featur base mann–whitney u test addit introduc auxiliari output binari categor target asd td known semi-supervis method train ae model eﬀect auxiliari output depict aux figur 1 reconstruct featur auxiliari classiﬁc written zi f z1 f yrec w3,4z3 b3,4 yaux ∂ yrec refer reconstruct egemap featur yaux auxiliari classiﬁc result f activ function ∂i softmax activ layer consid compress meaning valu extract input also note bottleneck featur normal egemap featur appli train feature-extract ae appli data input target ae model contain latent layer lower compact featur dimens compar input layer achiev use bottleneck featur model symmetr structur center around latent layer model could divid two compon encod consist layer input latent layer decod consist layer bottleneck output layer ae structur depict figur 1 ae model consist fc layer dimens 88 70 54 70 88 node input hidden latent hidden output layer respect hidden dimens select experiment bottleneck featur dimens use comparison previou research 54 featur select consid statist dissimilar distribut asd td featur base mann–whitney u test addit introduc auxiliari output binari categor target asd td known semi-supervis method train ae model effect auxiliari output depict aux figur 1 reconstruct featur auxiliari classif written 𝒛𝑖= 𝑓 𝒛1 𝑓 𝒚𝑟𝑒𝑐= 𝑾3,4𝒛3 𝒃3,4 𝒚𝑎𝑢𝑥= 𝜕 𝒚𝑟𝑒𝑐 refer reconstruct egemap featur 𝒚𝑎𝑢𝑥 auxiliari classif result 𝑓 activ function 𝜕 softmax activ figur 1 structur semi-supervis auto-encod model egemap extend version geneva minimalist acoust paramet set asd autism spectrum disord td typic develop loss reconstruct error main ae target measur use mean absolut error auxiliari asd/td target loss binari cross-entropi ad simultan optim ration hyper-paramet overal loss equat figur 1 structur semi-supervis auto-encod model egemap extend version geneva minimalist acoust paramet set asd autism spectrum disord td typic develop loss reconstruct error main ae target measur use mean absolut error auxiliari asd/td target loss binari cross-entropi ad simultan optim ration hyper-paramet overal loss equat lrecon 1 n n x i=1 yirec −yigt laux −y1gt log −y1gt log ltotal lrecon αlaux lrecon laux ltotal denot reconstruct error auxiliari loss use binari cross-entropi loss function total loss respect sensor 2020 20 6762 7 11 stack ae model ration valu α 0.3 select experiment consid proport loss order train ae eﬀect l2 normal weight normal batch normal adopt 28,29 train complet fetch encod ae featur extract part joint optim model train procedur deep learn model 2.3 establish train deep learn model asd detect egemap data set ae train semi-supervis learn machin learn model svm blstm joint optim blstm construct model input paramet dimens output target asd td classiﬁc label egemap featur data pair diagnost result supervis learn neural network model binari decis asd label posit data point label td label neg data point compos four kind model pair data svm linear kernel vanilla blstm 88 egemap featur vanilla blstm 54 egemap featur jointli optim blstm layer ae joint optim model depict figur 2 data set prepar input ﬁve sequenti frame i.e. group egemap featur figur 2 svm receiv singl frame paramet 440 dimens ﬂatten origin ﬁve input frame deep learn model batch normal rectangular linear unit activ dropout appli layer except output layer 30,31 adapt momentum optim use train network train procedur control earli stop minim valid error 100 epoch patienc save best model improv valid loss epoch amount speech data rel small deep learn model compar dispar ﬁeld audio engin group data ﬁve segment test utter separ formerli select randomli 10 total data evenli distribut across vocal type underw ﬁve-fold cross-valid train best-perform model chosen model train tensorflow framework comparison svm model linear kernel train data split propos deep learn model well vanilla blstm suggest singl blstm eight cell sensor 2020 20 x peer review 8 12 figur 2 structur joint optim model auto-encod bidirect long short- term memori 3 perform evalu perform method evalu five-fold cross valid 95 averag asd utter 130 averag td utter proport distribut five case vocal gener estim unconcentr utter data averag perform five valid split model describ tabl 4 label name blstm use featur train blstm model egemaps-88 denot 88 featur egemap egemaps-54 denot 54 featur select mann–whitney u test ae-encod denot joint optim model classif stage one utter th f th th ft l di 0 1 figur 2 structur joint optim model auto-encod bidirect long short-term memori 3 perform evalu perform method evalu ﬁve-fold cross valid 95 averag asd utter 130 averag td utter proport distribut ﬁve sensor 2020 20 6762 8 11 case vocal gener estim unconcentr utter data averag perform ﬁve valid split model describ tabl 4 label name blstm use featur train blstm model egemaps-88 denot 88 featur egemap egemaps-54 denot 54 featur select mann–whitney u test ae-encod denot joint optim model classiﬁc stage one utter process frame-wis method softmax output convert class index 0 1 averag class index frame 0.5 utter consid asd child ’ utter perform score convent measur well unweight averag recal weight averag recal chosen interspeech 2009 emot challeng consid imbalanc class experi svm model show low precis extrem bias toward td class blstm classiﬁ 88 featur egemap ae model show consider qualiti term classifi asd td child ae model show margin improv correctli classifi child asd compar egemaps-88 54 select featur show degrad qualiti compar egemaps-88 obtain bias result toward child td tabl 4 classiﬁc result support vector machin blstm 88 54 egemap featur 54 select egemap featur blstm ae-encod featur model svm blstm blstm blstm predict asd td asd td asd td asd td asd 62 18 170 103 196 99 215 98 td 413 632 305 547 279 551 260 552 accuraci 0.6178 0.6373 0.6640 0.6818 precis 0.1305 0.3579 0.4126 0.4526 recal 0.7750 0.6227 0.6644 0.6869 f1 score 0.2234 0.4545 0.5091 0.5457 uar 0.5514 0.5997 0.6302 0.6509 uar unweight averag recal 4 discuss vanilla blstm model present conduct discrimin well-classiﬁ subject 10-month-old child sort 54 featur egemap distinct distribut asd td select mann–whitney u test use three-fold cross-valid method howev diﬀer data distribut fail achiev egemap featur select test classiﬁc result speciﬁ featur set present herein applic ident model structur adopt featur domain allow approach indirectli compar result interpret data distribut perform t-stochast neighbor embed analysi train data set nonlinearli squeez data dimens base machin learn algorithm figur 3 show data distribut two-dimension scatter plot ﬁgure egemap featur egemaps-88 egemaps-54 show almost ident distribut except amount asd outlier impli asd td featur egemap featur show similar distribut experi shown egemap includ tempor featur relev vocal utter thu featur might caus confus regard discrimin asd td ae-encod featur howev show redistribut featur map characterist distribut compar egemap featur ae-encod featur compress bottleneck featur deriv weight matrix pay attent signiﬁc paramet sensor 2020 20 6762 9 11 reduc inﬂuenc ambigu paramet joint optim model achiev margin improv result compar egemaps-88 distribut featur map would notic improv featur extract model well diﬀerenti complex model although blstm eight cell employ comparison convent research experi distribut compar egemap featur ae-encod featur compress bottleneck featur deriv weight matrix pay attent signific paramet reduc influenc ambigu paramet joint optim model achiev margin improv result compar egemaps-88 distribut featur map would notic improv featur extract model well differenti complex model although blstm eight cell employ comparison convent research experi overal perform score compar low gener classif problem account subject complex problem limit term shortag data result jointli optim model impli possibl deep-learning-bas featur extract improv autom asd/td diagnosi restrict circumst figur 3 two-dimension scatter plot egemaps-88 egemaps-54 ae process t-stochast neighbor embed 5 conclus paper conduct experi discov possibl auto-encoder-bas featur extract joint optim method autom detect atyp voic child asd earli development stage condit insuffici dispers data set classif result rel poor comparison gener classif task base deep learn although investig use limit number subject unbalanc data set suggest auto-encoder-bas featur extract joint optim method reveal possibl featur dimens slight improv model-bas diagnosi uncertain circumst figur 3 two-dimension scatter plot egemaps-88 egemaps-54 ae process t-stochast neighbor embed overal perform score compar low gener classiﬁc problem account subject complex problem limit term shortag data result jointli optim model impli possibl deep-learning-bas featur extract improv autom asd/td diagnosi restrict circumst 5 conclus paper conduct experi discov possibl auto-encoder-bas featur extract joint optim method autom detect atyp voic child asd earli development stage condit insuﬃci dispers data set classiﬁc result rel poor comparison gener classiﬁc task base deep learn although investig use limit number subject unbalanc data set suggest auto-encoder-bas featur extract joint optim method reveal possibl featur dimens slight improv model-bas diagnosi uncertain circumst futur work focu increas reliabl propos method addit number infant ’ speech data reﬁnement acoust featur auto-encod featur extract better deeper up-to-d model structur research also extend child age 3 4 speak sever sentenc case investig linguist featur well acoust featur done paper addit asd detect research appli detect infant develop delay author contribut author discuss content manuscript h.k.k contribut research idea framework studi g.b h.j.i provid databas help discuss j.h.l perform experi g.w.l contribut data collect pre-process author read agre publish version manuscript fund work support institut inform commun technolog plan evalu grant fund korea govern 2019-0-00330 develop ai technolog earli screen infant/child autism spectrum disord base cognit psycholog behavior respons conﬂict interest author declar conﬂict interest sensor 2020 20 6762 10 11', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f19f9b63-234f-4c9c-bf79-78f7eb22957e', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Patten_Audio_cleaned.txt', 'file_name': 'Patten_Audio_cleaned.txt', 'file_type': 'text/plain', 'file_size': 40409, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='vocal pattern infant autism spectrum disord canon babbl statu vocal frequenc elena patten ph.d.1 kati belardi m.s.2 grace t. baranek ph.d.2 linda r. watson ed.d 2 jeffrey d. labban ph.d.1 d. kimbrough oller ph.d.3 1univ north carolina greensboro 2univ north carolina chapel hill 3univ memphi konrad lorenz institut evolut cognit research klosterneuburg austria abstract canon babbl critic mileston speech develop usual well place 10 month possibl infant asd show late onset canon babbl far elud evalu rate vocal “ volubl ” also suggest possibl aberr infant asd conduct retrospect video studi examin vocal 37 infant 9–12 15–18 month twenty-thre 37 infant later diagnos asd inde produc low rate canon babbl low volubl comparison 14 typic develop infant studi thu support suggest earli vocal pattern may prove use compon earli screen diagnosi asd keyword canon babbl volubl vocal pattern earli detect asd earli vocal develop earli intervent critic posit outcom child autism spectrum disord earli identif atyp behavior manifest infanc could significantli impact age diagnosi subsequ initi intervent current minimum age major child asd reliabl diagnos rel stabil two year accord recent data center diseas control mani child correspond concern articl address elena patten univers north carolina greensboro 300 ferguson build p. box 26170 greensboro nc 27402-6170. e_patten uncg.edu elena patten unc greensboro 300 ferguson build greensboro nc 27412-6170 kati belardi unc chapel hill bondur hall cb 7190 chapel hill nc 27599-7190 grace baranek unc chapel hill bondur hall cb 7122 chapel hill nc 27599-7190 linda watson unc chapel hill bondur hall cb 7190 chapel hill nc 27599-7190 jeffrey labban unc greensboro 231 hhp build greensboro nc 27412 d. kimbrough oller univers memphi 807 jefferson avenu memphi tn 38105 elena patten jeffrey labban unc greensboro north carolina usa kati belardi grace baranek linda watson unc chapel hill north carolina usa d. kimbrough oller univers memphi tennesse usa nih public access author manuscript j autism dev disord author manuscript avail pmc 2014 octob 01 publish final edit form j autism dev disord 2014 octob 44 2413–2428 doi:10.1007/s10803-014-2047-4 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript diagnos preschool kindergarten age research target earli detect primarili focus behavior exhibit toddlerhood preschool year e.g. matson fodstad dempsey 2009 volkmar chawarska 2008 diagnosi made use retrospect video analysi studi infant sibl child diagnos asd allow examin possibl indic asd first year life e.g. baranek 1999 osterl dawson munson 2002 sheinkopf iverson rinaldi lester 2012 zwaigenbaum et al. 2005 still wide use autism screen tool young child modifi checklist autism toddler recommend age 16–30 month sought identifi potenti commun marker asd might observ within first year life retrospect evalu data infant record home later diagnos asd focus presum precursor languag two reason first commun impair core deficit asd second evalu earli vocal behavior typic develop infant alreadi establish marker critic normal vocal commun develop one robust pre-speech vocal mileston onset canon babbl canon syllabl compris consonant-lik sound vowel-lik sound rapid transit second potenti import vocal measur consid volubl rate infant vocal independ vocal type canon babbl key mileston typic develop infant birth produc veget vocal e.g. cough burp etc cri well vowel-lik sound becom elabor time incorpor supraglott articul canon syllabl emerg usual earli second half-year life robust onset canon babbl well document typic develop infant later 10 month koopmans-van beinum van der stelt 1986 oller 1980 stark 1980 impress robust reinforc fact delay onset canon babbl discern infant anticip at-risk commun deficit due prematur birth low socioeconom statu even infant syndrom usual show normal age onset although group level delay month detect furthermor infant tracheostom birth provid artifici airway prevent substanti inhibit vocal mani month tend produc age-appropri canon syllabl within short period decannul bleil stark mcgowan 1993 lock pearson 1990 ross 1983 simon fowler handler 1983 profound hear impair william syndrom shown produc consist substanti delay onset canon babbl kent osberg netsel hustedd 1987 koopmans-van beinum clement van den dikkenberg-pot 1998 masataka 2001 oller eiler 1988 stoel-gammon otomo 1986 support idea restrict hear prevent experi critic onset canon babbl patten et al page 2 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript age onset sever profoundli hear impair infant report posit correl age amplif infant without known disord onset canon babbl ten month shown signific predictor languag delay development disabl late onset canon babbl rare occurr infant without easili diagnos physic mental limit seem resist derail development mileston suggest canon babbl import human develop evolv emerg within rel tightli constrain time period spite substanti variat home environ perinat event import canon babbl predict later languag function assum due fact word overwhelmingli compos canon syllabl thu lexic learn depend control canon syllabl date two studi awar target canon babbl asd neither specif examin onset canon babbl reason optim delay onset canon babbl could constitut earli asd marker found research show variou aspect vocal appear disrupt young child asd paul augustyn klin volkmar 2005 pepp mccann gibbon ’ hara rutherford 2007 sheinkopf mundi oller steffen 2000 warren gilkerson richard oller 2010 wetherbi et al. 2004 research use autom analysi all-day record base autom lena languag environ analysi system classif shown clear indic young child asd display low rate canon syllabl product compar typic develop infant even match subgroup express languag oller et al. 2010 even point one recent studi assess usag canon syllabl infant high-risk asd sibl child asd seven 24 particip studi receiv provision diagnosi asd 24 month paul fuerst ramsay chawarska klin 2011 group at-risk infant produc significantli lower mean canon babbl ratio canon syllabl divid “ speech-lik ” vocal i.e. deem “ transcrib ” research compar low-risk infant nine-month age signific differ 12 month “ non-speech ” vocal includ evalu canon babbl vocal measures—especi number consonant- like element number speech-lik proport non-speech-lik vocalizations— also appear potenti use indic emerg asd volubl asd volubl rate vocal measur term frequenc syllabl utter product may limit asd possibl support autom analysi data show low volubl asd all-day record child 16 48 month age base lena system volubl infant sever profound hear loss infant syndrom found patten et al page 3 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript depress compar typic develop infant howev infant lower socio-econom statu shown consist produc fewer utter per minut middl high s peer research suggest child low s experi le commun caregiv hart risley 1995 snow 1995 lower volubl infant may product decreas social-commun adult potenti result lower level social motiv infant variabl moment-to-mo parent interact clearli affect infant volubl middl first year life indic research parent-inf interact “ still-fac ” paradigm work suggest strong tendenc particular case parent still-fac infant increas vocal rate specif volubl baselin period one three minut face-to-fac vocal interact substanti lower follow still-fac period one three minut parent withhold facial vocal reaction continu look directli infant pattern seen infant 5 month 3 month volubl chang shift face-to-fac interact still-fac delgado messing yale 2002 goldstein schwade bornstein 2009 yale messing cobo-lewi oller eiler 1999 result still-fac paradigm interpret mean infant seek re-engag withdrawn parent still-fac period learn middl first year vocal impact effect rais question whether infant emerg asd similarli increas volubl re-engag caregiv period withdrawn caregiv attent whether decreas volubl possibl due diminish motiv engag social other frequenc vocal direct other report significantli lower infant later diagnos asd compar typic develop infant 12 month 6 month also notabl frequenc vocal base parent report predict languag abil toddler asd paul et al assess frequenc vocal infant high-risk low-risk develop asd found differ group howev studi actual test volubl way volubl defin much prior research frequenc vocal talli special way paul et al studi count speech-lik nonspeech-lik vocal occur within first 50 speech-lik vocal record sampl particip produc 50 speech-lik utter one length record requir reach 50 speech-lik utter criterion variabl thu rate vocal per unit time examin studi consequ given common usag term volubl possibl determin whether differ volubl group addit particip studi high-risk asd—som later diagnos asd mixtur may attenu group differ also note weismer et al includ child vocal direct other paul et al includ vocal although asd root social impair vocal direct other well independ vocal play might well abnorm asd patten et al page 4 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript new studi earli vocal develop asd one reason develop pre-speech vocal behavior asd well document may asd reliabl diagnos long canon syllabl expect emerg thu make prospect analysi challeng retrospect interview parent whose child diagnos asd regard age canon syllabl emerg may hinder poor parent recal given parent gener ask rememb natur child babbl occur one year prior time interview also parent ’ awar diagnosi may bia recal onset canon babbl effort paul et al cite repres key advanc methodolog assess infant known at- risk prospect fashion approach seiz addit opportun afford fortuit exist home video data first year life analyz diagnosi asd comparison similar video data infant receiv diagnosi indic studi cite emerg canon syllabl critic mileston develop spoken languag delay onset shown predict signific commun impair canon babbl volubl well character infant asd arriv better understand two variabl potenti indic asd risk infant investig vocal infant later diagnos asd typic develop infant two age rang 9–12 month 15–18 month use retrospect video analysi method previou research suggest nearli td infant reach canon babbl stage 9–12 month assumpt delay might present child later diagnos asd predict delay would observ age rang took opportun also evalu avail data 15–18 month infant failur show canon babbl age would greatli delay canon babbl onset would consid high risk varieti disord code scheme studi base wide appli method laboratory-bas evalu canon babbl accord method infant assum canon stage show canon babbl ratio canon syllabl divid syllabl least .15 valu base code train listen record valu .15 greater laboratori code empir determin prior research correspond parent judgment infant canon stage reason parent judgment constitut appropri standard establish criterion valu reason base three point 1 parent respond interview question provid consist accur inform canon babbl infant papoušek 1994 oller eiler basing 2001 2 parent capabl predict given recogn canon babbl repres noth abl recogn syllabl well-form enough could form part word real speech cours normal adult easili recogn vocal human speech non- speech 3 parent appear intuit understand onset canon babbl patten et al page 5 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript emerg foundat speech evidenc fact initi intuit lexic teach soon begin recogn canon babbl infant consist parent recognit onset canon babbl run parallel recognit development mileston e.g. sit unsupport crawl walk studi could use parent inform age onset canon babbl sinc onset occur long time first contact consequ canon babbl ratio determin record code laboratori provid best avail measur upon base infer whether infant reach canon stage present studi follow hypothesi test 1 infant later diagnos asd le like td infant canon stage age determin whether canon babbl ratio exceed .15 criterion 2 infant later diagnos asd demonstr significantli lower canon babbl ratio compar td infant 3 infant later diagnos asd demonstr significantli fewer total vocal age rang compar td infant 4 combin analysi use volubl canon babbl statu significantli predict group membership method particip total 37 particip includ present studi 23 individu later diagnos asd 14 individu td group one set fratern twin asd group particip drawn larger studi conduct univers north carolina-chapel hill base avail video record particip must two five-minut edit video segment 9–12 month least one edit video segment 15–18 month part larger studi particip recruit midwest southeast 15-year time period recruit criterion includ child age two seven year time recruit avail home videotap child birth two year age parent will share enough video footag least one 5-minut codabl segment see video edit section child either 9–12 15–18 month age particip includ asd group receiv clinic diagnosi asd licens psychologist and/or physician point record made thu design retrospect analysi similar other use home movi child later diagnos asd train research staff member valid diagnosi particip use criterion diagnost statist manual iv one asd screen diagnost tool includ childhood autism patten et al page 6 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript rate scale autism diagnost observ schedul and/or autism diagnost interview- revis particip car score particip asd group adi/adi-r score 13 23 asd particip ado score typic develop group membership base part score within normal limit mullen scale earli learn and/or vineland adapt behavior scale vab sparrow balla cicchetti 1984 addit exclusionari criterion particip td group histori learn development difficulti per parent report individu signific physic visual hear impair known genet condit e.g. fragil x rett ’ syndrom associ asd exclud indic tabl 1 mean age similar across group gender balanc two group also similar regard s base matern educ famili mostli middl s access videotap equip univers north carolina-chapel hill institut review board approv studi famili sign inform consent inform regard recruit inclus criterion see baranek video edit procedur famili provid home video child birth two year avail videotap includ footag varieti context includ famili play situat vacat outing special event familiar routin individu variat situat content famili ’ videotap would expect home videotap videotap copi transform digit format origin return particip famili video edit guidelin first focus identif video footag child consist visibl parent felt could accur identifi child ’ age two age rang origin select anoth studi earli behavior asd time two age rang well-suit current purpos 9–12 month age rang earliest age rang parent suffici videotap footag use research repres time period number commun behavior emerg time frame vast major td child would expect alreadi canon babbl stage 15–18 month rang provid follow-up child expect monitor behavior would consist would allow confirm clarif data earlier age td child canon babbl usual well consolid 15–18 month age rang edit tape larger studi aim compil two 5-minut video segment child 9–12 age rang two 5-minut segment 15–18 month age rang averag 5-minut segment consist 5 scene research assist blind research question inform diagnost statu patten et al page 7 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript particip edit videotap code scene follow content variabl number peopl present amount physic restrict child ’ freedom move rate low medium high amount social intrus anoth person use engag child interact rate low medium high type event assist instruct quasi-randomli select cross-sect scene avail footag design age rang purpos includ scene one-month age interv video footag avail within age rang provid child visibl select scene particip includ current studi two 5-minut compil 9–12 month age rang 15–18 month age rang three td infant one infant asd singl 5- minut segment assembl due insuffici video footag result mean durat sampl 15–18 month age rang 9.5 minut rather 10 although vocal infant common scene segment specif select captur vocal behavior therefor volubl estim present studi may lower prior work infant observ set design maxim vocal interact similarli video segment select procedur may yield differ canon babbl prior studi studi 20–30 minut vocal interact record wherea le half amount data per sampl procedur predict produc greater variabl canon babbl ratio studi longer sampl period moleman 2011 moleman et al. 2011 addit audio-video qualiti home movi good would expect laboratori studi anoth factor could reduc perceiv canon babbl volubl ensur context child record compar specif content paramet identifi compar differ found group content paramet includ number peopl present level physic restrict i.e. amount physic confin highchair versu free play rate low medium high amount social intrus rate low medium high total number event type number time event type repres asd group versu td group age compar use chi-squar analysi result omnibu chi-squar test fail reach signific 9–12 month age group reach signific 15–18 month age group typic develop child like engag passiv activ 15–18 month age rang p 0.046 td 16.6 asd 4.6 accord follow-up analysi six event categori see tabl 4 5 percentag categori comprehens descript code procedur yield data situat context see watson crai baranek dykstra wilson code procedur observ agreement videotap analyz studi code infant product syllabl speech-lik vocal two certifi speech-languag pathologist patten et al page 8 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript inform diagnost group infant intent cours coder blind diagnost categori except one infant discuss coder report saw reason suspect infant asd defin speech-lik vocal includ canon precanon infant vocal regardless whether would deem “ transcrib ” train two coder provid last author origin definit “ canon syllabl ” use studi conduct collabor numer studi onset canon babbl rate canon babbl volubl infant cobo-lewi oller lynch levin 1996 lynch et al. 1995 oller eiler 1982 1988 oller eiler basing 2001 oller et al. 1995 oller eiler neal cobo-lewi 1998 two observ train identifi canon syllabl count syllabl independ canon statu video sampl use train separ although drawn similar materi base home record includ analysi investig syllabl defin rhythmic unit speech-lik vocal exclud raspberri effort “ grunt ” sound ingress sound sneez hiccup cri laugh within “ utter ” defin vocal breath group possibl identifi syllabl correspond sonor peak intuit recogn matur listen rhythmic event occur time frame typic syllabl real speech canon syllabl defin includ vowel-lik nucleu least one margin consonant-lik sound transit margin nucleu rapid uninterrupt gener transit fast track auditorili fast heard “ transit ” instead heard gestalt syllabl auditori track transit focu formant transit measur spectrogram typic 120 m formant audibl band energi correspond reson frequenc vocal tract chang tract chang shape size audibl formant transit occur vocal tract move open consonant closur vowel vice versa exampl canon utter syllabl listen might perceiv ba taka gaga vocal produc mouth object eat exclud analysi ground could sure role movement hand may play appar syllabif video random randomli distribut across two coder regard diagnost group 37 particip ’ video randomli split coder particip includ age rang coder independ watch video count syllabl canon syllabl real time procedur util regularli laboratori last author accord reason present recent patten et al page 9 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript paper especi ramsdel et al naturalist listen approach mimic mother would hear child listen utter measur canon babbl ratio use number canon syllabl divid number syllabl measur util bulk research onset canon babbl date howev studi use differ ratio number canon syllabl divid number utter former procedur gener prefer nowaday result valu interpret proport valu vari 0 1 wherea latter procedur yield ratio effect upper limit coder agreement test observ independ code twenti sampl consist two five-minut segment ten particip ’ video footag research assist unawar studi goal select test sampl repres diagnost group age reliabl gaug accord degre coder agre upon canon syllabl total syllabl whether child canon babbl stage inter-rat agreement rang good excel canon syllabl total syllabl reliabl canon babbl ratio also good agreement canon stage criterion 95 twenti sampl addit coder differ averag 10 total rang canon babbl ratio obtain correl across ratio twenti sampl two coder .89 volubl coder differ averag 13 total rang volubl valu correl across twenti sampl video two coder .91 result analysi perform confirm group match demograph variabl analysi reveal signific differ group variabl initi descript statist within- between-group variabl reveal two outlier asd group case produc high canon babbl ratio 9–12 month rang rel mean group asd .12 23 case td 17 base prior research canon babbl ratio observ two asd case substanti higher would expect td infant 9–12 month age range—inf group english spanish home high low s born term prematur show mean canon babbl ratio .4 8 12 month age oller eiler urbano cobo-lewi 1997 oller eiler steffen lynch urbano 1994 analysi z-score reveal infant 22 3.96 standard deviat mean present sampl infant 23 2.73 standard deviat mean suggest outlier statu basi decid elimin two case primari analysi canon babbl remain 35 case analyz address research question regard canon babbl see figur 1 2 canon babbl ratio particip age patten et al page 10 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript two outlier indic howev signific outlier regard volubl thu includ data 37 case analysi see figur 3 4 syllabl volubl particip age hypothesi 1 infant later diagnos asd le like typic develop infant canon stage age log odd ratio calcul compar classif asd typic develop child regard canon babbl criterion canon babbl stage set 15 greater canon syllabl compar syllabl common criterion studi canon babbl base data review oller td infant significantli like reach canon babbl stage base criterion infant later diagnos asd 9–12 month age rang remain like 15–18 month age rang n 35 log 1.78 ci95 −0.04 3.61 p 0.054 easili interpret effect size measur simpl odd ratio oppos log odd ratio statist prefer signific test small n ’ consid simpl or indic td infant 17 time like categor canon stage asd infant 9–12 month 6 time like 15–18 month hypothesi 2 infant later diagnos asd demonstr significantli lower canon babbl ratio compar typic develop infant canon babbl ratio infant later diagnos asd td infant contrast use mix anova between-subject variabl diagnost categori within-subject variabl age rang 9–12 month 15–18 month mean canon babbl ratio 9–12 month .06 21 infant later diagnos asd .17 14 td infant 15–18 month valu .16 .28 respect analysi reveal signific main effect diagnost categori 6.79 p .01 ŋp2 0.17 infant later diagnos asd produc significantli lower canon babbl ratio signific main effect age 7.86 p .01 ŋp2 0.19 higher canon babbl ratio older age effect size group 9–12 month 1.09 15–18 month .62 moder effect cohen 1992 age diagnosi interact signific hypothesi 3 infant later diagnos asd demonstr significantli fewer total vocal age rang compar typic develop infant analysi 37 infant includ signific outlier volubl infant later diagnos asd td infant contrast use mix anova between-subject variabl diagnost categori within-subject variabl age rang infant later diagnos asd produc mean 4.55 syllabl per minut td patten et al page 11 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript infant produc mean 5.86 syllabl per minut 9–12 month 15–18 month infant later diagnos asd produc mean 3.24 syllabl per minut td infant produc mean 4.63 syllabl per minut see figur 6 analysi reveal signific main effect diagnost categori 4.85 p .034 ŋp2 0.12 age 4.96 p .032 ŋp2 0.12 thu infant later diagnos asd display significantli lower volubl td infant effect size group 9–12 month 2.07 15–18 month 2.77 hypothesi 4 combin analysi use volubl canon babbl statu significantli predict group membership logist regress analysi conduct test whether canon babbl statu volubl age rang 9–12 month 15–18 month could reliabl predict later diagnosi statu test conduct 37 case includ partli order match number case two predictor variabl partli goal analysi determin potenti practic util identif child without inform volubl canon babbl ratio test may thu one primari clinic interest sinc evalu circumst screen impli would basi know whether infant might outlier variabl without evalu would direct indic result degre group discrimin statist signific reach test full model constant-onli model indic set canon babbl statu volubl reliabl predict later diagnosi small-to-moder relationship predict group observ overal predict success 75 howev examin predictor use wald criterion reveal four predictor variabl includ model none significantli contribut predict group membership individu level statu infant regard canon babbl stage 9–12 month age rang provid largest observ predict contribut wald 3.06 p 0.08 exp 0.198 contribut group discrimin volubl 9–12 15–18 month age rang approach nil exp 0.992 0.985 respect examin correl among predictor variabl show volubl 9–12 month significantli correl predictor volubl 9–12 month significantli correl canon babbl 9–12 month inter-rel among predictor variabl suggest degre account varianc diagnosi howev observ exp valu strongli suggest canon babbl 9–12 month account bulk variabl diagnosi seem clear signific individu predictor logist regress may hamper high level relat among individu volubl patten et al page 12 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript variabl appear much influenc given small beta high p-valu predictor enter model hierarch fashion matter predictor entri order 9–12 month variabl step 1 15–18 month variabl step 2 cb variabl step 1 volubl step 2 9–12 month cb variabl signific independ predictor r2 chang diagnost abil regress regress step iter suggest littl ad r2 ad variabl second step addit substanti alter abil model predict later diagnosi effici model appear logist regress 9–12 month cb predictor discuss import earli intervent child asd result attempt quantifi behavior infanc may lead earli detect substanti effort address gestur social develop potenti role detect within first year life present result offer parallel find domain vocal develop demonstr signific group differ canon babbl statu canon babbl ratio total syllabl produc first year life studi infant later diagnos asd significantli le like classifi canon babbl stage demonstr significantli reduc canon babbl ratio compar td peer although signific group differ appar age rang effect size canon babbl larger 9–12 month paul et al demonstr similar result infant high-risk develop asd produc significantli lower canon babbl ratio compar low risk infant 9 month though 12 month differ statist signific combin find oller et al child asd 48 month age show low canon syllabl product data suggest low product canon syllabl may help marker asd infanc earli childhood sinc canon babbl well establish vast major td infant 10 month might seem odd sever td infant 5 9–12 month 3 15–18 month present studi provid sampl meet .15 canon babbl ratio criterion assign canon stage vocal develop howev import consid fact even infant clearli canon stage base parent report often fail reach criterion singl laboratori sampl 20–30 minut addit unlik sampl prior research canon babbl sampl design elicit vocal consequ may le rich quantiti varieti vocal sampl use develop criterion sampl 9–12 month 10 minut durat 15–18 month averag slightli le 10 minut shown variabl obtain canon babbl ratio increas length sampl decreas moleman 2011 moleman van den berg patten et al page 13 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript van severen gilli 2011 final sampl base home record consider nois variabl camera manag may imped abil recogn vocal sampl consequ surpris td infant fail reach criterion use determin canon statu base laboratori sampl given strong link onset canon babbl languag develop delay onset canon babbl infant asd may reflect latent commun impair also may delay canon babbl directli contribut commun symptom asd canon babbl requir motor abil well motiv produc syllabl practic babbl may lay critic foundat speech prospect research motor develop infant later diagnos asd spars often limit high-risk group avail research indic earli motor impair may present e.g. matson mahan fodstad hess neal 2010 manjiviona prior 1995 page boucher 1998 teitelbaum teitelbaurm nye fryman maurer 1998 thu delay canon babbl may reflect immatur disord motor system specif implic speech languag develop consequ social reinforc speech-lik sound eventu evolv true word consid behavior model languag develop hulit howard 2002 goldstein king west 2003 goldstein schwade 2008 goldstein west 1999 social reinforc may encourag product canon babbl child asd may le motiv social reinforc yield le frequent vocal explor product canon syllabl td infant add problem delay canon babbl may result reduct caregiv social-commun direct toward infant averag six seven month rare later ten month canon babbl emerg td infant respons recognit canon babbl caregiv alter commun pattern sometim attempt direct infant toward use canon syllabl meaningfully—for exampl parent hear baba may repli “ ye ’ bubbl ” therefor infant delay canon babbl may also delay exposur import linguist input thu may given le opportun learn word final point infant asd may simpli lower motiv vocal social first place lower motiv could provid basi slow vocabulari learn result volubl includ two statist reliabl find first child group lower volubl second age first attribut particular theoret import find take note fact lower level volubl 15–18 month compar 9–12 month correspond greater physic movement child older age group combin level physic restrict select record sampl significantli le older age p 001 report earlier level physic restrict significantli differ diagnost group patten et al page 14 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript second volubl find infant later diagnos asd produc significantli fewer vocal deem relev emerg speech canon non-canon sound age rang compar td peer research demonstr infant asd direct fewer vocal other studi extend find gener measur volubl term total vocal rather one direct other find also congruent result autom analysi all- day record indic low volubl child asd 16–48 month age result may seem run counter paul et al whose sampl high-risk infant report produc significantli fewer vocal low-risk infant howev describ introduct paul et al studi report data way directli compar volubl data report disabl group report exhibit volubl similar td infant clement 2004 chapman hardin-jon schult halter 2001 van den dikkenberg-pot koopmans-van beinum clement 1998 nathani oller neal 2007 davi morrison von hapsburg warner- czyz 2005 howev infant low s household report significantli decreas volubl comparison higher s household child low s background often presum at-risk languag deficit although would imposs identifi quantifi mechan poverti may affect languag develop research demonstr amount commun caregiv direct toward child decreas low s situat impoverish linguist environ may result decreas dyadic social commun interact thu decreas overal volubl infant import note rel well-match s two group suggest differ volubl attribut differ s case low s household impoverish linguist environ due lack parent respons might expect lead decreas volubl infant later languag difficulti infant later diagnos asd reduc volubl may affect multipl factor relat inher parent respons relat instead social impair asd one issu child may experi le linguist stimul due disrupt sensori process system correspond sensori hyporespons child asd le like respond requir substanti stimul respond environment event baranek 1999 baranek et al. 2013 miller reisman mcintosh simon 2001 roger ozonoff 2005 characterist asd also reflect tendenc infant young eight month later diagnos asd le like td infant respond name call lack respons may indic infant asd le affect vocal commun caregiv td infant lack respons may reflect effect impoverish linguist environ attenu recept caregiv input infant asd subsequ commun impair inde patten et al page 15 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript sensori hyporespons shown associ poorer languag function child asd addit way environ child asd may impoverish could involv social feedback loop investig use autom analysi vocal parent infant all-day home record sinc infant asd produc fewer canon syllabl td infant sinc parent respond strongli languag stimul canon syllabl infant asd may actual hear le languag parent parent provid input tie infant ’ output infant ’ low volubl may aggrav lower input level result infant ’ anomal pattern vocal final logist regress analysi four independ variabl age 1 age 2 canon babbl classif age 1 age 2 volubl demonstr classif diagnost categori could predict 75 accuraci even two outlier includ model accur classifi infant later diagnos asd td infant strongest predictor group membership canon babbl classif 9–12 month alon correctli classifi 90 infant later diagnos asd 63 td infant thu search marker asd risk infanc canon babbl statu 9–12 month appear singl best candid among variabl consid current studi util measur group marker age depend sinc larger proport infant asd group 15–18 month reach canon stage 9–12 month help better understand high canon babbl ratio two outlier coder certifi speech-languag pathologist view video infant outlier statu identifi specul outlier statu two infant may relat phenomenon motor stereotypi common asd two infant engag least 9–12 month sampl motor stereotypi focus precis canon babbl re-examin video two outlier coder look qualit evid might speak credibl specul second view record coder notic first outlier infant produc major canon syllabl singl scene walk outsid repeatedli produc da syllabl brief episod direct vocal caregiv sens prelinguist vocal stereotypi may oper enhanc fact syllabl repeat throughout stereotypi canon babbl infant report coder constitut evid either notic specif suggest possibl asd code thu singl case intend blind coder diagnost group seem foil coder observ stereotyp behavior vocal otherwis sampl second infant engag high canon babbl product roughhous father clinic eye behavior seem particularli unusu research possibl babbl focu motor stereotypi asd seem order may worthi patten et al page 16 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript note two outlier ’ car score fell within rang score asd group addit find suggest possibl clinic use marker asd present result provid new scientif view robust canon babbl prior empir indic canon babbl onset delay asd volubl low infant later diagnos asd result thu suggest develop vocal infanc affect whatev fundament disord asd may assum asd social disord obviou babbl would necessarili disturb disord extent babbl social oppos endogen gener phenomenon empir question result thought provid new empir perspect possibl social natur babbl result also suggest vocal differenti two group robust given rel clariti result indic low canon babbl volubl infant asd group even though sampl low record qualiti limit durat result seem especi signific context broad bodi research cite robust canon babbl foundat languag robust resist canon babbl delay seen prior studi cite paper—no delay found case prematur low s multilingu exposur futur direct limit studi provid proof concept regard notion atyp emerg canon babbl stage develop infant later diagnos asd possibl track canon babbl infanc may add repertoir marker asd prior one year age futur research address limit current studi advanc understand develop canon babbl among infant asd warrant find current studi one limit current studi lack comparison group infant later diagnosi non-asd disabl prevent u definit attribut differ found studi asd rather gener impair cognit commun work hypothesi test futur studi differ canon babbl onset volubl specif asd anoth limit studi use short video segment time point sure impact abil precis ass import aspect vocal shown variabl obtain canon babbl ratio increas length sampl decreas moleman 2011 moleman van den berg van severen gilli 2011 low canon babbl ratio obtain td infant presum would occur larger sampl size futur studi hope obtain longer sampl possibl precis identifi canon babbl onset longitudin laboratori assess pair caregiv report onset cours make possibl prospect studi may necessari sever year follow-up presum take advantag opportun present sibl studi studi would also afford opportun obtain much better record patten et al page 17 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript avail retrospect studi present one inde sibl studi capit all-day record yield opportun ass vocal develop asd much greater ecolog valid repres onset canon babbl usual occur 5 9 month td infant appear present data onset may occur within much wider rang asd quantif onset asd may yield prognost valu regard core commun symptom exampl canon stage onset delay beyond certain threshold infant may especi high-risk remain nonverb discoveri delay could allow specif intervent tailor base prognosi earlier develop futur research also focu caregiv role canon stage develop identif prior work suggest td infant parent extrem accur report onset canon babbl caregiv infant asd similarli capabl identifi onset canon babbl may possibl use canon babbl onset part parent-report screen tool earli identif addit alter commun direct infant caregiv canon babbl emerg may help elicit maintain social- commun interact subsequ impact languag develop find volubl repres anoth potenti avenu understand earli social- commun develop process asd perhap intrigu aspect possibl suggest propos may feedback loop involv low canon syllabl product asd follow low parent rate vocal infant aggrav low volubl low rate canon syllabl asd anticip rapid growth studi track possibl especi sinc rapidli grow possibl conduct aspect analysi base autom classif vocal all-day record indic growth lena system studi clinic implic find suggest canon babbl consid import mileston infanc may delay infant later diagnos asd infant demonstr delay canon babbl development assess includ evalu earli warn sign asd administ although volubl appear le promis marker asd may use combin item context earli identif screen tool infant demonstr either low canon babbl ratio low volubl intervent draw infant ’ attent social-commun stimulu context dyadic interact may help stimul growth vocal commun acknowledg research made possibl grant nation institut child health human develop grant cure autism foundat sensory-motor social- commun symptom autism infanc thank famili whose particip made studi possibl staff collect process data project patten et al page 18 j autism dev disord author manuscript avail pmc 2014 octob 01 nih-pa author manuscript nih-pa author manuscript nih-pa author manuscript', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4f507a19-bc1b-40e0-be75-ef920d43f23b', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Qiu_cleaned.txt', 'file_name': 'Qiu_cleaned.txt', 'file_type': 'text/plain', 'file_size': 23799, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='origin research publish 05 june 2020 doi 10.3389/fped.2020.00290 frontier pediatr www.frontiersin.org 1 june 2020 volum 8 articl 290 edit sara calderoni fondazion stella mari itali review whitney i. mattson nationwid child ’ hospit unit state lori-ann rosalind sacrey univers alberta canada correspond xiaoyan ke kexiaoyan njmu.edu.cn specialti section articl submit child adolesc psychiatri section journal frontier pediatr receiv 05 januari 2020 accept 07 may 2020 publish 05 june 2020 citat qiu n tang c zhai huang w weng j li c xiao x fu j zhang l xiao fang h ke x applic still-fac paradigm earli screen high-risk autism spectrum disord infant toddler front pediatr 8:290. doi 10.3389/fped.2020.00290 applic still-fac paradigm earli screen high-risk autism spectrum disord infant toddler nana qiu 1 chuangao tang 2 mengyao zhai 1 wanq huang 3 jiao weng 1 chunyan li 1 xiang xiao 1 junli fu 1 lili zhang 4 ting xiao 1 hui fang 1 xiaoyan ke 1 1 nanj brain hospit afﬁliat nanj medic univers nanj china 2 school biolog scienc medic engin southeast univers nanj china 3 colleg telecommun inform engin nanj univers post telecommun nanj china 4 wuxi child ’ hospit wuxi china background although autism spectrum disord current diagnos age 2 year age asd diagnosi still 40 month even later order earli screen asd object method behavior video use number studi recent year method still-fac paradigm adopt measur frequenc durat non-soci smile protest behavior eye contact social smile activ social engag high-risk asd group typic develop group hr group follow-up 2 year old conﬁrm ﬁnal diagnosi machin learn method use establish model earli screen asd result face-to-fac interact episod sfp statist signiﬁc differ durat frequenc eye contact social smile activ social engag two group still-fac episod statist signiﬁc differ durat frequenc eye contact activ social engag two group 45 child hr group reclassiﬁ two group follow-up ﬁve child n-asd group meet criterion asd 40 child asd group result show accuraci support vector machin classiﬁc 83.35 sf episod conclus use social behavior indic sfp child hr 2 year old effect predict clinic diagnosi child age 2 year screen model construct use svm base sf episod sfp best also prof sfp certain valu high-risk autism spectrum disord screen addit conveni provid self-screen mode use home trial registr chines clinic trial registri chictr-opc-17011995 keyword high-risk autism spectrum disord still-fac paradigm social behavior machin learn model earli screen qiu et al earli screen high-risk asd introduct autism spectrum disord seriou neurodevelopment disord start earli childhood character social commun barrier restrict interest repetit stereotyp behavior abnorm percept recent year epidemiolog survey data incid asd show preval rate increas 0.07 1.8 china larg number studi asd shown earli intervent help improv patient prognosi howev age asd diagnosi still 40 month even later therefor earli detect earli diagnosi eﬀect intervent essenti achiev better prognosi understand earli childhood behavior asd help facilit earli intervent infant toddler suspect asd improv prognosi import social econom implic earli social interact adult child basi complex social cognit child asd lack social abil especi promin earli life accord 2013 version diagnost statist manual mental disord ﬁfth edit asd symptom usual present young child age 1–2 year occasion initi symptom often involv delay languag develop accompani lack social interest unusu social interact quirki play mode unusu commun pattern studi barbaro dissanayak famili video parent report reveal earli warn sign social interact child asd age 12 24 month old includ lack joint attent lack eye contact lack social smile lack social interest share respons call name lack gestur commun impair studi would focu diﬀer earli social behavior hr group td group previou studi earli behavior abnorm asd mostli form retrospect interview parent scale-bas evalu highli subject unfavor widespread promot recent year increas number studi adopt object method involv video use behavior code tronick et al propos still-fac paradigm test infant ’ emot regul abil social expect social interact earli maternal-inf interact core basi infant ’ social emot emot regul social commun develop maternal- infant relationship ﬁrst relationship develop earli childhood flexibl frequent interact basi earli childhood emot organ attent switch emerg social skill earli maternal- infant interact non-verb commun domin addit process young child learn rule social particip express form social expect provid social framework futur social interact relationship studi appli sfp emot regulatori asd found child asd employ simpl regulatori behavior le complex strategi addit cassel et al also found diﬃculti child asd develop socioemot abil studi sfp use measur social behavior hr group td group studi appli machin learn method build model earli screen asd base characterist valu biolog indic electro-encephalogram brain imag found accuraci 80 order improv stabil reliabl model earli screen asd essenti combin social behavior indic biolog indic subsequ research studi would tri build model earli screen asd base social behavior indic method particip forty-ﬁv infant toddler high-risk autism spectrum disord sought treatment outpati clinic child mental health research center nanj brain hospit aﬃliat nanj medic univers decemb 2017 decemb 2018 enrol hr group 43 infant toddler typic develop nanj area recruit period enrol control group inclus criterion hr group follow child posit result base modiﬁ checklist autism toddler pediatr psychiatrist recogn child met core criterion asd dsm-5 month age 24 month child age 8 23 month old child whose primari caregiv mother child whose guardian agre particip studi exclus criterion hr group follow child genet metabol diseas rett syndrom fragil x syndrom child neurodevelopment disord asd languag develop disord alon intellectu disabl child clear histori craniocerebr trauma child histori nervou system diseas seriou physic ill inclus criterion td group follow child td whose sex match child hr group child age 8 23 month old child whose primari caregiv mother child whose guardian agre particip studi exclus criterion td group follow child suﬀer variou type neurodevelopment disord mental disord child clear histori craniocerebr trauma child histori nervou system diseas seriou physic ill studi approv medic ethic committe nanj brain hospit aﬃliat nanj medic univers subject ’ guardian agre particip studi sign inform consent form frontier pediatr www.frontiersin.org 2 june 2020 volum 8 articl 290 qiu et al earli screen high-risk asd measur procedur gener psycholog evalu hr td group self-guid gener inform questionnair use collect gener demograph data past histori medic histori famili histori studi particip gesel development scale use ass development level subject enrol gesel development scale use evalu development quotient child 5 skill domain adapt gross motor ﬁne motor languag personal-soci sever asd symptom hr group assess use commun symbol behavior scale development proﬁl childhood autism rate scale autism behavior checklist csbs-dp 3 factor score social commun languag symbol behavior total score lower csbs- dp factor score seriou asd symptom car abc total score higher total score sever asd symptom video behavior hr td group sfp classic paradigm consist three episod baselin episod mother child requir normal interact still-fac episod mother ’ face requir present neutral express without respons child ’ action reunion episod mother resum normal interact child current sfp arous child ’ behavior chang e.g. reduct eye gaze posit facial emot increas neg emot transit baselin episod sf episod eﬀect recogn term sf eﬀect relev studi research also found reason gener sf eﬀect infant toddler disappear social respons eye contact mother show still face disappear social signal caus appear neg emot infant toddler ﬁrst two episod often use research randomli present order past decad basic set sfp use method explor earli childhood social behavior reason studi chosen ﬁrst two episod present studi particip mother video record sfp design observ room time enrol mother sit opposit child interact child 2 min ﬁxed instruct stop interact maintain neutral face 1 min figur 1 show setup experiment environ procedur infant caregiv engag phase nichol et al deﬁn code indic follow protest behavior infant show facial express anger frown infant upset cri arch bodi tri escap express anger use gestur non-soci smiling—th infant smile mother toward direct object eye contact—th infant look directli mother ’ eye face instead look camera toward direct social smiling—th infant look mother take initi smile initi smile mother smile infant immedi respond smile activ social engagement—th infant display happi facial express includ clear smile occasion coo activ vocal laugh babbl look mother initi interact infant posit respons interact initi mother observ xt 12 behavior observ record analysi system use code video code complet 2 train graduat student durat frequenc 5 indic ff sf episod calcul durat measur use second unit frequenc measur use number time unit total 18 video randomli select determin intercod consist use intraclass correl coeﬃcient found 2 coder high consist icc protest behavior non-soci smile eye contact social smile activ social engag 0.76 0.82 0.81 0.83 0.79 respect figur 1 sfp infant toddler hr frontier pediatr www.frontiersin.org 3 june 2020 volum 8 articl 290 qiu et al earli screen high-risk asd tabl 1 comparison gener condit hr group td group hr group td group t/χ2 p-valu sex −0.06 0.08 male 40 32 femal 5 11 age dq 19.71 ± 3.43 16.40 ± 4.70 3.80 0.01 adapt 80.29 ± 17.62 92.98 ± 7.89 −4.34 0.01 gross motor 92.02 ± 17.60 92.77 ± 8.46 −0.25 0.80 fine motor 86.64 ± 19.03 93.70 ± 8.29 −2.24 0.03 languag 60.84 ± 21.27 86.51 ± 8.353 −7.39 0.01 personal-soci 78.80 ± 17.19 92.28 ± 7.18 −4.76 0.01 hr high-risk autism spectrum disord td typic develop dq development quotient gesel development scale diagnost evalu child hr group 2 year age 2 year age child hr group evalu use autism diagnosi interview-r autism diagnost observ schedul two pediatr psychiatrist clinic diagnos child base asd diagnost criterion dsm-5 aforement evalu result particip conﬁrm asd asd group reach cut-oﬀscor asd diagnosi evalu scale analyt approach sex diﬀer hr td group compar use χ2 test diﬀer hr group td group social behavior determin use independ sampl t-test correl social behavior hr group age dq symptom sever analyz use pearson ’ rho final model earli asd screen construct use machin learn method base asd group td group hr group contain 40 child conﬁrm asd 5 child met criterion asd would use veriﬁ eﬀect model earli asd screen p 0.05 indic diﬀer statist signiﬁc result comparison gener condit hr group td group age adapt dq languag dq ﬁne motor dq personal-soci dq signiﬁcantli diﬀer hr group td group sex dq gross motor dq signiﬁcantli diﬀer two group see tabl 1 figur s1 comparison social behavior hr td group differ sfp episod ff episod sfp statist signiﬁc diﬀer durat frequenc eye contact social smile activ social engag hr group td group =-4.93 −6.17 −3.54 −2.90 −9.56 −8.34 p 0.05 diﬀer length frequenc non-soci smile protest behavior hr group td group statist signiﬁc see figur 2a b sf episod sfp statist signiﬁc diﬀer durat frequenc eye contact activ social engag hr group td group −4.94 −5.34 −4.49 −6.16 p 0.05 diﬀer length frequenc non- social smile protest behavior social smile hr group td group statist signiﬁc see figur 2c analysi correl social behavior factor hr td group differ sfp episod td group frequenc eye contact signiﬁcantli posit correl gross motor dq sf episod indic statist signiﬁc correl age dq ff episod durat eye contact social smile activ social engag hr group signiﬁcantli posit correl adapt dq durat eye contact gross motor dq also signiﬁcantli posit correl sf episod durat eye contact signiﬁcantli posit correl languag dq ﬁne motor dq durat activ social engag languag dq also signiﬁcantli posit correl indic signiﬁc correl age dq p 0.05 tabl 3 analysi correl clinic asd symptom sever social behavior indic suggest statist signiﬁc diﬀer social behavior indic clinic symptom sever ff episod sf episod durat eye contact posit correl symbol behavior factor score total csbs-dp score durat activ social engag posit correl total csbs-dp score frequenc eye contact posit correl social commun factor score languag factor score total csbs-dp score indic signiﬁc correl symptom sever p 0.05 tabl 3 frontier pediatr www.frontiersin.org 4 june 2020 volum 8 articl 290 qiu et al earli screen high-risk asd figur 2 comparison differ social behavior hr group td group differ sfp episod comparison differ durat social behavior ff episod comparison differ frequenc social behavior ff episod comparison differ durat social behavior sf episod comparison differ frequenc social behavior sf episod hr high-risk autism spectrum disord td typic develop sfp still-fac paradigm p 0.01 use machin learn construct model earli asd screen follow-up hr group re-diagnosi hr group 2 year age found 5 1 femal 4 male 45 infant toddler hr longer met diagnost criterion asd non-asd group 40 child still met diagnost standard model earli asd screen construct use machin learn method base asd group td group use durat frequenc eye contact activ social engag social smile ff episod well durat frequenc eye contact activ social engag sf episod behavior characterist sampl asd group td group use sampl classiﬁc asd comparison group td subject within 83 sampl use test model train rest 82 sampl predict label test sampl correspond 83 classiﬁc model collect calcul overal accuraci dataset 82 train sampl 1 sampl select test test set data classiﬁ use follow machin learn method support vector machin naïv bay random forest python platform use analysi random forest classiﬁ gaussian nb svm function scikit-learn toolbox develop python employ build classiﬁc model respect result show accuraci bayesian classiﬁc 80.54 ff episod 82.35 sf episod frontier pediatr www.frontiersin.org 5 june 2020 volum 8 articl 290 qiu et al earli screen high-risk asd tabl 2 analysi correl social behavior age dq td group differ sfp episod episod indic age adapt dq gross motor dq fine motor dq languag dq personal-soci dq durat ff episod eye contact −0.17 0.20 0.09 0.09 0.15 0.09 social smile −0.04 −0.06 −0.05 −0.22 −0.04 −0.11 activ social engag −0.03 −0.18 −0.12 −0.25 0.11 −0.12 frequenc ff episod eye contact −0.04 0.09 −0.10 0.11 0.03 0.01 social smile 0.15 −0.07 −0.08 −0.21 0.03 −0.09 activ social engag 0.05 −0.15 −0.04 0.02 0.02 −0.14 durat sf episod eye contact 0.05 −0.09 −0.02 −0.02 0.04 −0.12 social smile 0.04 −0.02 0.19 0.06 0.07 0.12 activ social engag −0.13 −0.17 0.07 −0.15 0.13 −0.01 frequenc sf episod eye contact 0.01 −0.08 0.31 0.01 0.04 −0.22 activ social engag −0.12 −0.03 0.02 −0.04 0.14 −0.01 td typic develop sfp still-fac paradigm dq development quotient gesel development scale p 0.05 tabl 3 analysi correl social behavior age dq clinic symptom hr group differ sfp episod episod indic age dq csbs-dp car abc adapt gross motor fine motor languag personal- social social commun factor languag factor symbol behavior factor total score durat ff episod eye contact −0.08 0.43 0.31 0.18 0.25 0.29 0.09 −0.01 −0.01 0.03 0.07 −0.15 social smile −0.11 0.36 0.25 0.08 0.21 0.14 0.10 −0.01 −0.04 0.02 0.01 −0.12 activ social engag −0.04 0.39 0.26 0.18 0.16 0.20 0.27 −0.01 0.19 0.19 −0.04 −0.08 frequenc ff episod eye contact −0.18 0.23 0.21 0.28 0.10 0.09 0.14 −0.04 0.05 0.05 −0.13 −0.24 social smile −0.09 0.09 0.11 0.14 0.01 0.17 0.01 −0.11 −0.02 −0.06 −0.04 −0.13 activ social engag −0.05 0.17 0.03 0.22 −0.07 0.03 0.21 −0.07 0.21 −0.10 0.15 0.11 durat sf episod eye contact −0.04 0.29 0.22 0.37 0.30 0.18 0.27 0.17 0.32 0.30 −0.34 −0.25 activ social engag 0.02 0.27 0.23 0.26 0.38 0.12 0.29 0.24 0.29 0.30 −0.11 −0.16 frequenc sf episod eye contact −0.29 0.17 0.12 0.29 0.26 0.12 0.35 0.33 0.25 0.36 −0.22 −0.18 activ social engag −0.18 0.15 0.27 0.29 0.28 0.29 0.15 −0.25 0.15 −0.18 0.13 −0.17 hr high-risk autism spectrum disord sfp still-fac paradigm dq development quotient gesel development scale csbs-dp commun symbol behavior scale development proﬁl car childhood autism rate scale abc autism behavior checklist p 0.05 p 0.01. accuraci random forest classiﬁc 80.72 ff episod 83.13 sf episod accuraci svm classiﬁc 81.18 ff episod 83.35 sf episod higher accuraci confus matrix show tabl 4 order ﬁnd age diﬀer kid pick machin learn asd group td group divid 4 group month age respect 8–11 12–15 16–19 20–23 subsequ eﬀect svm classiﬁc model veriﬁ 40 child conﬁrm asd 5 n-asd child hr group unfortun even though averag classiﬁc accuraci svm 80 5 n-asd classiﬁ correctli lack enough sampl n-asd result larg imbal two group limit sampl 10 indic within sampl could possibl reason low recal rate n-asd sampl therefor essenti expand sampl n-asd futur studi verifi eﬀect svm classiﬁc model ’ necessari build eﬀect machin learn model follow studi frontier pediatr www.frontiersin.org 6 june 2020 volum 8 articl 290 qiu et al earli screen high-risk asd tabl 4 confus matrix svm asd td ff episod asd 35 5 td 10 33 sf episod asd 34 6 td 7 36 asd autism spectrum disord td typic develop ff episod face face interact sf episod still-fac episod discuss face-to-fac interact constitut begin earli childhood learn deﬁn social interact face- to-fac interact infant toddler primari caregiv allow former learn mean self- express behavior characterist peopl close relationship emot inform percept local cultur primari caretak ident self-ident emot regul import link earli childhood develop mileston close relat primari caregiv studi shown strong emot regul abil child associ good develop predict social emot outcom later stage weak emot regul abil earli childhood associ behavior problem develop problem later stage especi 4 9 month old infant quickli learn regul emot face-to-fac interact therefor qualiti infant-moth interact crucial stage compar analysi diﬀer social behavior infant toddler hr infant toddler td age 2 compar infant toddler td infant toddler hr exhibit shorter durat lower frequenc eye contact social smile activ social engag ff episod sfp ﬁnding consist studi 28 36– 38 sf episod compar infant toddler td infant toddler hr show shorter durat lower frequenc eye contact activ social engag mean although child hr exhibit behavior attract attent non-respons mother abil initi activ social engag lower child td infant hr avoid eye contact result low-qual infant-moth interact therefor develop emot regul abil infant toddler may delay explain extent caus delay develop social smile activ social engag child asd result correl analysi diﬀer age development level social behavior infant toddler hr group td group diﬀer repres i.e. age development level infant toddler inﬂuenc social behavior gener condit infant toddler hr analysi correl clinic symptom social behavior show correl social behavior symptom sever ff episod sfp sf episod durat eye contact infant toddler hr posit correl symbol behavior factor score total csbs-dp score durat social smile posit correl social commun factor score total csbs-dp score durat activ social engag posit correl social commun factor score symbol behavior factor score total csbs-dp score frequenc eye contact posit correl social commun factor score languag factor score total csbs-dp score result indic ﬂexibl appropri eye contact activ social engag infant toddler hr le sever asd symptom also consist result studi although social behavior infant toddler asd develop time develop level limit gap infant toddler asd infant toddler td also increas time infant toddler asd develop clinic symptom asd sfp present chang child ’ express emot behavior microscop code mode basi set normal interact sfp provid social challeng scenario set sf episod social signal mother complet miss period typic develop child inabl adapt loss social signal stimul abil initi social interact express emot regul emot bear stress analysi result show social behavior infant toddler hr especi social behavior sf episod sfp associ core asd symptom accord extrem male brain theori autism toddler asd prone systemat thu lower empath abil td toddler make prone deﬁcienc social verbal commun examin diﬀer social behavior infant toddler hr group td group found although mani diﬀer abnorm social behavior infant toddler asd infant toddler td ff sf episod sfp social behavior infant toddler hr eye contact activ social engag sf episod signiﬁcantli correl core commun impair social commun factor score symbol behavior factor score total csbs-dp score sf episod sfp better induc social commun impair infant toddler asd markram et al propos intens world theori suggest excess activ brain would excess amplifi ordinari sensori experi caus toddler asd state fragment sensori inform overload strong reaction intens emot perceiv surround environ caus social withdraw result seri autism symptom frontier pediatr www.frontiersin.org 7 june 2020 volum 8 articl 290 qiu et al earli screen high-risk asd social commun impair stereotyp behavior therefor face social commun challeng sf episod infant toddler td attempt arous mother ’ respons point social smile contrast infant toddler hr even higher function may good interact mother ff episod mother respond social pressur reduc made fewer attempt shorter attempt initi social interact addit studi shown respond emot reaction child asd wors emot regul abil unreason express like show neg emot howev studi neg emot protest behavior non-soci smile infant toddler hr td diﬀer diﬀer frustrat scenario i.e. mother use still face valid discuss need futur studi base re-diagnosi regroup child 2 year age machin learn method includ svm naïv bay random forest use construct model earli asd screen found classiﬁc model establish use svm best perform especi found better screen abil reliabl sf episod unfortun model select appli diﬀerenti diagnosi child hr group 5 n-asd classiﬁ correctli also goal identifi n-asd asd group futur eﬀort sinc age diﬀer asd group td group ad figur s2 divid asd group td group 4 group month age respect 8–11 12–15 16–19 20–23 found regular classiﬁc accuraci vs. month age similarli limit studi first infant toddler asd gener delay develop 2 group match age make develop level hr group td group second sampl size small view limit continu expand sampl size futur studi verifi ﬁnding control physiolog psycholog age hope sfp wide appli earli asd screen object standard conveni way self-screen home achiev data avail statement dataset gener studi includ article/supplementari materi ethic statement studi involv human particip review approv medic ethic committe nanj brain hospit aﬃliat nanj medic univers written inform consent particip studi provid particip ’ legal guardian/next kin written inform consent obtain individu minor ’ legal guardian/next kin public potenti identiﬁ imag data includ articl author contribut nq xk design experi nq ct mz jw cl xx jf lz tx hf carri experi nq ct wh analyz experiment result nq wrote manuscript fund key research foundat jiangsu provinc fifth ‘ ‘ 333 high level cultiv talent project ’ ’ jiangsu provinc supplementari materi supplementari materi articl found onlin http //www.frontiersin.org/articles/10.3389/fp 2020.00290/full supplementary-materi', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cb6327a0-05d6-4085-875e-9fbbc32423d2', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Tariq2018_cleaned.txt', 'file_name': 'Tariq2018_cleaned.txt', 'file_type': 'text/plain', 'file_size': 39348, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='research articl mobil detect autism machin learn home video develop prospect valid studi qandeel tariqid1,2 jena danielsid1,2 jessey nicol schwartzid1,2 peter washingtonid1,2 haik kalantarian1,2 denni paul wallid1,2 1 depart pediatr divis system medicin stanford univers california unit state america 2 depart biomed data scienc stanford univers california unit state america dpwall stanford.edu abstract background standard approach diagnos autism spectrum disord evalu 20 100 behavior take sever hour complet part contribut long wait time diagnosi subsequ delay access therapi hypothes use machin learn analysi home video speed diagnosi without compromis accuraci analyz item-level record 2 standard diagnost instrument construct machin learn classifi optim sparsiti interpret accuraci present studi prospect test whether featur optim model extract blind nonexpert rater 3-minut home video child without asd arriv rapid accur machin learn autism classif method find creat mobil web portal video rater ass 30 behavior featur e.g. eye contact social smile use 8 independ machin learn model identify- ing asd 94 accuraci cross-valid test subsequ independ valid previou work collect 116 short home video child autism 46 video typic develop child three rater blind diagnosi independ measur 30 featur 8 model median time complet 4 minut although sever model consist alter- nate decis tree support vector machin svm logist regress radial kernel linear svm perform well spars 5-featur lr classifi yield highest accuraci across age test use prospect collect independ valid set 66 video 33 asd 33 non- asd 3 independ rater measur valid outcom achiev lower compar accuraci final appli lr 162- plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 1 20 a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 open access citat tariq q daniel j schwartz jn washington p kalantarian h wall dp mobil detect autism machin learn home video develop prospect valid studi plo med 15 e1002705 http //doi.org/10.1371/journ pmed.1002705 academ editor suchi saria john hopkin univers unit state receiv june 8 2018 accept octob 25 2018 publish novemb 27 2018 copyright © 2018 tariq et al open access articl distribut term creativ common attribut licens permit unrestrict use distribut reproduct medium provid origin author sourc credit data avail statement de-identifi data made avail follow github repositori includ primari dataset valid dataset http //github.com/qandeelt/ video_phenotyping_autism_plos/tree/master/ dataset code made avail follow github repositori instruct run classifi provid http //github.com/qandeelt/video_phenotyping_ autism_plo video-featur matrix construct 8-featur model achiev 0.93 auc 95 ci 0.90–0.97 held-out test set 0.86 valid set 66 video valid child exist diagnosi limit abil gener perform undi- agnos popul conclus result support hypothesi featur tag home video machin learn- ing classif autism yield accur outcom short time frame use mobil devic work need confirm approach acceler autism diagnosi scale author summari studi done • autism risen incid approxim 700 sinc 1996 impact least 1 59 child unit state • current standard diagnosi requir direct clinician-to-child observ take hour administ • sharp rise incid autism coupl un-scal natur stan- dard care creat strain healthcar system averag age diagnosi remain around 4.5 year 2 year past time could reliabl diagnos • mobil measur scale could help allevi strain healthcar system reduc wait time access therapi treatment reach underserv popul research find • appli 8 machin learn model 162 two-minut home video child without autism diagnosi test abil reliabl detect autism mobil platform • three nonexpert rater measur 30 behavior featur need machin learn classif 8 model approxim 4 minut • leverag video rate machin learn model 5 featur achiev 86 unweight averag recal 162 video uar 80 differ independ evalu set 66 video uar 83 child 4 • machin learn process render mobil video diagnosi quickli cre- ate novel collect label video featur new video feature–bas model 90 accuraci mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 2 20 fund work support part fund dpw nih 1r01eb025025-01 1r21hd091500-01 hartwel foundat bill melinda gate foundat coulter foundat lucil packard foundat program grant stanford univers ’ human center artifici intellig program precis health integr diagnost center beckman center bio-x center predict diagnost acceler child health research institut also receiv philanthrop support bobbi dekesy peter sullivan fund bodi role studi design data collect analysi decis publish prepar manuscript compet interest read journal ’ polici author manuscript follow compet interest dpw scientif founder cognoa compani focus digit pediatr healthcar approach find present paper independ from/not relat cognoa author declar compet interest exist abbrevi adi-r autism diagnost interview-revis ado autism diagnost observ schedul adtre altern decis tree adtree7 7-featur altern decis tree adtree8 8-featur altern decis tree asd autism spectrum disord auc area curv auc-roc area receiv oper characterist curv bid balanc independ dataset ira interrat agreement lr logist regress lr10 10-featur logist regress classifi lr5 5-featur logist regress classifi lr9 9-featur logist regress classifi lr-en-vf logist regress elast net penalti roc receiv oper characterist soc standard care svm support vector machin svm10 10-featur support vector machin svm12 12-featur support vector machin svm5 5-featur support vector machin uar unweight averag recal find mean • short home video provid suffici inform run machin learn classifi- er train detect child autism either typic atyp develop featur need machin learn model design detect autism identifi measur home video mobil devic nonexpert timefram close total video length 6 minut • machin learn model provid quantit indic autism risk pro- vide granular binari outcom flag inconclus case potenti add- ing valu use clinic set e.g. triag • process mobil video analysi autism detect gener grow matrix video featur use construct new machin learn model may higher accuraci autism detect home video • clinic prospect test gener pediatr set popul yet diag- nose need howev result support possibl mobil video analysi machin learn may enabl rapid autism detect outsid clinic reduc wait period access care reach underserv popul region limit healthcar infrastructur introduct neuropsychiatr disord singl greatest caus disabl due noncommunic diseas worldwid account 14 global burden diseas signific con- tributor metric autism spectrum disord risen inci- denc approxim 700 sinc 1996 2,3 impact 1 59 child unit state 4,5 asd arguabl one largest pediatr health challeng support individu condit cost 2.4 million his/her lifespan u 5 billion annual u healthcar cost like mental health condit autism complex array symptom diagnos behavior exam standard care autism diagnosi us behavior instrument autism diagnost observ schedul autism diagnost interview-revis standard exam similar other development pediatr requir direct clinician-to-child observa- tion take hour administ 11–14 sharp rise incid autism coupl unscal natur soc creat strain healthcar system wait time diagnost evalu reach exceed 12 month u averag age diagnosi u remain near 5 year age 2 13 underserv popul ’ averag age asd diagnosi high 8 year 16–18 high variabl avail diagnos- tic therapeut servic common psychiatri mental health condit across u sever shortag mental health servic 77 u counti behavior intervent asd impact administ 5 year age 12,20–23 howev diagnost bottleneck famili face sever limit impact therapeut intervent scalabl measur necessari allevi bottleneck reduc wait time access therapi reach underserv popul need mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 3 20 step toward enabl fast accur access care asd use supervis machin learn approach identifi minim set behavior align clinic diag- nose asd 24–30 assembl analyz item-level outcom administra- tion ado adi-r train test accuraci rang classifi ado focus analysi ordin outcom data modul 1 2 3 ass child limit vocabulari phrase speech fluent speech respect 3 ado modul us approxim 10 activ clinic obser- vation child risk 28–30 addit behavior measur use score child follow observ machin learn analysi focus archiv record categor ordin data gener score compon ado exami- nation similarli adi-r involv 93 multiple-choic question ask clinician child ’ primari care provid in-clin interview ado focus classif task ordin outcom data result test ’ administr preliminari studi focus build model optim accuraci sparsiti interpret differenti autism non-aut manag class imbal chose model small number featur perform 1 stan- dard error away best test perform interpret outcomes—for exampl score gener boost decis tree logist regress approach studi use score data 11,298 individu autism mix low- medium- high-sever autism 1,356 control includ child autism may suspect rule identifi follow 8 classifi 7-fea- ture altern decis tree 8-featur altern decis tree 12-featur support vector machin 9-featur lr classifi 5-featur support vector machin 5-featur lr classifi 10-fea- ture lr classifi 10-featur support vector machin two 8 classifi independ test 4 separ analysi pro- spectiv head-to-head comparison clinic outcom adtree7 measur prior clinic evalu offici diagnosi 222 child nasd 69 ncontrol 153 median age 5.8 year perform measur unweight averag recal 84.8 separ bone colleagu test adtree7 “ balanc independ dataset ” consist adi-r outcom data 680 particip 218 non-asd found perform similarli high 80 duda colleagu test adtree8 2,333 individu autism 283 “ non-aut ” control individu mean age 6.4 year found perform 90.2 bone colleagu also test adtree8 model 1,033 particip bid—858 autism mean age 5.2 year sd 3.6 year 73 autism spectrum 102 non-spec- trum —and found perform slightli higher 94 independ valid studi report classifi perform rang publish test accuraci lend addit support hypothesi model use mini- mal featur set reliabl accur autism detect other run similar train test experi identifi top-rank featur standard instrument data includ bone bussu approach arriv similar conclus name machin learn effect way build objec- tive quantit model featur distinguish mild- medium- high-sever autism child outsid autism spectrum includ developmen- tal disord howev translat model clinic practic requir addit step yet adequ address although earlier work mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 4 20 shown untrain video annot measur autism behavior home video high interrat reliabl accuraci question step must taken move minim behavior model clinic practic remain present studi build prior work address question hypothesi featur repres minim viabl classifi label quickli accur reliabl short home video video rater offici train autism diagnosi child develop deploy crowdsourc real-tim video analysi featur label- ing run evalu accuraci 8 machin learn model train detect autism 2 independ home video repositori procedur enabl u test abil reduc practic process rapid mobil video analysi viabl method identifi autism symptom screen addit mobil featur tag video automati- calli gener rich featur matrix present opportun train new artifici intelli- genc model potenti higher generaliz task automat detect autism short video clip test relat hypothesi construct novel video fea- ture classifi compar result altern model held-out subset origi- nal video featur matrix independ extern valid set result work support hypothesi autism detect done mobil devic outsid clinic set high effici accuraci method sourc classifi reduce-to-practic test assembl 8 publish machin learn classifi test viabil use rapid mobil detect autism short home video 8 model sourc train valid data medic record gener administr one two gold-standard instrument diagnosi autism ado adi-r ado sever modul contain approxim 30 featur correspond development level individu assess modul 1 use individu limit vocabu- lari modul 2 use individu use phrase speech fluent modul 3 use individu fluent speaker adi-r parent-direct interview includ 90 element ask parent multipl choic answer model train item-level outcom administr either ado adi-r optim accuraci sparsiti featur interpret purpos breviti without omiss detail opt creat abbrevi model use basic name convent abbrevi took form “ model_- type ” “ number features. ” exampl use adtree8 refer use altern decis tree 8 featur develop medic data administr diagnost instrument ado modul 1 lr5 refer lr 5 behavior featur develop analysi ado modul 2 medic record data adtree7 appli machin learn electron medic record data record administr adi-r diagnost assess child risk autism use 80 :20 train test split perform 10-fold cross-valid sampl 891 child autism 75 non-aut control particip adtre model contain 7 featur adtre us boost man- age class imbal 36,37 also perform up-sampl 1,000 bootstrap permu- tation manag class imbal model valid clinic trial 222 particip bid consist 680 individu lowest sensit specif exhibit 89.9 79.7 respect mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 5 20 adtree8 use dataset score sheet ado modul 2 612 child asd 15 non-aut control particip 90 :10 train test split 10-fold cross-valid train test adtre model 8 29 modul 2 fea- ture adtre us boost inher robust class imbal 36,37 also perform up-sampl 1,000 bootstrap permut test sensit model perform class imbal 8-featur adtre model independ test 446 individu autism wall colleagu 2,333 individu autism 238 without autism duda colleagu 1,033 individu 858 autism 73 autism spectrum 102 non-spectrum bone colleagu lowest sensi- tiviti specif report 97.1 83.3 respect lr9 perform train ado modul 2 record 362 individu autism 282 individu without autism backward featur select iter remov singl lowest-rank featur across 10 fold 90 :10 class split class weight invers proport class size manag imbal model highest sensit specif lowest number featur lr l1 regulari- zation 9 featur select test test model independ data 1,089 individu autism 66 individu autism diagnosi lowest sensitiv- iti specif identifi 98.8 89.4 respect svm12 use score sheet ado modul 3 gener evalu 510 child asd 93 non-asd control particip data split 90 train 10 test set train paramet tune perform stepwis backward featur select iter remov singl lowest-rank featur across 10 fold class weight invers proport class size manag imbal sever model fit featur cross-valid fold model highest sensi- tiviti specif lowest number featur support vector machin radial basi function appli test set measur gener error test model 1,924 individu autism 214 individu qualifi autism diagnosi lowest sensit specif identifi test set 97.7 97.2 respect lr5 svm5 experi use medic record gener administr ado modul 2 1,319 child autism 70 non-aut control particip dataset split 80 :20 train test set proport particip without asd set class imbal manag set class weight invers proport class size 10-fold cross-valid use select featur separ 10-fold cross-valid run hyperparamet tune prior test perform svm lr model l1 regular show highest test perform 5 featur lowest sensit specif exhibit test set svm5 98 58 respect 93 67 respec- tive lr5 lr10 svm10 experi use medic record gener administr ado modul 3 2,870 child autism 273 non-aut control particip dataset split 80 :20 train test set pro- portion particip without asd set class imbal manag set class weight invers proport class size 10-fold cross-valid use select featur separ 10-fold cross valid run hyperparamet tun- ing prior test perform svm lr model l1 regular show highest test perform 10 featur lowest sensit specif exhibit independ test set svm10 95 87 respect 90 89 respect lr10 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 6 20 account overlap featur select 8 model measur 23 uniqu featur total test accuraci model 90 model contain approxim 90 fewer question adi-r 70 –84 fewer question total featur mea- sure within ado addit 7 featur chosen potenti diagnost valu score video rater ass suitabl score home video creat total 30 featur mobil video rate process describ recruit video collect approv stanford univers irb protocol develop mobil portal facili- tate collect video child asd particip electron con- sent particip upload video particip recruit via crowdsourc method 38–41 target social medium platform listserv famili child autism interest particip direct secur encrypt video portal websit consent particip requir particip least 18 year age primari care provid child autism age 12 month 17 year partici- pant provid video either direct upload portal via refer video alreadi upload youtub togeth age diagnosi salient characterist consid video elig 1 5 minut length show face hand child show clear opportun direct social engag involv opportun use object utensil crayon toy fig 1 feature-to-classifi map video analyst score video 30 featur matrix show featur correspond classifi darker color featur indic higher overlap lighter color indic lower overlap across model featur rank order accord frequenc use across 8 classifi detail classifi provid tabl 1 bottom 7 featur part machin learn process chosen potenti relationship autism phenotyp use evalu model ’ featur set construct video feature–specif classifi adtree7 7-featur altern decis tree adtree8 8-featur altern decis tree lr5 5-featur logist regress classifi lr10 10-featur logist regress classifi svm5 5-featur support vector machin svm10 10-featur support vector machin svm12 12-featur support vector machin http //doi.org/10.1371/journal.pmed.1002705.g001 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 7 20 reli self-report inform provid parent concern child ’ offi- cial diagnosi autism non-aut age child video submit addit demograph inform video submit directli web portal video provid via youtub url use youtub metatag confirm age diagnosi child video video includ metatag age child video age assign follow full agreement among estim made 3 clinic practition pediatr evalu accuraci parent ’ self- report safeguard report bia commiss practic pediatr spe- cialist certifi administ ado review random select 20 video also commiss development pediatrician review nonoverlap random select 10 addit video clinic expert classifi video “ asd ” “ non-asd. ” featur tag video run machin learn model employ total 9 video rater either student high school undergradu graduate-level work profession none train certif detect diagnosi autism given instruct tag 30 question ask score 10 exampl video perform independ featur tag new video tabl 1 eight machin learn classifi use video analysi autism detect model construct analysi archiv medic record use standard instrument includ ado adi-r. 8 model identifi small stabl subset featur cross-valid experi total number affect unaffect control particip train test provid togeth measur accuraci test set four model test independ dataset mention separ “ test ” categori remain 4 indic “ train/test ” use given dataset 80 :20 train test split calcul test accuraci 20 held-out test set name convent classifi “ model type ” “ number featur ” classifi medic record sourc featur nasd nnon-asd mean age male test sensit test specif test accuraci adtree8 ado modul 1 8 train 612 train:15 6.16 76.8 100 100 100 test 446 test 0 test 2,333 test 238 test 931 test 102 adtree7 adi-r 7 train 891 train 75 8.5 65 100 1.13 99.9 test 222 test 0 test 462 test 218 svm l1 norm ado modul 2 5 train/test 1,319 train/test 70 6.92 80 98 58 98 lr l2 norm ado modul 2 5 train/test 1,319 train/test 70 6.92 80 93 67 95 lr l1 norm ado modul 2 9 train 362 train 282 11.75 76.4 98.81 89.39 98.27 test 1,089 test 66 radial kernel svm ado modul 3 12 train 510 train 93 16.25 76.4 97.71 97.2 97.66 test 1,924 test 214 linear svm ado modul 3 10 train/test 2,870 train/test 273 9.08 81 95 87 97 lr ado modul 3 10 train/test 2,870 train/test 273 9.08 81 90 89 94 abbrevi adi-r autism diagnost interview-revis ado autism diagnost observ schedul adtree7 7-featur altern decis tree adtree8 8-featur altern decis tree lr logist regress lr5 5-featur lr classifi lr10 10-featur lr classifi svm support vector machin svm5 5-featur svm svm10 10-featur svm svm12 12-featur svm http //doi.org/10.1371/journal.pmed.1002705.t001 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 8 20 train provid rater uniqu usernam password access secur onlin portal watch video answer 30 question video need fea- ture vector run 8 machin learn classifi featur present video rater multiple-choic question written approxim seventh-grad read level rater remain blind diagnosi throughout studi task choos one tag featur best describ child ’ behavior video respons featur map score 0 3 higher score indicat- ing sever autism featur measur behavior 8 indic featur could score behavior featur overlap across model provid fig 1 test viabil featur tag video rapid machin learn detect diag- nosi autism empir identifi minimum number video rater need score parent-provid home video select random subset video full set vid- eo collect crowdsourc portal ran adtree8 model featur vector tag 9 rater chose run adtree8 effici reason model previous valid 2 independ studi 25,32 use sample-with-replac permut procedur measur accuraci function major- iti rater agreement true diagnost classif increment increas number video rater per trial 1 rater start 1 end 9 draw replac 1,000 time per trial consid 2 rater requir perfect class agreement rater odd number rater requir strict major consensu even number rater disagre classif use indepen- dent randomli chosen rater ’ score break tie determin minim viabl number video rater use minimum gener full set 30-featur vector video seven model written python 3 use packag scikit-learn one written r. ran 8 model featur matrix featur tag video measur model accuraci comparison rater ’ major classif result true diagnosi evalu model perform age categori \\x142 year 2 \\x144 year 4 year \\x146 year 6 year categori calcul accuraci sensit specif collect time data rater video began video rater press “ play ” video conclud video rater finish score click “ submit ” video portal use time stamp calcul time spent annot video approxim time taken answer question exclud length video total time spent score video build video featur classifi process video featur tag provid opportun gener crowdsourc col- lection independ featur measur specif video child well independ rater impress child ’ behavior turn abil gener- ate valuabl featur matrix develop model includ video-specif featur rather featur identifi analysi archiv data gener administr soc end follow com- pletion annot video minimum number rater perform machin learn video featur set use lr elast net penalti lr- en-vf predict autism class non-aut class randomli split dataset train test reserv 20 latter use cross-valid train- ing set tune hyperparamet use cross-valid model hyperparamet mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 9 20 tune perform grid search differ valu alpha l1 ratio mix paramet determin much weight appli l1 versu l2 penalti base result area curv accuraci combi- nation select top-perform pair hyperparamet use pair train model use lr balanc class weight adjust weight invers proport class frequenc input data determin top-rank featur base train model result coeffici valid model reserv test set independ test set valid video phenotyp process use video portal crowdsourc approach gener independ collec- tion video evalu featur tag 3 differ rater use pri- mari analysi rater similar characterist origin group age educ clinic certif development pediatr train video tag procedur ethic statement studi conduct approv stanford univers ’ irb protocol irb- 31099 inform written consent obtain studi particip submit video studi result classifi use test time accuraci mobil video rate accuraci 90 union featur across 8 classifi 23 featur plu addit 7 chosen clinic valid test load mobil video rate portal enabl remot featur tag nonclin video rater collect total 193 video averag video length 2 minut 13 sec- ond 119 asd video 72 direct submiss made tabl 2 demograph inform child collect home video collect n 193 home video analysi exclud 31 video inadequ label video qualiti use randomli chosen 25 autism 25 non-aut video empir defin optim number rater video featur tag machin learn done 162 home video video n nasd nnon- asd mean age \\x142 year 2 year \\x144 year 4 year \\x146 year 6 year percent male asd percent male non-asd total 193 119 74 4 year 4 month 2 year 1 month 24.4 33.7 25.9 15.5 39.38 23.32 exclud 31 3 28 3 year 8 month 1 year 11 month 32.3 29.0 25.8 9.6 3.23 58.06 total video use analysi 8 classifi 162 116 46 4 year 4 month 2 year 2 month 22.8 34.5 25.9 16.7 67.2 56.5 subset video use find minim viabl number rater 50 25 25 4 year 6 month 2 year 4 month 28 34 18 20 48 44 abbrevi asd autism spectrum disord http //doi.org/10.1371/journal.pmed.1002705.t002 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 10 20 primari caregiv child 47 link exist video youtub 74 non-asd video 46 non-asd video link exist youtub video 28 direct submiss primari caregiv exclud 31 video insuffici evid diagnosi inadequ video qualiti leav 162 video 116 asd 46 non-asd load mobil video rate portal pri- mari analysi valid self-report presenc absenc asd diagnosi 2 clinic staff train certifi autism diagnosi evalu random select 30 video 162 video classif perfect corre- spondenc diagnosi provid self-report primari caregiv randomli select 50 video total 162 collect video 9 rater featur tag effort evalu potenti optim num- ber rater optim defin balanc scalabl inform con- tent averag video length random subset 1 minut 54 second sd 46 second asd class 2 minut 36 second non- asd class ran adtree8 model featur vector gener 9 rater found differ accuraci statist insignific 3 raters— minimum number major consensu classif ties—and 9 fig 2 accuraci across differ permut 9 rater 50 video perform analysi determin optim number minimum number reach consensu classif video rater need maintain accuraci without loss power nine rater analyz gener featur tag subset n 50 video ran adtree8 classifi increas accuraci confer use 3 versu 9 rater signific therefor set optim rater number 3 subsequ analysi adtree8 8-featur altern decis tree asd autism spectrum disord http //doi.org/10.1371/journal.pmed.1002705.g002 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 11 20 rater therefor elect use random select 3 rater 9 featur tag 162 crowdsourc home video model perform three rater perform video screen featur tag gener vector 8 machin learn model compar evalu perform classifi sensit 94.5 howev 3 8 model exhibit specif 50 top-perform classifi lr5 show accuraci 88.9 sensit 94.5 specif 77.4 next-best-perform model svm5 85.4 accuraci lr10 84.8 accuraci lr5 exhibit high accuraci age rang except child 6 year old model perform best child age 4 6 year sensit speci- ficiti 90 svm5 lr10 show increas perform child age 2–4 year 100 sensit former 66.7 latter 58.8 specif 3 rater agre unanim 116 162 video use top-perform classifi lr5 interrat agreement model 75 age rang except youngest age group child fig 3 overal procedur rapid mobil classif asd versu non-asd perform model tabl 1 particip recruit particip via crowdsourc method provid video direct upload via preexist youtub link minimum major rule 3 video rater tag featur gener featur vector run 8 classifi automat sensit specif base major outcom gener 3 rater 162 video provid highlight yellow best perform model lr5 adtree7 7-featur altern decis tree adtree8 8-featur altern decis tree asd autism spectrum disord lr5 5-featur logist regress classifi lr9 9-featur logist regress classifi lr10 10-featur logist regress classifi svm5 5-featur support vector machin svm10 10-featur support vector machin svm12 12-featur support vector machin http //doi.org/10.1371/journal.pmed.1002705.g003 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 12 20 2 year greater frequenc disagr number non- asd repres small older age rang evalu median time 3 rater watch score video 4 minut exclud time spent watch video rater requir median 2 minut 16 second tag 30 featur analyst portal found signific differ averag time spent score video child asd averag time spent score non-asd video 6 minut 36 second compar 5 minut 8 second independ valid valid feasibl accuraci rapid featur tag machin learn short home video launch second effort crowdsourc video child with- autism gener independ replic dataset collect 66 video 33 chil- dren autism 33 non-asd set video compar initi set 162 video term gender age video length averag age child asd 4 year 5 month averag age non-asd child 3 year 11 month forty-two percent child asd male 45 non-asd child male averag video length 3 minut 24 second sd 45 second independ replic use 3 dif- ferent rater offici train experi development pediatr rater requir median time 6 minut 48 second complet featur tag lr5 yield highest accuraci sensit 87.8 specif 72.7 total 13 66 video misclassifi 4 fals neg fig 4 perform lr5 age lr5 exhibit highest classifi perform 8 classifi test model perform best child age 2 6 year show perform lr5 across 4 age rang provid roc curv lr5 ’ perform child age 2 6 year tabl 3 provid addit detail includ number affect unaffect control particip within age rang auc area curv lr5 5-featur logist regress classifi roc receiv oper characterist http //doi.org/10.1371/journal.pmed.1002705.g004 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 13 20 given higher averag time video evalu hypothes video con- tain challeng display autism symptom therefor examin probabl gener lr5 model 13 misclassifi video two 4 fals neg 4 9 fals posit borderlin probabl score 0.4 0.6 elect defin probabl threshold 0.4 0.6 flag video inconclus case twenty- six 66 video fell within inconclus group appli threshold exclud 26 accuraci analysi sensit specif increas 91.3 88.2 respect tabl 3 model perform age tabl detail accuraci sensit specif precis recal 8 classifi 4 age rang found evalu 162 home video averag length 2 minut also provid ira indic frequenc model result 3 rater ’ featur tag agre class top-perform classifi lr5 yield accuraci 88.9 sensit 94.5 specif 77.4 notabl classifi- er svm5 lr10 yield 85.4 84.8 accuraci respect 3 best-perform classifi show improv classif power within certain age rang age group statist adtree8 adtree7 svm5 lr5 lr9 svm12 svm10 lr10 overal sensit 100 94.5 100 94.5 100 100 100 100 specif 22.4 37.3 54.9 77.4 31.4 0 17.6 51.0 accuraci 76.1 76.3 85.4 88.9 78.4 71.6 73.9 84.8 ira 76.1 67.5 68.4 71.7 75.9 71.6 79.5 70.9 precis 74.3 76.3 82.3 89.7 76.0 71.6 72.4 82.0 uar 61.2 65.9 77.5 86.0 65.7 50 58.8 75.5 \\x142 year sensit 100 100 100 93.3 100 100 100 100 specif 14.2 18.2 38.1 77.3 22.7 0 14.3 47.6 accuraci 50 51.4 62.9 83.8 54.1 40.5 50.0 96.2 ira 53 48.6 45.7 51.4 48.6 100 66.7 100 precis 45.5 45.5 51.9 73.7 46.9 45.9 45.4 57.7 uar 57.1 59.1 69.1 85.3 61.4 50.0 57.2 73.8 2 year \\x144 year sensit 100 97.3 100 91.8 100.0 100 100 100 specif 23.6 50 66.7 73.7 38.9 0 22.2 58.8 accuraci 76.4 50 88.9 85.7 80.4 66.7 74.5 86.8 ira 74.5 81.8 63.0 75.0 76.8 100 85.4 77.4 precis 74.5 80.0 85.7 87.2 77.6 69.6 72.5 83.7 uar 61.8 73.7 83.4 82.8 69.5 50.0 61.1 79.4 4 year \\x146 year sensit 100 96.8 100 96.9 100.0 100 100 100 specif 40.0 60 72.7 90.9 40.0 0 18.2 50.0 accuraci 85.4 87.8 92.9 95.3 85.7 74.4 79.1 88.1 ira 85.4 78.0 78.6 79.1 85.7 93.0 76.7 71.4 precis 83.8 88.2 91.2 96.9 84.2 80.9 78.0 86.5 uar 70.0 78.4 86.4 93.9 70.0 50.0 59.1 75.0 6 year sensit 100 84.6 100 96.2 100 100 100 100 specif 0 0 0 0 0 0 0 0 accuraci 96.2 81.5 96.2 92.6 96.2 96.2 96.2 96.3 ira 96.2 70.4 96.2 81.5 96.2 100 100 85.2 precis 96.3 95.7 96.3 96.2 96.3 96.3 96.3 96.3 uar 50.0 42.3 50.0 48.1 50.0 50.0 50.0 50.0 abbrevi adtree7 7-featur altern decis tree adtree8 8-featur altern decis tree asd autism spectrum disord ira interrat agreement lr5 5-featur logist regress classifi lr9 9-featur logist regress classifi lr10 10-featur logist regress classifi svm5 5-featur support vector machin svm10 10-featur support vector machin svm12 12-featur support vector machin uar unweight averag recal http //doi.org/10.1371/journal.pmed.1002705.t003 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 14 20 train video feature–specif classifi build video feature–specif classifi train lr-en-vf model 528 3 rat- er × 176 video novel measur 30 video featur use distinguish autism class neurotyp cohort 176 video 162 analysi set 14 video asd 5 non- asd 12 set 66 valid video model hyperparamet alpha l1 ratio identifi 10-fold cross-valid 0.01 0.6 respect use high l1 ratio enforc sparsiti decreas model complex number featur similar proport non-asd asd measur train set held-out test set allow u creat model gener well without signific chang sensit specif novel data model area receiv oper characterist curv 93.3 accuraci 87.7 held-out test set comparison lr-en-vf lr l2 penalti reveal similar result top-8 featur select model consist follow order highest lowest rank speech pattern commu- nic engag understand languag emot express sensori seek respons social smile stereotyp speech one 8 features—sensori seeking—wa part full set item standard instrument data use develop test 8 model depict tabl 1 valid classifi remain 52 video valid set result show accuraci 75.5 auc-roc 86.0 discuss previou work 26–29 shown machin learn model built record stan- dard autism diagnosi achiev high classif accuraci small number fea- ture although promis term minim featur requir abil gener accur risk score potenti improv autism diagnosi practic tabl 4 time requir mobil tag video featur need run machin learn model highlight averag length video particip particip asd particip without asd well averag time requir watch score video averag time requir start end score compon alon total time requir review featur tag total time requir featur tag alon video length overal mean 6 minut 9 second 3 minut 36 second 5 minut 52 second 2 minut 13 second 1 minut 40 second median 4 minut 0 second 2 minut 16 second 1 minut 45 second rang 1 minut 0 second 37 minut 0 second 0 minut 50 second 35 minut 42 second 0 minut 25 second 8 minut 6 second asd mean 6 minut 36 second 4 minut 22 second 6 minut 20 second 2 minut 4 second 1 minut 40 second median 5 minut 0 second 2 minut 40 second 1 minut 30 second rang 1 minut 0 second 37 minut 0 second 0 minut 50 second 35 minut 42 second 0 minut 25 second 8 minut 6 second non-asd mean 5 minut 8 second 2 minut 18 second 4 minut 22 second 2 minut 38 second 1 minut 34 second median 4 minut 0 second 1 minut 21 second 2 minut 11 second rang 1 minut 0 second 30 minut 0 second 0 minut 50 second 25 minut 42 second 0 minut 36 second 6 minut 42 second abbrevi asd autism spectrum disord http //doi.org/10.1371/journal.pmed.1002705.t004 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 15 20 remain open question present studi test abil reduc model practic home video evalu nonexpert use mobil platform e.g. tablet smart- phone independ tag 30 featur 3 rater blind diagnosi enabl major rule machin learn classif 162 two-minut home video median 4 minut 90 auc child age 20 month 6 year perform main- tain 89 auc prospect collect independ extern set 66 video 3 independ rater measur vector take advantag probabl score gener best-perform model l1-regular lr model 5 featur flag low-confid case abl achiev 91 auc suggest approach could benefit use score quantit scale rather binari classif outcom use mobil format access onlin show possibl get multipl independ featur vector classif potenti elev confi- denc classif outcom time diagnosi foster growth novel matrix featur short home video second part studi test abil video featur matrix enabl develop new model gener task video-bas classif autism found 8-featur lr model could achiev auc 0.93 held-out subset 0.86 prospect independ valid set one featur use model sensori seek use instrument origin model train suggest- ing possibl altern featur may provid ad power video classif result support hypothesi detect autism done effect scale mobil video analysi machin learn classif produc quanti- fie indic autism risk quickli process could streamlin autism diagnosi enabl earlier detect earlier access therapi highest impact earlier window social develop approach could help reduc geograph financi burden associ access diagnost resourc provid equal fig 5 roc curv lr-en-vf show perform test data along roc l2 loss featur reduct former chose 8 30 video featur auc area curv lr-en-vf logist regress elast net penalti roc receiv oper characterist http //doi.org/10.1371/journal.pmed.1002705.g005 mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 16 20 opportun underserv popul includ develop countri test- ing refin conduct identifi viabl method crowdsourc- ing video acquisit featur tag addit prospect trial undiagnos larger more-balanc cohort includ exampl child non-aut development delay need better understand approach ’ potenti use autism diagnosi support inform s1 tabl result 8 classifi independ valid set lr10 lr5 adtree7 top-3 best-perform classifi valid set fall line result observ test dataset 162 video use earlier lr5 still perform high- est specif 8 model adtree7 7-featur altern decis tree lr5 5-featur logist regress classifi lr10 10-featur logist regress classifi s1 text instruct video rater s1 checklist tripod checklist acknowledg would like thank kaitlyn dunlap particip famili video rater import contribut studi author contribut conceptu denni paul wall data curat qandeel tariq jena daniel jessey nicol schwartz peter washington haik kalantarian denni paul wall formal analysi qandeel tariq peter washington haik kalantarian denni paul wall fund acquisit denni paul wall investig qandeel tariq jena daniel jessey nicol schwartz denni paul wall methodolog qandeel tariq jena daniel denni paul wall project administr jena daniel jessey nicol schwartz denni paul wall resourc jena daniel jessey nicol schwartz peter washington haik kalantarian denni paul wall softwar qandeel tariq denni paul wall supervis denni paul wall valid qandeel tariq denni paul wall visual qandeel tariq jessey nicol schwartz denni paul wall write – origin draft qandeel tariq jessey nicol schwartz denni paul wall write – review edit qandeel tariq jena daniel jessey nicol schwartz peter wash- ington haik kalantarian denni paul wall mobil detect autism machin learn home video plo medicin http //doi.org/10.1371/journal.pmed.1002705 novemb 27 2018 17 20', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6cebbe0b-4b08-4630-a4e4-51e65756f5e2', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Tariq_2019_cleaned.txt', 'file_name': 'Tariq_2019_cleaned.txt', 'file_type': 'text/plain', 'file_size': 0, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3b52d333-c25f-48c3-a52f-4ad4da0b4387', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/Young_Behavior_cleaned.txt', 'file_name': 'Young_Behavior_cleaned.txt', 'file_type': 'text/plain', 'file_size': 16462, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='video-bas measur identifi autism risk infanc gregori s. young phda john n. constantino mdb simon dvorak bsc ashleigh beld mpha devon gangi phda alesha hill baa moniqu hill maa meghan miller phda chandni parikh phda aj schwichtenberg phdd erika soli bsa salli ozonoff phda adepart psychiatri behavior scienc mind institut univers california-davi bdepart psychiatri washington university-st. loui school medicin cinform educ technolog univers california-davi ddepart human develop famili studi purdu univers abstract background sign autism present first two year life averag age diagnosi lag far behind instrument improv detect autism risk infanc need studi develop test psychometr properti novel video-bas approach detect asd infanc method prospect longitudin studi child elev lower risk autism spectrum disord conduct particip 76 infant older sibl asd 37 infant known famili histori autism video-referenc infant rate system autism web-bas applic present pair video parent infant play togeth requir forced-choic judgment video similar child rate parent rate particip virsa 6 9 12 18 month age examin split-half test-retest reliabl converg discrimin valid sensit specif neg posit predict valu concurr 36-month asd diagnosi result virsa demonstr satisfactori reliabl converg discrimin valid virsa rate significantli lower child ultim diagnos asd child typic develop 12 month age virsa score 18 month identifi child diagnos asd age well 78 child diagnos 36 month conclus studi repres initi step develop novel video-bas approach detect asd infanc virsa ’ psychometr properti promis use parent older affect child still must test commun sampl famili histori asd result replic virsa ’ low-burden web-bas format potenti reduc dispar commun limit access screen keyword autism screen infanc social develop correspond salli ozonoff mind institut uc davi health 2825 50th street sacramento ca 95817 916-703-0259 sozonoff ucdavis.edu hh public access author manuscript j child psychol psychiatri author manuscript avail pmc 2021 januari 01 publish final edit form j child psychol psychiatri 2020 januari 61 88–94 doi:10.1111/jcpp.13105 author manuscript author manuscript author manuscript author manuscript introduct development cours autism spectrum disord involv onset symptom first three year life differ child later receiv asd diagnosi typic develop emerg second birthday gammer et al. 2015 landa garrett-may 2006 ozonoff et al. 2010 zwaigenbaum et al. 2005 studi document sign first year life maestro et al. 2002 miller et al. 2017 werner dawson osterl dinno 2000 parent first express concern averag age 14 month despit advanc knowledg earliest present asd mean age diagnosi stubbornli remain 4 year declin last two decad squander year potenti intervent brain plastic critic attempt made decreas age asd diagnosi better align age first symptom emerg one identifi barrier prompt recognit asd measur al qabandi gorter rosenbaum 2011 last decad much effort gone develop instrument earlier detect asd feasibl method large-scal screen parent report exist measur use methodolog howev recent studi demonstr low agreement parent report object measur asd symptom well lower reliabl screen instrument use rural low incom le educ racial divers sampl popul screen studi 10,479 twelve-month-old use parent- report measur identifi 32 infant asd repres signific under-identif even account case later onset sinc current preval studi estim 170 10,000 child asd lower sensit earli screen measur may due subtleti initi asd symptom difficulti accur convey parent written descript major sourc error parent questionnair includ comprehens interpret problem limit understand queri construct inadequ knowledg development mileston bia due post-ev inform current studi move beyond verbal descript employ video exampl reduc subject interpret use video shown dramat increas clariti field music instruct motor vehicl repair recent video incorpor asd screen marru colleagu parent complet rate watch video social compet toddler order “ reduc discrep interpret item provid inform common naturalist standard comparison ” describ develop new instrument video-referenc infant rate system autism extend previou approach young et al page 2 j child psychol psychiatri author manuscript avail pmc 2021 januari 01 author manuscript author manuscript author manuscript author manuscript creat larg librari video clip depict wide rang social-commun abil reli sole video rate written descript behavior hypothes semant clariti afford video would improv earli discrimin infant highest risk asd method instrument develop virsa develop use video particip longitudin infant sibl studi valid independ sampl infant video use virsa drawn archiv 300,000 minut digit video record clinic laboratori set video depict infant parent play togeth age-appropri toy segment select task use standard toy set instruct parent play child would home schwichtenberg kellerman miller young ozonoff 2019 video record util consist camera angl face child parent profil famili gave inform consent legal author includ video virsa social behavior includ smile vocal eye contact code research assist unawar particip risk group outcom use previous valid code scheme sensit chang occur onset asd symptom earli 6 month order includ broad rang behavior virsa candid video rank frequenc code behavior twenty-second segment excis origin video file result collect 3,000 video segment 100 past particip 6 18 month age next video segment rate 9 clinic research staff scale 1 10 clinician rate randomli select set 39 video twice establish test-retest reliabl mean=0.89 rang 0.78–0.98 inter-rat reliabl examin larger randomli select set 260 video clip rate rater use two-way random icc model averag measur icc absolut agreement 0.92 lower bound 0.86 suggest strong inter- rater reliabl 10-point scale video segment exclud poor light audio qualiti obscur video angl use child ’ name result pool video compris 1,132 individu 20-second clip constrain insur adequ represent across 10-point rate scale within age 6 9 12 18 month limit softwar overhead virsa app 268 video randomli select creat final virsa video librari final pool video includ segment 11 child asd 23 child non-asd development concern e.g speech-languag delay 29 child typic develop base 36-month outcom thirty-eight child depict virsa video male 43 non-hispan caucasian analysi rate virsa video use gener linear model random effect subject age reveal signific group effect asd video rate averag 4.18 video child non-asd development concern rate averag 6.14 video typic develop young et al page 3 j child psychol psychiatri author manuscript avail pmc 2021 januari 01 author manuscript author manuscript author manuscript author manuscript particip rate averag 6.35 simpl comparison indic rate asd video differ significantli video non- asd development concern typic develop case t=2.62 p= 013 differ one anoth expect sinc virsa design specif detect social-commun behavior relev asd broader development delay pattern result provid valid final video pool librari video segment incorpor web-bas applic present pair video depict differ degre social compet side side accompani prompt “ video like child ’ interact typic day ” trial video left play automat follow video right point viewer select one like child present video follow algorithm alway began pair video rate 3 8 10-point scale choic algorithm select display second pair video new scale valu conting upon previous chosen video ’ rank subsequ trial viewer ’ video choic dictat rang sociabl repres video next trial analog optometrist help patient select eyeglass prescript way algorithm present video increas similar subsequ trial distanc video reduc 1 rate scale point 2 subsequ trial point averag rate last 2 trial record final score virsa web applic design brief introductori video orient parent concept rang social behavior depict video provid rate instruct virsa app also ask confirm child ’ age order present video match age group sinc multipl video exemplar scale point avail video sampl pool without replac uc davi institut review board approv studi procedur parent sign inform consent form prior particip complet virsa rate child 6- 9- 12- 18-months-old two week later examin test-retest reliabl autom email invit parent onlin virsa app could access comput mobil devic virsa rate alway done prior in-person assess conduct 6 12 18 24 36 month examin unawar risk group previou test result particip virsa valid sampl consist 110 infant 73 older sibl asd 37 known famili histori autism none suppli video use instrument develop twenty-on child famili high-risk group receiv diagnosi asd wherea none low-risk child asd diagnosi made age child met dsm-5 criterion base inform avail one child diagnos asd 12 month 7 diagnos 18 month 7 24 month 6 36 month child diagnos 36 month retain asd diagnosi final visit rest sampl classifi non-asd young et al page 4 j child psychol psychiatri author manuscript avail pmc 2021 januari 01 author manuscript author manuscript author manuscript author manuscript stratifi famili risk yield hr non-asd lr non-asd comparison group descript statist shown tabl 1 measur mullen scale earli learn assess cognit motor languag develop child age 1 68 month msel score use describ sampl score fine motor visual recept subtest use evalu discrimin valid sinc development domain theoret unrel social-commun focu virsa autism diagnost observ schedul 2nd edit observ measur ass asd symptom semi-standard interact clinician child compris five modul appropri variou age languag level toddler modul administ 18 24 month either modul 1 2 use 36 month depend upon child ’ verbal level analysi util overal total algorithm social affect restrict repetit behavior sarrb score score ado 18 month also use examin converg valid virsa rate 18 month analysi plan psychometr properti virsa examin sever way split-half reliabl analyz compar first half rate within given session second half test-retest reliabl analyz compar initi virsa rate obtain two week later parent shown seri pair video seen two week earlier instead video pair dictat virsa algorithm permit examin reliabl individu trial choic converg valid examin correl 18 month concurr sarrb algorithm score ados-2 toddler modul discrimin valid examin correl virsa score concurr msel fine motor visual recept age equival predict valid assess examin diagnost outcom group differ virsa score age use mix model group age interact includ fix effect virsa score time-vari depend variabl also use roc analysi ass virsa ’ sensit specif posit predict valu neg predict valu predict asd diagnosi area curv comput measur abil distinguish group sampl size initi project 90 high-risk 45 low-risk infant anticip asd outcom rate approxim 20 high-risk group power estim .82 detect auc valu .70 roc analysi analysi conduct r version 3.5.0 result virsa trial took averag 56.49 second averag number trial final score reach 7.67 complet virsa take averag 7.21 minut split-half reliabl moder r=.48 young et al page 5 j child psychol psychiatri author manuscript avail pmc 2021 januari 01 author manuscript author manuscript author manuscript author manuscript test-retest reliabl rel strong 72 video choic made two week later significantli greater chanc converg valid correl concurr ados-2 sarrb algorithm score 18 month r=−.36 significantli stronger discrimin valid correl concurr msel fine motor visual recept r= 10 fisher ’ z=2.11 p .05 age equival score figur 1 show model parent virsa score group 6 18 month examin model reveal main effect group main effect age interact age group signific plan contrast reveal signific differ virsa score asd comparison group 6 month hr non-asd t=0.71 p=0.48 lr non-asd t=0.89 p=0.38 9 month 12 month virsa score significantli lower asd group hr non- asd lr non-asd group 18 month virsa score significantli lower asd group hr non-asd group t=3.29 p=.002 margin lower lr non-asd group roc analysi conduct virsa score age predict binari 36-month outcom threshold/cutoff roc analysi best separ asd non-asd case defin virsa score closest theoret limit maximum specif sensit virsa perform best 18 month tabl 3 present roc model examin well virsa score 18 month predict concurr 18-month diagnosi sensit 100 specif posit predict valu low discuss hypothes employ video exampl within screen tool would enabl detect asd infanc start 12 month age virsa rate significantli lower group eventu diagnos asd comparison group sensit 18-month virsa score predict 36-month diagnosi approxim 0.80 compar quit favor studi report sensit 18-month clinic diagnost assess predict 36-month diagnosi 0.37 fact virsa score better sensit even 6–12 month age report clinic diagnosi 18 month ozonoff et al hypothes use video allow parent “ see ” differ child preced full onset symptom virsa ’ sensit especi impress given extend time cours develop asd symptom multipl previou studi demonstr symptom slowli unfold first two year life mani child ultim diagnos asd show overt sign first birthday gammer et al. 2015 landa garrett-may 2006 ozonoff et al. 2010 zwaigenbaum et al. 2005 child identifi virsa may yet show sign asd parent rate young et al page 6 j child psychol psychiatri author manuscript avail pmc 2021 januari 01 author manuscript author manuscript author manuscript author manuscript also examin virsa ’ abil index concurr symptom roc analysi virsa rate 18 month identifi eight child diagnos asd age fals neg recent meta-analysi accuraci asd screener 14 36 month age report pool sensit 0.72 specif 0.98 sensit virsa 18 month thu compar better exist measur suggest may use adjunct identifi toddler need referr asd evalu specif posit predict valu howev lower recommend standard result over-identif risk reason present result support use virsa stand-alon asd screener infanc yet futur studi could examin whether use virsa initi step two-stag screen process improv accuraci addit predict valid virsa examin number psychometr properti test-retest reliabl strong parent select 70 video retook virsa two week later virsa score 18 month significantli correl ados-2 score correl significantli higher measur diverg abil e.g. fine motor visual recept skill major particip child develop asd came high- risk group imper prior recommend virsa clinic use examin psychometr properti use parent naïv asd posit predict valu instrument depend upon base rate condit popul thu virsa ’ predict abil may reduc community-bas sampl lower preval asd high-risk famili studi current underway laboratori determin whether present result gener low-risk sampl despit limit virsa make sever contribut literatur first demonstr possibl develop parent report instrument capabl identifi asd risk first year life second demonstr video use clarifi development phenomenon improv parent report earli develop final innov virsa web-bas mobile-optim applic 90 american adult childbear age smartphon rate 65 even lower incom rural minor commun vital screen procedur keep pace advanc technolog societi ’ increasingli internet-bas prefer inform acquisit commun thu studi provid initi step proof principl video- web-bas screen asd develop virsa low-burden quick onlin rate potenti reduc dispar commun limit access screen provid possibl initi intervent full symptom set asd emerg supplementari materi refer web version pubm central supplementari materi young et al page 7 j child psychol psychiatri author manuscript avail pmc 2021 januari 01 author manuscript author manuscript author manuscript author manuscript acknowledg work support nih grant r01 mh099046 u54 hd079125 abbeduto mind institut intellectu development disabl research center autism speak grant 8370 deepli grate parent author use child ’ video develop virsa child famili particip valid studi disclosur dr. constantino receiv royalti western psycholog servic commerci distribut social respons scale dr. miller receiv research grant fund nation institut health travel reimburs and/or honorarium societi clinic child adolesc psycholog help group dr. ozonoff receiv research grant fund nation institut health autism speak travel reimburs honorarium editori activ autism speak autism scienc foundat wiley book royalti guilford press american psychiatr press inc. dr. schwichtenberg receiv grant fund nation institut health travel support autism speak autism scienc foundat author report financi disclosur potenti conflict interest abbrevi asd autism spectrum disord virsa video-referenc infant rate system autism', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9c29aaac-b2e8-45d9-a444-acbe26a7549c', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/carpenter2020 (1)_cleaned.txt', 'file_name': 'carpenter2020 (1)_cleaned.txt', 'file_type': 'text/plain', 'file_size': 26249, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='research articl digit behavior phenotyp detect atyp pattern facial express toddler autism kimberli l. h. carpent jordan hahemi kathleen campbel steven j. lippmann jeffrey p. baker helen l. egger steven espinosa saritha vermeer guillermo sapiro geraldin dawson commonli use screen tool autism spectrum disord gener reli subject caregiv questionnair behavior observ object also expens time-consum requir signiﬁc expertis perform remain critic need develop feasibl scalabl reliabl tool character asd risk behavior studi assess util tablet-bas behavior assess elicit detect one type risk behavior name pattern facial express 104 toddler evalu whether pattern differenti toddler without asd assess consist child sit his/her caregiv ’ lap watch brief movi shown smart tablet embed camera record child ’ facial express com- puter vision analysi automat detect track facial landmark use estim head posi- tion facial express use cva speciﬁc point throughout movi identiﬁ reliabl differenti child without asd base pattern facial movement express instanc child asd frequent display neutral express compar child without asd express frequenc express driven non-asd child often display rais eye- brow open mouth characterist engagement/interest preliminari result suggest comput code facial movement express via tablet-bas assess detect differ affect express one earli core featur asd autism re 2020 00 1–12 © 2020 intern societi autism research wiley period llc lay summari studi test use tablet behavior assess young child autism child watch seri development appropri movi facial express record use camera embed tablet result suggest comput assess facial express may use earli detec- tion symptom autism keyword autism risk behavior facial express comput vision earli detect introduct autism spectrum disord reliabl diagnos earli 24 month old risk sign detect earli 6–12 month old dawson bernier 2013 luyster et al. 2009 despit aver- age age diagnosi unit state remain around 4 year age christensen et al. 2016 mix evid stabil autism trait earli childhood bieleninik et al. 2017 waizbard-bartov et al. 2020 delay diagnosi still impact time intervent critic window develop respons 2007 american academi pedi- atric publish guidelin support need child screen asd 18- 24-month age part well-child visit myer johnson council child disabl 2007 current screen typic reli caregiv report modiﬁ checklist asd toddlers— revis follow-up robin et al. 2014 evid suggest two-tier screen- ing approach includ direct observ assess child improv posit predict valu m-chat screen 48 khowaja robin duke center autism brain develop depart psychiatri behavior scienc duke univers school medicin dur- ham north carolina usa depart electr comput engin duke univers durham north carolina usa depart pediatr univers utah salt lake citi utah usa depart popul health sci- enc duke univers school medicin durham north carolina usa depart pediatr duke univers school medicin dur- ham north carolina usa nyu langon child studi center new york univers new york new york usa depart biomed engin comput scienc mathemat duke univers durham north carolina usa duke institut brain scienc duke univers durham north carolina usa receiv april 7 2020 accept public august 24 2020 address correspond reprint kimberli l. h. carpent duke center autism brain develop depart psychiatri behavior scienc duke univers school medicin 2608 erwin rd 300 durham nc 27705 e-mail kimberly.carpent duke.edu publish onlin 00 month 2020 wiley onlin librari doi 10.1002/aur.2391 © 2020 intern societi autism research wiley period llc insar autism research 000 1–12 2020 1 adamson 2017 may reduc ethnic/raci dispar gener screen guthri et al. 2019 current tool observ assess asd sign infant toddler autism observ scale infant autism diagnost observ schedul take substanti time train administ result shortag qualiﬁ diagnostician per- form observ assess remain critic need develop feasibl scalabl reliabl tool character asd risk behavior identifi child need follow-up asd specialist effort address critic need embark program research use comput vision analysi develop tool digit phenotyp earli emerg risk behavior asd dawson sapiro 2019 success digit screen tool opportun help exist practition reach child assist triag boundari case review specialist one earli emerg sign asd tendenc often display neutral facial expres- sion pattern evid qualiti facial express share emot express other adrien et al. 1993 baranek 1999 s. clifford dissanayak 2009 s. clifford young williamson 2007 s. m. clifford dissanayak 2008 maestro et al. 2002 osterl daw- son munson 2002 werner dawson osterl dinno 2000 restrict rang emot expres- sion integr eye gaze e.g. social referenc found differenti child asd typic develop child well development delay earli 12 month age adrien et al. 1991 s. clifford et al. 2007 fillit et al. 2015 gangi ibanez messing 2014 nichol ibanez foss-feig stone 2014 core featur asd vari age cognit abil languag one stabl symptom earli childhood adolesc increas frequenc neutral express bal kim fok lord 2019 differ facial affect may show util assess earli risk asd recent meta-analysi facial express product autism found individu asd display facial express le often non-asd particip display facial express expres- sion occur shorter durat differ qualiti non-asd individu trevisan hoskyn birmingham 2018 decreas frequenc emot facial express share express other demonstr across naturalist interact bieberich morgan 2004 czapinski bryson 2003 dawson hill spencer galpert watson 1990 mcgee feldman chernin 1991 snow hertzig shapiro 1987 tantam holm cordess 1993 lab-bas assess ado owada et al. 2018 aosi fillit et al. 2015 respons emotion-elicit video trevisan bower birmingham 2016 fur- thermor higher frequenc neutral express corre- late social impair child asd owada et al. 2018 differenti chil- dren delay bieberich morgan 2004 yirmiya kasari sigman mundi 1989 fre- quenci durat facial affect promis earli risk marker young child autism previou research atyp facial express chil- dren asd reli hand code facial expres- sion time intens often requir signiﬁc train bieberich morgan 2004 s. clifford et al. 2007 dawson et al. 1990 gangi et al. 2014 mcgee et al. 1991 nichol et al. 2014 snow et al. 1987 approach scalabl use gen- eral asd risk screen behavior biomark outcom assess use larg clinic trial ﬁeld move toward autom code facial express one earliest studi approach guha colleagu demonstr chil- dren asd atyp facial express mimick other howev technolog requir child wear marker face data cap- ture guha yang grossman narayanan 2018 guha et al. 2015 invas scalabl recent sever group appli non-invas cva technolog measur affect older child adult asd within laboratori set capriola-hal et al. 2019 owada et al. 2018 samad et al. 2018 repres import move toward scalabl cva approach reli presenc physic marker face extract emot infor- mation rather cva reli video individu featur around speciﬁc region face e.g. mouth eye extract notabl featur mirror use manual rate facial affect cod- ing system ekman 1997 earlier work hashemi et al. 2018 other capriola-hal et al. 2019 shown good concord human code cva rate facial emot fur- thermor previou research adult demonstr cva detect neutral facial express reli- abli human coder lewinski 2015 build previou work appli cva laboratori set develop portabl tablet-bas tech- nolog us embed camera automat cva code asd risk behavior 10 min across rang non-laboratori set e.g. pediatr clinic home etc. develop seri movi design captur child ’ attent elicit emot respons novel interest event ass toddler ’ abil sustain attent share other embed insar carpent et al./digit behavior phenotyp asd 2 movi fulli autom system cost- effect tablet wherebi elicit behavior case frequenc differ pattern facial affect automat encod cva aim creat tool object efﬁcient access cur- rent analysi focu preliminari result support util tablet-bas assess detec- tion facial movement affect young child use facial affect differenti child without asd though facial affect focu cur- rent analysi ultim goal combin inform across autism risk featur collect current digit screen tool e.g. delay respons name describ campbel et al. 2019 develop risk score base multipl behavior dawson sapiro 2019 inform could combin addi- tional measur risk enhanc screen asd method particip particip 104 child 16–31 month age child recruit pediatr pri- mari care visit research assist embed within clinic via referr physician well commun advertis n 4 non- asd group n 15 asd group child recruit within pediatr clinic recruit occur 18- 24-month well-child visit time receiv standard screen asd m-chat-r/f total 76 particip recruit clinic research assist chose par- ticip particip chose particip 11 indic interest studi wherea remaind declin due enough time anoth child take care want- ing discu partner child alreadi distress physician visit chil- dren enrol studi found procedur engag enough abl provid adequ data analysi administr brief non-demand data loss signiﬁc problem exclusionari criterion includ known vision hear deﬁcit lack exposur english home insufﬁ- cient english languag skill caregiv ’ inform con- sent twenty-two child diagnos asd non-asd comparison group compris 74 typic develop child 8 child non-asd delay deﬁn diagnosi lan- guag delay development delay clinic signiﬁ- canc sufﬁcient qualifi speech development therapi record electron medic record caregivers/leg guardian gave written inform consent studi protocol approv duke uni- versiti health system irb child recruit pediatr primari care set receiv screen digit version m-chat-r/f part qualiti improv studi ongo clinic campbel et al. 2017 particip recruit commun receiv asd screen digit m-chat-r/f prior tablet assess- ment part particip studi child either fail m-chat-r/f caregiv physician concern possibl asd under- went diagnost test use ados-toddl ados- luyster et al. 2009 conduct licens psycholo- gist research-reli examin supervis licens tabl 1 sampl demograph typic develop non-asd delay asd age month mean 21.7 23.9 26.2 sex femal 31 3 5 male 43 5 17 ethnicity/rac african american 10 1 3 caucasian 46 2 10 hispan 1 0 1 other/unknown 17 5 8 insurancea medicaid 11 1 6 non-medicaid 60 6 3 mchat resultb posit 1 0 18 neg 73 8 4 ainsur statu unknown 17 particip studi bchildren mchat neg receiv asd diagnosi refer assess due concern either parent child ’ physician insar carpent et al./digit behavior phenotyp asd 3 psychologist mean ados-t score 18.00 subset asd child also receiv mullen scale earli learn mean iq base earli learn composit score subgroup 63.58 none child non-asd com- parison group administ ado mullen child ’ demograph inform extract child ’ medic record self-report caregiv studi visit child asd group averag 4 month younger compari- son group furthermor would expect higher proport male asd group comparison group though differ statist signiﬁc χ2 1 104 2.60 p 0.11 differ proport racial/ethn minor child two group look child medicaid statu known differ proport child medicaid asd non-asd group stimulu procedur seri development appropri brief movi design elicit affect engag child ’ attent shown tablet child sat care- giver ’ lap tablet place stand approxi- mate 3 ft away child prevent child touch screen depict previou public campbel et al. 2019 dawson et al. 2018 hashemi et al. 2015 hashemi et al. 2018 movi consist cascad bubbl mechan bunni anim puppet interact split screen show woman sing nurseri rhyme one side dynam noise-mak toy side movi includ stimulu use previou studi asd symptomatolog muria et al. 2018 well develop speciﬁc current tablet-bas tech- nolog elicit autism symptom base dawson et al jone dawson kelli est webb jone et al luyster et al three point movi examin locat behind child call child ’ name prior administr app caregiv clearli instruct direct child ’ attent way tri inﬂuenc child ’ behavior assess furthermor caregiv began tri direct child ’ attent examin room immedi ask caregiv refrain caregiv persist note valid- iti form administr would consid- ere invalid research stop task one comparison particip due cri research restart task three particip asd due difﬁculti remain view tablet ’ camera half ﬁrst video stimulu famili member present well-child visit ask stand behind caregiv child distract child assess addition- alli child assess well-child visit research assist instruct collect data prior plan shot blood draw comput vision analysi frontal camera tablet record video through- experi 1280 × 720 resolut 30 frame per second cva algorithm hashemi et al. 2018 ﬁrst automat detect track 49 facial landmark child ’ face de la torr et al. 2015 head posit rel camera estim comput optim rotat paramet detect landmark 3d canon face model fischler boll 1981 “ visibl ” tag assign frame face detect face exhibit drastic yaw 45\\x01 center acknowledg current method use indic whether child orient toward stimulu track eye movement “ visibl ” frame probabl express three standard categori facial express posit neutral i.e. activ facial figur 1 exampl movi stimulu development appropri movi consist cascad bubbl mechan bunni anim puppet interact split screen show woman sing nurseri rhyme one side dynam noise-mak toy side insar carpent et al./digit behavior phenotyp asd 4 action unit express assign hashemi et al. 2018 model automat facial express extens pose-invari cross-mod dictionari learn approach origin describ hashemi et al train dictionari represent setup map facial informa- tion 2d 3d modal abl infer discrimin facial inform facial expres- sion recognit even 2d facial imag avail deploy train data bing- hamton univers 3d facial express databas yin wei sun wang rosato 2006 use along synthes face imag vari pose see hashemi et al. 2015 synthesi detail extract imag featur distanc subset facial landmark use facial featur learn robust dictionari lastli use infer discrimin 3d frontal 2d facial featur multiclass support vector machin chang lin 2011 train classifi differ facial express recent year progress automat facial express analysi child toddler dy malti 2016 gadea aliño espert salvador 2015 hain et al. 2019 lobu thrasher 2014 messing mahoor chow cohn 2009 addit previous valid cva algorithm expert human rater code facial affect subsampl 99 video record- ing across 33 particip repres 20 non-asd sampl mat- ched group asd sampl select partici- pant previous publish valid studi base age distribut ensur represent across rang age non-asd asd group previou work show strong concord cva- human-r code facial emot data set high precis recal f1 score 0.89 0.90 0.89 respect hashemi et al. 2018 statist approach video frame cva algorithm produc probabl valu express posit neutral calcul mean probabl valu three express type within non- overlap 90-frame interv exclud frame face visibl 3-sec window select provid u continu distribut emot probabl still within 0.5–4-sec window macroexpress addit name call event remov time window start cue name call prompt point 75 audibl name call actual occur plu 150 frame window select base previou studi campbel et al. 2019 show orient tend occur within second name call calcu- late proport frame child attend- ing movi stimulu base “ visibl ” “ visibl ” tag describ within 90-frame interv exclud name call period thu child gener four variabl mean probabl posit neutral proport frame attend 90-frame interv within ﬁve movi evalu differ asd non-asd child regular interv throughout assess ﬁt seri bivari logist regress obtain odd ratio associ mean express probabl attend proport given interv parameter increment 10 point asd diagnosi ﬁt seri multi- variabl logist regress model separ movi variabl includ paramet 3-sec interv within movi predict asd diagnosi given larg number interv rel small sampl size use least absolut shrinkag select oper penal regress approach tibshirani 1996 select parsimoni set paramet repres interv within movi express type predict asd diagnosi ﬁve movi combin lasso-select interv paramet full logist model one express paramet select given interv select one stronger odd ratio estim analysi conduct without age covari sinc small studi size preclud separ train valid set use leave-one-out cross-valid ass model perform receiver-oper characterist curv plot c-statist area roc curv calcul movi result figur 2 depict odd ratio analysi use “ rhyme toy ” movi one illustr exampl shown variabl odd ratio estim part movi elicit strongli differenti respons certain pattern express section substanti differ- enc two group overlaid plot odd ratio conﬁdenc band interv paramet select expression-speciﬁc lasso model select param- eter use movie-level logist model calcul classiﬁc metric insar carpent et al./digit behavior phenotyp asd 5 figur 3 compar roc curv ﬁve ﬁnal movie-level logist model leave-one-out cross- valid roc curv analysi perform video individu model “ rhyme ” movi yield strongest predict abil area curv 0.73 95 conﬁdenc interv ci 0.59–0.86 follow “ puppet ” auc 0.67 95 ci 0.53–0.80 “ bunni ” auc 0.66 95 ci 0.51–0.82 video final two “ bubbl ” movi bookend stimulu set least predict auc 0.62 0.64 95 ci 0.51–0.76 respect signiﬁc differ age asd non-asd com- parison group ran second set roc analysi age includ covari shown tabl 2 result remain signiﬁc includ age covari given preponder emot cate- gori non-asd comparison group explor speciﬁc facial movement drive cate- gori express differ neutral express categori focus analyz movement facial landmark head pose angl differ facial express categori cva algorithm align facial landmark child canon face model afﬁn trans- format normal landmark locat across video frame common space normali- zation process commonli use across cva task relat facial analysi allow one analyze/compar landmark locat across differ frame partici- pant align step abl quantifi distanc eye corner corner eyebrow vertic distanc inner lip point vertic distanc outer lip point interpret featur differenti- ate neutral facial express cate- gori assess differ facial landmark distanc given child pre- domin express neutral versu facial expres- sion also includ yaw pitch head pose angl sinc may play role align process figur 2 time seri odd ratio associ mean express probabl proport attend asd diagnosi use “ rhyme ” movi one illustr exampl line depict odd meet criterion asd non-asd comparison group outcom interest 3 sec time bin across movi point error bar interv select lasso regress model includ ﬁnal logist model blue window depict segment movi differenti emot respons asd non-asd child green window depict segment movi differ emot respons group figur 3 receiver-oper characterist curv roc curv calcul predict abil expression-speciﬁc lasso select interv paramet facial express attent stimulu movi independ insar carpent et al./digit behavior phenotyp asd 6 focus three stimulu particip exhibit high probabl express name ﬁrst bubbl puppet rhyme toy video 104 particip exhibit frame neutral facial express domin wilson signed-rank test report median differ p valu indic within individu particip diagnost group median differ distanc versu neutral facial express signiﬁcantli higher inner right eyebrow non- asd diff 2.5 p 8.1e-10 asd diff 4.0 p 1.1e-4 inner left eyebrow non-asd diff 2.4 p 1.5e-9 asd diff 3.6 p 1.4e-4 outer right eyebrow non-asd diff 1.2 p 1.0e-5 asd diff 2.3 p 1.6e-4 outer left eyebrow non-asd diff 0.9 p 3.4e-6 asd diff 1.4 p 1.4e-3 mouth height non-asd diff 1.5 p 1.0e-3 well pitch head pose angl non- asd diff 2.8 p 8.7e-10 asd diff 4.4 p 1.2e-3 eye height lip part yaw head pose angl discuss present studi evalu applic administ tablet compris care design movi elicit affect express combin cva record behavior respons identifi pattern facial movement emot express differ- entiat toddler asd without asd demonstr movi elicit rang affect facial express group furthermor use cva found child asd like dis- play neutral express child without asd watch seri video pattern facial express elicit speciﬁc part movi differ two group believ ﬁnding strong face valid rest research clinic observ restrict rang facial express child autism furthermor replic previou ﬁnding group report increas frequenc neutral express young child screen posit m-chat egger et al. 2018 togeth preliminari result support use engag brief movi shown cost-effect tablet combin autom cva behavior code object feasibl tool measur earli emerg symptom asd name increas frequenc neutral facial express predict power emot express video vari one repres medium effect equival cohen ’ 0.5 greater rice harri 2005 overal best predictor batteri video “ rhyme ” video auc larg effect size may suggest present “ rhyme ” video alon sufﬁ- cient differenti asd non-asd group caution reader come conclu- sion two reason first possibl larger sampl video would larger effect second anticip variabl asd group regard featur singl child express differ video may better suit elicit differ featur given individu believ import understand independ featur case facial affect perform across differ video build better predict model combin featur e.g. facial affect postur sway describ dawson et al. 2018 understand differ facial expres- sion non-asd group compar asd sam- ple explor facial landmark differenti facial express categori domi- nate non-asd control group versu neutral facial express common asd group analysi identiﬁ featur rais eyebrow open mouth play role dis- crimin v neutral categori facial pattern consist engaged/inter- est look display child activ watch describ young child sullivan lewi interest note rais pitch angl also statis- tical signiﬁc sinc median differ angl two facial express small may natur movement rais one ’ eyebrow result need consid light sever limit first cva model facial express use current studi train adult face hashemi et al. 2018 despit previou ﬁnding young child demonstr good concord human cva code design facial express hashemi et al. 2018 furthermor facial express categori includ non- posit neg express even though abl determin predomin featur driv- ing express rais eyebrow line observ watch movi tabl 2 comparison asd versu non-asd area curv analysi auc without covari auc age model bubbl 1 0.62 0.75 bunni 0.66 0.81 puppet 0.67 0.78 rhyme 0.73 0.83 bubbl 2 0.64 0.79 insar carpent et al./digit behavior phenotyp asd 7 possibl combin facial expres- sion non-asd group drive design futur studi need train engaged/inter- est facial express speciﬁc test robust ﬁnding addit though previous demonstr good reliabl cva algo- rithm human code emot hashemi et al. 2015 futur valid cva analysi emot facial express larger dataset current underway second use lasso statist approach mean model may select featur dif- ferenti inform howev select approach minim ﬁtting model third sampl size rel small separ train test sampl account appli cross-valid roc curv even though decreas perform metric model suggest roc result poten- tialli conserv final comparison group con- tain child typic develop child non-asd development delay factor view weak strength previou research demonstr increas fre- quenci neutral express differenti child asd development delay bieberich morgan 2004 yirmiya et al. 1989 how- ever due small sampl size child non- asd development delay unabl directli test data furthermor subset sampl receiv assess cognit abil possibl addit child non-asd comparison group also developmen- tal delay undetect ongo research pro- spectiv longitudin studi larger sampl underway pars abil cva tool differenti child asd child non-asd development delay and/or attent deﬁcit hyperact disord typic develop child differ facial express one core fea- ture asd heterogen asd mean expect child asd display sign asd next step combin current result measur autism risk assess current digit screen tool includ respons name campbel et al. 2019 postur sway dawson et al. 2018 differenti vocal tenenbaum et al. 2020 among featur develop risk score base multipl behavior dawson sapiro 2019 sinc one child expect display everi risk behav- ior goal determin threshold base total number behavior regardless combin behavior ass risk similar done commonli use screen diagnost tool m-chat robin et al. 2014 autism diagnost figur 4 analysi facial express 4 panel left depict heat map align landmark across asd non-asd particip exhibit neutral facial express color bar indic proport frame land- mark display given imag locat singl panel right exampl landmark distanc explor insar carpent et al./digit behavior phenotyp asd 8 interview lord rutter le couteur 1994 ado gotham risi pickl lord 2007 lord et al. 2000 summari evalu integr object tool elicit measur facial movement express toddler without asd current studi add bodi research support digi- tal behavior phenotyp viabl method assess autism risk behavior goal develop valid tool eventu use within context current standard care enhanc autism screen pediatr popul acknowledg fund work provid nih r01-mh 120093 sapiro dawson pi nih ro1-mh121329 nichd p50hd093074 dawson kollin pi simon foundat duke depart psychiatri behavior scienc pride award duke educ human develop initi duke-coult translat part- nership grant program nation scienc foundat stylli translat neurosci award depart- ment defens stimulu use movi creat geraldin dawson michael muria sara webb univers washington work would possibl without help eliza- beth glenn elizabeth adler samuel marsan also grate acknowledg particip child famili studi final could complet studi without assist collabo- ration duke pediatr primari care provid conﬂict interest guillermo sapiro receiv basic research gift amazon googl cisco microsoft consul- tant appl volvo geraldin dawson sci- entiﬁc advisori board janssen research develop akili inc. labcorp inc. tri pharma roch pharmaceut compani consult appl inc gerson lehrman group guidepoint inc. teva phar- maceut axial ventur receiv grant fund janssen research develop ceo dasio llc dawson receiv royalti guilford press springer oxford univers press dawson sapiro carpent hashemi campbel espinosa baker egger help develop aspect technolog use studi technolog licens daw- son sapiro carpent hashemi espinosa baker egger duke univers beneﬁt ﬁnancial', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a83c6f65-0f21-4a7f-b78f-e2fcba2a4056', embedding=None, metadata={'file_path': '/content/drive/MyDrive/Autism/zhao2020_cleaned.txt', 'file_name': 'zhao2020_cleaned.txt', 'file_type': 'text/plain', 'file_size': 8678, 'creation_date': '2024-05-31', 'last_modified_date': '2024-05-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='research develop autism diagnosi inform system base deep convolut neural network facial express data wang zhao long lu school inform manag wuhan univers wuhan china abstract purpos – facial express provid abund inform social interact analysi util facial express data play huge drive role area societi facial express data reflect peopl ’ mental state health care analysi process facial express data promot improv peopl ’ health paper introduc sever import public facial express databas describ process facial express recognit standard facial express databas fer2013 ckþ use main train sampl time facial express imag data 16 chines child collect supplementari sampl help vgg19 resnet18 algorithm model deep convolut neural network paper studi develop inform system diagnosi autism facial express data design/methodology/approach – facial express data train sampl base standard express databas fer2013 ckþ fer2013 ckþ databas common facial express data set suitabl research facial express recognit basi fer2013 ckþ facial express databas paper us machin learn model support vector machin deep convolut neural network model cnn vgg19 resnet18 complet facial express recognit find – studi ten normal child ten autist patient recruit test accuraci inform system diagnost effect autism test accuraci rate facial express recognit 81.4 percent inform system easili identifi autist child feasibl recogn autism facial express verifi research limitations/impl – ckþ facial express databas contain adult facial express imag order improv accuraci facial express recognit child facial express data child collect train sampl therefor recognit rate inform system improv originality/valu – research us facial express data latest artifici intellig technolog advanc technolog diagnost accuraci autism higher tradit system studi innov research topic come actual need doctor content method research discuss doctor mani time system diagnos autism earli possibl promot earli treatment rehabilit patient reduc econom mental burden patient therefor inform system good social benefit applic valu keyword facial express data fer2013 ckþ deep convolut neural network vgg19 resnet18 autism diagnost inform system paper type research paper 1 introduct facial express recognit import social cognit skill emot express facial express therefor recognit understand facial express facial express autism diagnosi research possibl thank support project nation natur scienc foundat china independ research project school inform manag wuhan univers current issu full text archiv journal avail emerald insight http //www.emerald.com/insight/0737-8831.htm receiv 31 august 2019 revis 16 decemb 2019 accept 23 januari 2020 librari hi tech © emerald publish limit 0737-8831 doi 10.1108/lht-08-2019-0176 basi commun interperson relationship other abnorm express promin manifest autism also one criterion diagnosi autism doctor diagnos autism respond abnorm facial express child autism also known autism autism disord repres diseas gener development disord recent year incid autism child becom higher higher experienc transit rare diseas epidem present research autism still infanc home abroad research method tool still develop main symptom autism includ impair social interperson commun languag retard repetit behavior sensori dysfunct difficult autist patient correctli recogn face explain facial emot differ emot express ordinari peopl correctli perceiv understand basic express anger present diagnost method autism spectrum disord includ tradit standard dsm-iv-tr icd-10 variou autism diagnost assess scale “ childhood autism rate scale ” “ autism child behavior scale ” autism behavior rate scale questionnair interview method reli doctor ’ direct observ patient ’ express speech behavior base experi diagnost result easili disturb extern factor hospit level physician ’ subject level patient ’ educ level age rel larg subject factor result certain degre miss diagnosi misdiagnosi take 1–2 h autist patient diagnos doctor lot work best period treatment autist patient age six earli diagnosi great signific rehabilit autist patient purpos research design train model make facial express recognit system base normal express verifi abnorm express system test facial express autist child judg differ autist child normal child studi fer2013 ckþ use main facial express train sampl time collect facial express imag data 16 chines child supplementari sampl facial express help vgg19 resnet18 algorithm model deep convolut neural network accord hospit autism diagnosi scale diagnosi process paper studi design inform system diagnosi autism facial express data actual test recruit tester recognit rate system 81.4 percent effect distinguish whether express child normal provid practic inform system diagnosi autism paper continu collect child ’ facial express data differ countri region train sampl improv recognit rate facial express autism diagnosi inform system design studi follow import signific autism diagnos earli possibl use system best time treat autism age six earlier diagnosi autism made le treatment cost higher probabl recoveri earli diagnosi great valu allevi burden famili societi autist patient system publish form app web page dissemin internet system instal use differ devic comput mobil phone tablet etc good applic lht system autism diagnos conveni time save earli treatment autism patient especi underdevelop area make diagnosi autism object whole diagnosi process complet system artifici intellig technolog use recogn facial express without human intervent diagnosi result object accur reduc intens doctor ’ work system use took hour doctor diagnos autist patient use system doctor save lot time pay attent treatment autism facial express databas use train system contain differ race world therefor system diagnos child differ countri region also diagnos suspect autism patient world research design system accord actual busi earli design system adopt suggest sever doctor design manufactur accord actual need doctor although paper autism diagnosi facial express home abroad still autism diagnosi system develop use practic paper us latest in-depth learn technolog improv accuraci facial express recognit previou tradit techniqu method low recognit rate facial express recent year develop artifici intellig technolog improv comput speed convolut neural network greatli improv accuraci facial express recognit innov research technolog 2 facial express databas recognit technolog 2.1 facial express databas facial express import way peopl express emot social process facial express import way judg attitud inner feel parti mehrabian found convers chang facial express play import role 55 percent facial express 38 percent voic 7 percent word compar voic express convey abund inform recognit understand facial express import commun other 1972 ekman demonstr empir research human be six basic facial express happi sad anger fear disgust surpris subsequ studi neutral express also ad basic express gener believ seven basic express facial express continu develop comput softwar hardwar technolog peopl deeper understand facial express recognit technolog order better studi facial express recognit technolog mani intern research institut establish standard facial express databas main facial express databas follow jaff databas store facial express data japanes woman contain 213 facial imag ten japanes woman seven type facial express name neutral happi facial express autism diagnosi sad surpris anger disgust fear resolut imag 256 3 256 pixel everyon seven kind pictur facial express ckþ express databas collect laboratori condit includ african american asian south american resolut imag 640 480 pixel contain 593 express sequenc 123 peopl 69 percent femal 31 percent male sequenc begin end neutral express includ process calm strong express ckþ facial express data set mani applic reliabl variou facial express evalu experi use databas high includ seven type facial express anger contempt disgust fear happi sad surpris fer2013 35,887 facial imag librari seven facial express type angri disgust fear happi sad surpris neutral resolut imag 48 48 pixel imag gray imag three sampl set 28,709 imag train set 3,589 imag valid set 3,589 imag test set mmi express databas divid two part one dynam data set compos 2,900 video sequenc part static data set consist larg number high resolut imag seven type express librari afew facial imag databas edit movi contain seven basic facial express sfew express librari static frame imag extract afew data set contain seven basic express 2.2 facial express recognit process process facial express recognit includ two stage shown', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7wKMv34tVKg"
      },
      "source": [
        "# **Setup default system prompt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VPNWx83ojDay"
      },
      "outputs": [],
      "source": [
        "system_prompt= \"\"\"\n",
        "You are a Q&A assistant. Your goal is to answer question as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n",
        "## Default format supportable by LLama2\n",
        "query_wrapper_prompt= SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "en9_PrvkF_qJ",
        "outputId": "fc058c33-d810-47bc-e176-00d9227f6285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiNkldHb4zu6",
        "outputId": "2d70694f-296e-4f5d-bf4d-dcc06f351b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517,
          "referenced_widgets": [
            "6d9cb3a5dd064e0da9ab953fb4c89653",
            "c46aba9eb4d042afa91d347b6dfd3c42",
            "fda845a9fa8b42adaf2b206a2188de7b",
            "a7c828067b994a9689b8e6ff16192860",
            "b0c45327232a4b39b5ed050bfa3c4994",
            "f1b5648731f2471cb271e50afa18204c",
            "f1e7ff7b85e9479780fa71130b963aaa",
            "0fb2be18207046b1848e2e89890191a6",
            "a680f9b58e3e45ed8e558aa431a48190",
            "f4054310f29042c5969c7baa6b6eaaa1",
            "6d7e0f712a5347d7844d798f75966fe0",
            "46f10b1a78fb46e5a6628f80d5395540",
            "a4ce17ca54f546aaa852a1a31e21a109",
            "ac6145e6d66f4e1ab5dbe6bb9ab21182",
            "4736a3d2b8df42779d4ec4c1db94f2d6",
            "2d06fc6b7fc04777856b1e5776b969a9",
            "df1511cb7d624d5095c2ae508f4990eb",
            "3203cce93e584ee081fe30ec97aa30ce",
            "ac45a2a28a4e4e6ba21580e21590b635",
            "6e78656301ab4a8a91cbd7178037d243",
            "28b08ef52310487a91b3accc5bc974d4",
            "6ccbc3776e974ba5aa9b0ae4f0217b99",
            "227ac239d99248a4b68652722a60ebb0",
            "c32b0ab85c8343e7a4eb396fe75211e8",
            "3677c0f5d92247dbb5800eff89dde66a",
            "eeb5386586d04b9ab715dd8390cd9a67",
            "f540d50ee543409b9232020c98eb2955",
            "8cbbb59499ea458e82341d941a17ec76",
            "5c3c4f4df6b14aaa8f9fae12406e44e5",
            "dd5aed0dbc7f4591b6ab8b1a36034032",
            "a2378acaf9b340c6b670062fff819835",
            "d9fa97b156c44a78a7db4433a0c005f3",
            "1cf28eed1b564f9f9482101cdd7cbfa5",
            "e4e58c8737764fd79513abdeff484e42",
            "3fe4e39924c34737b321927ce330f932",
            "dfaa65aab45040ddaa12b0f75821983d",
            "d164064a5fc040c7a904c67ee376024d",
            "9b4b7488b0cb4bbfbea37373bfd3ed5c",
            "d148fc54cc7b457098646f44d015f1c4",
            "b48154668ba241a0b40fff7a584b8dcd",
            "afa9941b20d9454da517f3dcb66831c1",
            "b30c3128069045469327f4f8761ac8b9",
            "ecb76ce4b84a4c25ac47798814c5e38b",
            "eeda9aaf61ba4db68505f6fd9482d719",
            "238c3e46264943a090586981c55b25c2",
            "2bd3a2fbddac4ed5967b3315ed1ab411",
            "9b51b6354309496d81f65104826d90fc",
            "36fdaf7c9c7c44409650c0315632bad9",
            "fe52c764bd20435d9b626898f3acfc99",
            "4fd94d55fb5b4e9a867cc85c22270b0e",
            "32187600e5234f95b4771715c95e9709",
            "a7e4067fef4e49e880f5d92f07bb14e1",
            "71098d99e3f24c4c840c1624f21bbe97",
            "49dfb7e04c9c4bddadd373361211dabe",
            "4592c74027cb40f498fb4da54e884f73",
            "b2aef908f69f41e0aa3f143b27343c3c",
            "42a17e2cff9b404a99a24adc8a4de656",
            "c9bdc234287942dc9bf76f1667c67803",
            "fb95fac2a1af4f3faef0b07689daa874",
            "0c29fdadbbf84cd5bc7405714f3acb08",
            "7e274eda3cbf4da48e43bae874b133a5",
            "c80e80775728442b8994ce9631889a90",
            "75f5c5c326b74257a0dba400db16d2a6",
            "91770e3bf57447caa7fd541b304323a2",
            "838cc746b0064921b25aeebdb340d414",
            "29e5a4b3f82340e5919467732c17e5ab",
            "bc264805bd184d44b6d83cca50605b73",
            "b64451321cc043c0a08ca904356af8ea",
            "011ef13d84c64253a5f14f054e01a3f3",
            "5e13f77467c941e5823e0c97468c64fe",
            "56fc76ae118544be987830943c21522e",
            "bc2407d56dff461eb24383b8bd60f6a8",
            "1a08ae6e67294556afdb6731e2aad386",
            "45ba058b6bf341d1b932b2fc0cf1590d",
            "a1ba43677dc0487bb226702ab087fd44",
            "e69093ae65df41439c38835253b660e9",
            "c03e9fb6df0c482982d5c19eca900202",
            "7bb3cf0536b946b9ae9069c26251866a",
            "8bcf269a29f14a0aab72972d2e39efb9",
            "d9c2693336bd4c96aa5a533c6107ead0",
            "2d145f8940fa4a5d8e4a6e746fdc9e3c",
            "5e9ab39d359547e08a23dbf612edd6f2",
            "8faffc25c74e437eb2fbcf4eecf3e202",
            "c1239ec1a5d34bdd80a8392d5e822887",
            "c8fb63f85d0743dfbd8d206c1eefc3de",
            "9edef587fc83493cb3b4ff8cc3715589",
            "dd29a0c5e50f49f0a9af7842ecfc99d3",
            "40dbb38837ca48409e302b98a21adbed",
            "473d91e2b1234f9e87c46fbe3c3db270",
            "cde33220f2f14c65a7babd3840a147c3",
            "3400c8369ca0496c8ab5e9b121385a68",
            "662aee1623a54bbf9c0778ffeda2008b",
            "5bce407005024a81a1f4ff823db5bcb3",
            "97331c2939994c4cb1091eb2ce53f5bb",
            "ebc64804dffb4db69075560eb1729931",
            "ca39c45494f74a5e9bf17380f05a417c",
            "01dc87e2652f4cb5b9cbdad6f98f6296",
            "d3d25247ff5f4fc8a188616d2a8a854a",
            "d236c189f4c4426b994a4b6fd61d2db1",
            "68a1e5e37a5a4a529d392f1154c0592b",
            "ac556c3bd81541f5a13cfddfbcc9410a",
            "0156e97593ac46d185d81abe01b36cd1",
            "7500a9d7bc134b0bbd4fd5f7a1c58ed3",
            "2a8b4f26983848aa988b5265fe355c90",
            "5dcf2a021b3c4f62a511091b5bfefbe5",
            "0de93ada5793427e8d110a3ab1517df5",
            "2feaab339959477086545764f6c50029",
            "a18093074801491ea0de4a1f5e031229",
            "a53e4320061e4eec811dbb34bafba1e0",
            "489e8102e5ef42cfad52da289cae6a7d",
            "d0517e0e8491448782b74498f3f740f3",
            "ba0720b62e1746c18434aa6c91ddc917",
            "67d820fe04be4a33819ea67f9b84d561",
            "0e7b0d398f324aa2adf7f558ca92ac08",
            "4461e5191be147d3b761a6524a4899f1",
            "c356a6d3f3f946a9901c54c368945883",
            "f6ba72ae68b749f487b720c1c0677cad",
            "7ef9781f1afe4f53bd818d896517c761",
            "7e1f219ec6b4498ab26b57620ef92d3f",
            "b507fdfe55f145688ba15232cc571ba4",
            "7b730ae995514265b97fc65c42d02bdb"
          ]
        },
        "id": "F7RpE_7PzHIV",
        "outputId": "9f7fd824-3f36-4786-b530-6febd579d9b9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d9cb3a5dd064e0da9ab953fb4c89653"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46f10b1a78fb46e5a6628f80d5395540"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "227ac239d99248a4b68652722a60ebb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4e58c8737764fd79513abdeff484e42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "238c3e46264943a090586981c55b25c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2aef908f69f41e0aa3f143b27343c3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc264805bd184d44b6d83cca50605b73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bb3cf0536b946b9ae9069c26251866a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "473d91e2b1234f9e87c46fbe3c3db270"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68a1e5e37a5a4a529d392f1154c0592b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0517e0e8491448782b74498f3f740f3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "    model_kwargs={\"torch_dtype\": torch.float16,\"load_in_8bit\": True}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjDuVXLwYu31"
      },
      "source": [
        "# **Embedding the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FAYZ8HTqO7av",
        "outputId": "bd38efa6-bfe3-44b0-f679-9bd03e1d7e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-embeddings-langchain\n",
            "  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-langchain) (0.10.41)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.30.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\n",
            "Installing collected packages: llama-index-embeddings-langchain\n",
            "Successfully installed llama-index-embeddings-langchain-0.1.2\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-embeddings-langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qlz5KnYq-Xfz",
        "outputId": "3b468f6f-7bd8-4407-e113-b1903faeed1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.1)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Installing collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425,
          "referenced_widgets": [
            "b98eea0cf2c542a59b1c187f4c5041f5",
            "4a54c5ab29a24f40a9a26e565759ea8e",
            "71ffd8bbde7a427c9fd3d5f266ded642",
            "b188bad312b8420ba13ac91c46fa4c05",
            "d461363340874f43be9e477640f3c567",
            "65f1080a60bb45328afd2d2cc9ce2d1f",
            "002cd73445f94b21b8ba329b8abb3abd",
            "3adcae7b3ec442a1a6bb13c6b297c044",
            "54958dbe2d7b4bcfb4b351647f151eb7",
            "3463782eea9246af8d70420ef74d43a5",
            "9934de929ddd4ab09ef87a2001036df4",
            "c0fb7c9cdaa8414a9cba2cbaa8ca0f17",
            "ee08dfadef6741c18f94e4b65bb43da9",
            "1844effe67214f07a93ac3e4dd5f6c1c",
            "26826c7fa62a421d97c214c29b21eba6",
            "b099974b652341548bc818ac95eb310a",
            "e8a981964f304bb5b5a497848ac07e03",
            "4295cf9e843a4567afda2339c2b2b71a",
            "97d63b93dfc24e06af471841b7a8e76c",
            "cfbea7e2769e4555b366a59e5f24cd6c",
            "54eda63145814ac3ab0d9a8ddd63f865",
            "98c0d71d88be4500bbeacfe6bd99ecf3",
            "a4e05fbc514b4b1ebcfe96e33240a66d",
            "f8a574d7eb1a4c4881e1a48574b434a1",
            "126d11b4ba9e4548844d1cb91ad0ff93",
            "7857bdd5c8ca4feebe84c739a495d122",
            "7316e97e03934f6ea9767cee840718ac",
            "2f98430c1f70401e9e5f08d490c302c5",
            "6e3026ae17fc48f794cc67dba56da001",
            "af9ff6484a724cc586015a7a0d4135c0",
            "f0dc626d50cd4944b4f2d7c884476bf1",
            "82a2122f52a449d09486e02c833854da",
            "899203a5b788489c87d2243b1458b1f8",
            "1edc575f3663455c9bfef3b5ef254faa",
            "fed77a82631c491ea690c9f4d27c2f7e",
            "99cbd83a7a564a569ead6959e11909fc",
            "462f9f2ba4894d55b74a3606d3ae0a05",
            "f5d397e0c2e64e2ba3b5f7d7e97f6a85",
            "7d641dd33dbc4e8786152ef687899065",
            "e77821263ab0444b8e5322d56a2fac6f",
            "54d66356d02146e49af7e03c6df9f2d2",
            "a1a69a1ddcd940788f79b5c739ab6ae4",
            "4e3615d98aec4f3597e565fd681f6377",
            "5f0e314e6a9144a8af37fed2ea495f0e",
            "5dda890948e24f0db140614534c10ee0",
            "28932d4c375c4602aee7d42747b7b833",
            "977503abbf414726ae12368076ace3b4",
            "a10976b614ee4d8b835604b92bb11b84",
            "8b9719d32b314690b649e5d420afa0f3",
            "2907163ad1834bf398d13b77d0282e13",
            "59880240cb98433da2bdb89901cecaec",
            "282d59d7fab548e3b53123ca29cb89fb",
            "ed2cfc4575c44e49b27202120b0d473b",
            "e003c1a6ed7d4576867b78b8092f18f0",
            "7aaf66678a434c0795eac61b5594d977",
            "54b355ebfdd541a39ca1390280037af4",
            "22f1e313d06c4dbfb17da513f8efcbc4",
            "03a71e4168c147bba406f283db0526fe",
            "4cf1202b3cf7427dbadf3b3cb3dbd99f",
            "4df90ad7fbc54ba7a9b384bb5cd44a21",
            "308ea81aa0d44d16949e636abf0574ad",
            "21812bec821b4a19a543c7dc8d284fe5",
            "9ebe9c92cedc452a9062d0c253cf091a",
            "c636c3d00a904d74bd5f8c86e50e46a1",
            "30f741cc550546bc842380b46b3e18e8",
            "0e8090350f8b44dcad1d9d5e9c87d4a7",
            "2aab078ef5b54d28868ff16fad125b4b",
            "ec546008f78844c58eb226937cdb1dec",
            "05e84fd9f41646c794ad714061596959",
            "c3af828f7d8148a8bfd46c995ead6dd2",
            "d3c9692b3287493e88dccbec7ae96b64",
            "b981fddd3b0548f7a0c6337ab168a676",
            "dbc81de916734be499e15df0735930b6",
            "7a95868eb19949f78be9ebe96de6963c",
            "8a78ce82e1034d2d90dce5ec8394f8a3",
            "5f945bac56d441ee8e0831b0b1d20081",
            "7d8c672dcf4d4a3fabe23e169b8c1ca1",
            "34a9a48cf8af420bbbce2f71340bcb11",
            "f3973e59e30e48cbb1967cea457952ed",
            "2abea1e1681d45d595beabab96dc5423",
            "ffd887618b714bec81535fb0dbeca5a3",
            "56915cb8f1ac407891d321f6a9bce34d",
            "d33adc09373a4171a009fb7b2339bb45",
            "2cbc5c822af64f95aa21717ea183f675",
            "15224f2a863c4b15b0b7e2c653a18fd0",
            "cf45a3bd20534964951caa271247c6ce",
            "7afa57c1872d433fb3ad34f2e65561e0",
            "8d92a351f8d84302beec08fb181dbca3",
            "1ef6afea27f34f89a47c324f095b850f",
            "45996221c909415f808c8f94dc4d8bd1",
            "6a489848fcc54c2885498c58c6fbd85e",
            "a18e1dca7afc4b37837886b51c07a892",
            "9e56a7bf53574a18b505f34cd204a137",
            "1b888a8bf7944f608d106232b7a5574b",
            "55bc5f84c23a41ed813f86943c1fece7",
            "fe0e730f01134f1986d0fdf8a17aa8e8",
            "a19594c0ca0c4bd996f783797abb12aa",
            "696050ecde6847f6bda164f3ca3d0942",
            "7bdfa030ded24a9c8923df81e27f61b8",
            "41325a4a0b25429386b567df321f6c5b",
            "763412f5485d4dffa438baef6a6007a6",
            "0b58597a59c6439f84a3cf89e2f7f744",
            "48f5ebb133fd46f1948e5cf35d00a98f",
            "d4041c53b8ff47148133a1602556f505",
            "e5397bbc12644ecba3ee31d372e8a6bd",
            "ef71ba2c2a904b1db276644c5cb56c2c",
            "6d4cc542cc1441d2bc070e7f0fd975af",
            "219c82d1e4974130ac60e20bd2863dd3",
            "c3e4b076ea194479b244bf171fb383a7",
            "676663fa11a24f5c8a4b74139e04a306",
            "28453b789e194689bbe68309e358a3d0",
            "1a9d581b30f34bc0a3571535a5e1cb48",
            "cff4fb7672f241d4bdd20e59099b5a64",
            "0b152220d68c4ef38cc18ea6f90d6898",
            "9a68bf0ae9924142815d6446a3675692",
            "856186cebe6b438d8b28409f102f94b6",
            "e02097a1bfa34621825e2f2cbf3ad51c",
            "3f839790bfdc453f8d5ddf9fe0cf1cef",
            "b6b0ae35fec14b09bbf3474c94999870",
            "bbd6902e0e0947c784c0b30ad2ab465b",
            "2e495801928348f0887a5a7de399af50"
          ]
        },
        "id": "vT3Ck0Ew6F5g",
        "outputId": "81507364-8b4b-40ff-8da0-f4aa5af4dbc8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b98eea0cf2c542a59b1c187f4c5041f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0fb7c9cdaa8414a9cba2cbaa8ca0f17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e05fbc514b4b1ebcfe96e33240a66d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1edc575f3663455c9bfef3b5ef254faa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dda890948e24f0db140614534c10ee0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54b355ebfdd541a39ca1390280037af4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2aab078ef5b54d28868ff16fad125b4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34a9a48cf8af420bbbce2f71340bcb11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ef6afea27f34f89a47c324f095b850f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41325a4a0b25429386b567df321f6c5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28453b789e194689bbe68309e358a3d0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJdBw-q4YyWF"
      },
      "source": [
        "# **Chunking the embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QYpV9BV7_nx",
        "outputId": "488fae16-0300-412c-9c37-857b5e5b0072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-6394536e40c5>:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(\n"
          ]
        }
      ],
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y3CrMC1X7ovz",
        "outputId": "b68b9ba9-4516-4011-e179-5b8965de276b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=4096, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=LangchainEmbedding(model_name='sentence-transformers/all-mpnet-base-v2', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7c7793dc8e20>, num_workers=None), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7c7793dc8e20>, id_func=<function default_id_func at 0x7c7901625b40>, chunk_size=1024, chunk_overlap=200, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.core.service_context_elements.llama_logger.LlamaLogger object at 0x7c783fb23070>, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7c7793dc8e20>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "service_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5DclriFY_Sw"
      },
      "source": [
        "# **Indexing the embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "53db95818f7242b3b91a7e78d71da946",
            "0fb2b1a00db74a00b7386256ead382e7",
            "c594fe3b029a457293c9c6fe13492cbf",
            "491b9ea12f9a4291bf6b266fcbc921d0",
            "0caa7a0892d84c8faa13a719c3c742d8",
            "b763cbf9c26f487881f044f9d720afe7",
            "3c5afecfe56744aa87080e49fa5d3b60",
            "94f9310948d54e4281b045f672e0c10c",
            "7ac68aca9c0a47eb846bdc0afcfaff05",
            "b3507f8a17fa412fb9abf0714a2a9054",
            "1364e0268bb54e39b3b4b249f57c926c",
            "9c33dda735c2485db7b0dbddfd89edf9",
            "8a212b97fa7a419a9ef591a5eef00590",
            "2643656e381a4e8e9a26e21c2230cf60",
            "09f1e063ba4f471380ff2bec92306304",
            "4ae39489747b44aab1dba2f03c4af84f",
            "9cb97c6ccad748b285ff7c3a88704915",
            "26d75c5b41454bcb946bb515f12892dc",
            "3edc3f151f2c45e289ba079496704977",
            "89f26a20394141dab79dc566ee69cc23",
            "0c0aa869f63847b3a7371842dedb6089",
            "c1fdf6947c9f48b28c07c1dc99aa01c4"
          ]
        },
        "id": "fjZy-Rd0mb-y",
        "outputId": "2c81f027-0c31-46b5-faa0-6430645449ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53db95818f7242b3b91a7e78d71da946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/107 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c33dda735c2485db7b0dbddfd89edf9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context= service_context,show_progress = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmLvyBf2be0T",
        "outputId": "1a255ee3-5bd7-4852-c127-bb8cd00bff7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7c7793dcbc70>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZYuBXakZUrh"
      },
      "source": [
        "# **Creating Query Engine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YGrhVYaKbPR-"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "SCCPjMr3bBRt"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"What is West Syndrome?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GX2nC2UZojk",
        "outputId": "8eaf1bc7-002f-4cd1-9a88-e7471a935b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "West Syndrome is a rare and severe neurodevelopmental disorder that is characterized by a triad of symptoms: infantile spasms, hypsarrhythmia, and developmental delays. It is usually diagnosed in the first year of life and is associated with a high risk of intellectual disability, autism spectrum disorder, and other neurodevelopmental disorders. The exact cause of West Syndrome is not fully understood, but it is thought to be related to genetic mutations, brain injury, or infections during fetal development or early childhood. Treatment for West Syndrome typically involves a combination of medications and other therapies, such as physical therapy, occupational therapy, and speech therapy, and may also include surgery in some cases. Early diagnosis and treatment are important to improve outcomes for children with West Syndrome.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Iq4F0YtmYdAd"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.indices.postprocessor import SimilarityPostprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "utBVSLkscNQu"
      },
      "outputs": [],
      "source": [
        "retriever= VectorIndexRetriever(index=index,similarity_top_k=4)\n",
        "postprocessor= SimilarityPostprocessor(similarity_cutoff=0.80)\n",
        "\n",
        "query_engine = RetrieverQueryEngine(retriever=retriever,\n",
        "                                    node_postprocessors=[postprocessor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTyRY-JOZ8_C",
        "outputId": "4d1b46ad-46cd-4e5a-e5ee-c4cbb39fd604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Response: West Syndrome is a rare and severe neurodevelopmental\n",
            "disorder that is characterized by a triad of symptoms: infantile\n",
            "spasms, hypsarrhythmia, and developmental delays. It is usually\n",
            "diagnosed in the first year of life and is associated with a high risk\n",
            "of intellectual disability, autism spectrum disorder, and other\n",
            "neurodevelopmental disorders. The exact cause of West Syndrome is not\n",
            "fully understood, but it is thought to be related to genetic\n",
            "mutations, brain injury, or infections during fetal development or\n",
            "early childhood. Treatment for West Syndrome typically involves a\n",
            "combination of medications and other therapies, such as physical\n",
            "therapy, occupational therapy, and speech therapy, and may also\n",
            "include surgery in some cases. Early diagnosis and treatment are\n",
            "important to improve outcomes for children with West Syndrome.\n",
            "______________________________________________________________________\n",
            "Source Node 1/2\n",
            "Node ID: e16a4504-ef60-4ec4-a705-1dd6a887e450\n",
            "Similarity: 0.38584150624730407\n",
            "Text: org/ 10.1371/journal.pone.0241690 editor zhishun wang columbia\n",
            "univers unit state receiv novemb 26 2019 accept octob 19 2020 publish\n",
            "decemb 10 2020 peer review histori plo recogn benefit transpar peer\n",
            "review process therefor enabl public content peer review author\n",
            "respons alongsid final publish articl editori histori articl avail\n",
            "http //doi.org/...\n",
            "______________________________________________________________________\n",
            "Source Node 2/2\n",
            "Node ID: 432cf088-a641-4e2d-aab4-0e90b976f1dd\n",
            "Similarity: 0.31668786202066324\n",
            "Text: origin research publish 05 june 2020 doi 10.3389/fped.2020.00290\n",
            "frontier pediatr www.frontiersin.org 1 june 2020 volum 8 articl 290\n",
            "edit sara calderoni fondazion stella mari itali review whitney i.\n",
            "mattson nationwid child ’ hospit unit state lori-ann rosalind sacrey\n",
            "univers alberta canada correspond xiaoyan ke kexiaoyan njmu.edu.cn\n",
            "specialti se...\n",
            "West Syndrome is a rare and severe neurodevelopmental disorder that is characterized by a triad of symptoms: infantile spasms, hypsarrhythmia, and developmental delays. It is usually diagnosed in the first year of life and is associated with a high risk of intellectual disability, autism spectrum disorder, and other neurodevelopmental disorders. The exact cause of West Syndrome is not fully understood, but it is thought to be related to genetic mutations, brain injury, or infections during fetal development or early childhood. Treatment for West Syndrome typically involves a combination of medications and other therapies, such as physical therapy, occupational therapy, and speech therapy, and may also include surgery in some cases. Early diagnosis and treatment are important to improve outcomes for children with West Syndrome.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.response.pprint_utils import pprint_response\n",
        "pprint_response(response,show_source= True)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How can cross country trials help in development of Machine learning based Multimodal solutions \t\")"
      ],
      "metadata": {
        "id": "C7W72VDnBnvM"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Dx5iOdZJY5o0tKS6dQMzPUeRcnRg-9io",
      "authorship_tag": "ABX9TyPDQieu8/QweW6mLe0GHUDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d9cb3a5dd064e0da9ab953fb4c89653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c46aba9eb4d042afa91d347b6dfd3c42",
              "IPY_MODEL_fda845a9fa8b42adaf2b206a2188de7b",
              "IPY_MODEL_a7c828067b994a9689b8e6ff16192860"
            ],
            "layout": "IPY_MODEL_b0c45327232a4b39b5ed050bfa3c4994"
          }
        },
        "c46aba9eb4d042afa91d347b6dfd3c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b5648731f2471cb271e50afa18204c",
            "placeholder": "​",
            "style": "IPY_MODEL_f1e7ff7b85e9479780fa71130b963aaa",
            "value": "config.json: 100%"
          }
        },
        "fda845a9fa8b42adaf2b206a2188de7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb2be18207046b1848e2e89890191a6",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a680f9b58e3e45ed8e558aa431a48190",
            "value": 614
          }
        },
        "a7c828067b994a9689b8e6ff16192860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4054310f29042c5969c7baa6b6eaaa1",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7e0f712a5347d7844d798f75966fe0",
            "value": " 614/614 [00:00&lt;00:00, 44.2kB/s]"
          }
        },
        "b0c45327232a4b39b5ed050bfa3c4994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b5648731f2471cb271e50afa18204c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e7ff7b85e9479780fa71130b963aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fb2be18207046b1848e2e89890191a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a680f9b58e3e45ed8e558aa431a48190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4054310f29042c5969c7baa6b6eaaa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7e0f712a5347d7844d798f75966fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46f10b1a78fb46e5a6628f80d5395540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4ce17ca54f546aaa852a1a31e21a109",
              "IPY_MODEL_ac6145e6d66f4e1ab5dbe6bb9ab21182",
              "IPY_MODEL_4736a3d2b8df42779d4ec4c1db94f2d6"
            ],
            "layout": "IPY_MODEL_2d06fc6b7fc04777856b1e5776b969a9"
          }
        },
        "a4ce17ca54f546aaa852a1a31e21a109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1511cb7d624d5095c2ae508f4990eb",
            "placeholder": "​",
            "style": "IPY_MODEL_3203cce93e584ee081fe30ec97aa30ce",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "ac6145e6d66f4e1ab5dbe6bb9ab21182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac45a2a28a4e4e6ba21580e21590b635",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e78656301ab4a8a91cbd7178037d243",
            "value": 26788
          }
        },
        "4736a3d2b8df42779d4ec4c1db94f2d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28b08ef52310487a91b3accc5bc974d4",
            "placeholder": "​",
            "style": "IPY_MODEL_6ccbc3776e974ba5aa9b0ae4f0217b99",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.90MB/s]"
          }
        },
        "2d06fc6b7fc04777856b1e5776b969a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1511cb7d624d5095c2ae508f4990eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3203cce93e584ee081fe30ec97aa30ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac45a2a28a4e4e6ba21580e21590b635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e78656301ab4a8a91cbd7178037d243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28b08ef52310487a91b3accc5bc974d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccbc3776e974ba5aa9b0ae4f0217b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "227ac239d99248a4b68652722a60ebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c32b0ab85c8343e7a4eb396fe75211e8",
              "IPY_MODEL_3677c0f5d92247dbb5800eff89dde66a",
              "IPY_MODEL_eeb5386586d04b9ab715dd8390cd9a67"
            ],
            "layout": "IPY_MODEL_f540d50ee543409b9232020c98eb2955"
          }
        },
        "c32b0ab85c8343e7a4eb396fe75211e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cbbb59499ea458e82341d941a17ec76",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3c4f4df6b14aaa8f9fae12406e44e5",
            "value": "Downloading shards: 100%"
          }
        },
        "3677c0f5d92247dbb5800eff89dde66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5aed0dbc7f4591b6ab8b1a36034032",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2378acaf9b340c6b670062fff819835",
            "value": 2
          }
        },
        "eeb5386586d04b9ab715dd8390cd9a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fa97b156c44a78a7db4433a0c005f3",
            "placeholder": "​",
            "style": "IPY_MODEL_1cf28eed1b564f9f9482101cdd7cbfa5",
            "value": " 2/2 [01:24&lt;00:00, 39.80s/it]"
          }
        },
        "f540d50ee543409b9232020c98eb2955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cbbb59499ea458e82341d941a17ec76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3c4f4df6b14aaa8f9fae12406e44e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd5aed0dbc7f4591b6ab8b1a36034032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2378acaf9b340c6b670062fff819835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9fa97b156c44a78a7db4433a0c005f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf28eed1b564f9f9482101cdd7cbfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4e58c8737764fd79513abdeff484e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe4e39924c34737b321927ce330f932",
              "IPY_MODEL_dfaa65aab45040ddaa12b0f75821983d",
              "IPY_MODEL_d164064a5fc040c7a904c67ee376024d"
            ],
            "layout": "IPY_MODEL_9b4b7488b0cb4bbfbea37373bfd3ed5c"
          }
        },
        "3fe4e39924c34737b321927ce330f932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d148fc54cc7b457098646f44d015f1c4",
            "placeholder": "​",
            "style": "IPY_MODEL_b48154668ba241a0b40fff7a584b8dcd",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "dfaa65aab45040ddaa12b0f75821983d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa9941b20d9454da517f3dcb66831c1",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b30c3128069045469327f4f8761ac8b9",
            "value": 9976576152
          }
        },
        "d164064a5fc040c7a904c67ee376024d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb76ce4b84a4c25ac47798814c5e38b",
            "placeholder": "​",
            "style": "IPY_MODEL_eeda9aaf61ba4db68505f6fd9482d719",
            "value": " 9.98G/9.98G [00:54&lt;00:00, 259MB/s]"
          }
        },
        "9b4b7488b0cb4bbfbea37373bfd3ed5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d148fc54cc7b457098646f44d015f1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48154668ba241a0b40fff7a584b8dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa9941b20d9454da517f3dcb66831c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30c3128069045469327f4f8761ac8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecb76ce4b84a4c25ac47798814c5e38b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeda9aaf61ba4db68505f6fd9482d719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "238c3e46264943a090586981c55b25c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bd3a2fbddac4ed5967b3315ed1ab411",
              "IPY_MODEL_9b51b6354309496d81f65104826d90fc",
              "IPY_MODEL_36fdaf7c9c7c44409650c0315632bad9"
            ],
            "layout": "IPY_MODEL_fe52c764bd20435d9b626898f3acfc99"
          }
        },
        "2bd3a2fbddac4ed5967b3315ed1ab411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd94d55fb5b4e9a867cc85c22270b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_32187600e5234f95b4771715c95e9709",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "9b51b6354309496d81f65104826d90fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e4067fef4e49e880f5d92f07bb14e1",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71098d99e3f24c4c840c1624f21bbe97",
            "value": 3500296424
          }
        },
        "36fdaf7c9c7c44409650c0315632bad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49dfb7e04c9c4bddadd373361211dabe",
            "placeholder": "​",
            "style": "IPY_MODEL_4592c74027cb40f498fb4da54e884f73",
            "value": " 3.50G/3.50G [00:29&lt;00:00, 250MB/s]"
          }
        },
        "fe52c764bd20435d9b626898f3acfc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd94d55fb5b4e9a867cc85c22270b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32187600e5234f95b4771715c95e9709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e4067fef4e49e880f5d92f07bb14e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71098d99e3f24c4c840c1624f21bbe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49dfb7e04c9c4bddadd373361211dabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4592c74027cb40f498fb4da54e884f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2aef908f69f41e0aa3f143b27343c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42a17e2cff9b404a99a24adc8a4de656",
              "IPY_MODEL_c9bdc234287942dc9bf76f1667c67803",
              "IPY_MODEL_fb95fac2a1af4f3faef0b07689daa874"
            ],
            "layout": "IPY_MODEL_0c29fdadbbf84cd5bc7405714f3acb08"
          }
        },
        "42a17e2cff9b404a99a24adc8a4de656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e274eda3cbf4da48e43bae874b133a5",
            "placeholder": "​",
            "style": "IPY_MODEL_c80e80775728442b8994ce9631889a90",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c9bdc234287942dc9bf76f1667c67803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f5c5c326b74257a0dba400db16d2a6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91770e3bf57447caa7fd541b304323a2",
            "value": 2
          }
        },
        "fb95fac2a1af4f3faef0b07689daa874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838cc746b0064921b25aeebdb340d414",
            "placeholder": "​",
            "style": "IPY_MODEL_29e5a4b3f82340e5919467732c17e5ab",
            "value": " 2/2 [00:53&lt;00:00, 24.65s/it]"
          }
        },
        "0c29fdadbbf84cd5bc7405714f3acb08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e274eda3cbf4da48e43bae874b133a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80e80775728442b8994ce9631889a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75f5c5c326b74257a0dba400db16d2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91770e3bf57447caa7fd541b304323a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "838cc746b0064921b25aeebdb340d414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e5a4b3f82340e5919467732c17e5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc264805bd184d44b6d83cca50605b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b64451321cc043c0a08ca904356af8ea",
              "IPY_MODEL_011ef13d84c64253a5f14f054e01a3f3",
              "IPY_MODEL_5e13f77467c941e5823e0c97468c64fe"
            ],
            "layout": "IPY_MODEL_56fc76ae118544be987830943c21522e"
          }
        },
        "b64451321cc043c0a08ca904356af8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2407d56dff461eb24383b8bd60f6a8",
            "placeholder": "​",
            "style": "IPY_MODEL_1a08ae6e67294556afdb6731e2aad386",
            "value": "generation_config.json: 100%"
          }
        },
        "011ef13d84c64253a5f14f054e01a3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ba058b6bf341d1b932b2fc0cf1590d",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1ba43677dc0487bb226702ab087fd44",
            "value": 188
          }
        },
        "5e13f77467c941e5823e0c97468c64fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69093ae65df41439c38835253b660e9",
            "placeholder": "​",
            "style": "IPY_MODEL_c03e9fb6df0c482982d5c19eca900202",
            "value": " 188/188 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "56fc76ae118544be987830943c21522e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2407d56dff461eb24383b8bd60f6a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a08ae6e67294556afdb6731e2aad386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ba058b6bf341d1b932b2fc0cf1590d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1ba43677dc0487bb226702ab087fd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e69093ae65df41439c38835253b660e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03e9fb6df0c482982d5c19eca900202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb3cf0536b946b9ae9069c26251866a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bcf269a29f14a0aab72972d2e39efb9",
              "IPY_MODEL_d9c2693336bd4c96aa5a533c6107ead0",
              "IPY_MODEL_2d145f8940fa4a5d8e4a6e746fdc9e3c"
            ],
            "layout": "IPY_MODEL_5e9ab39d359547e08a23dbf612edd6f2"
          }
        },
        "8bcf269a29f14a0aab72972d2e39efb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8faffc25c74e437eb2fbcf4eecf3e202",
            "placeholder": "​",
            "style": "IPY_MODEL_c1239ec1a5d34bdd80a8392d5e822887",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d9c2693336bd4c96aa5a533c6107ead0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8fb63f85d0743dfbd8d206c1eefc3de",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9edef587fc83493cb3b4ff8cc3715589",
            "value": 1618
          }
        },
        "2d145f8940fa4a5d8e4a6e746fdc9e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd29a0c5e50f49f0a9af7842ecfc99d3",
            "placeholder": "​",
            "style": "IPY_MODEL_40dbb38837ca48409e302b98a21adbed",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 121kB/s]"
          }
        },
        "5e9ab39d359547e08a23dbf612edd6f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8faffc25c74e437eb2fbcf4eecf3e202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1239ec1a5d34bdd80a8392d5e822887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8fb63f85d0743dfbd8d206c1eefc3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edef587fc83493cb3b4ff8cc3715589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd29a0c5e50f49f0a9af7842ecfc99d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40dbb38837ca48409e302b98a21adbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "473d91e2b1234f9e87c46fbe3c3db270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cde33220f2f14c65a7babd3840a147c3",
              "IPY_MODEL_3400c8369ca0496c8ab5e9b121385a68",
              "IPY_MODEL_662aee1623a54bbf9c0778ffeda2008b"
            ],
            "layout": "IPY_MODEL_5bce407005024a81a1f4ff823db5bcb3"
          }
        },
        "cde33220f2f14c65a7babd3840a147c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97331c2939994c4cb1091eb2ce53f5bb",
            "placeholder": "​",
            "style": "IPY_MODEL_ebc64804dffb4db69075560eb1729931",
            "value": "tokenizer.model: 100%"
          }
        },
        "3400c8369ca0496c8ab5e9b121385a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca39c45494f74a5e9bf17380f05a417c",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01dc87e2652f4cb5b9cbdad6f98f6296",
            "value": 499723
          }
        },
        "662aee1623a54bbf9c0778ffeda2008b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d25247ff5f4fc8a188616d2a8a854a",
            "placeholder": "​",
            "style": "IPY_MODEL_d236c189f4c4426b994a4b6fd61d2db1",
            "value": " 500k/500k [00:00&lt;00:00, 28.9MB/s]"
          }
        },
        "5bce407005024a81a1f4ff823db5bcb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97331c2939994c4cb1091eb2ce53f5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc64804dffb4db69075560eb1729931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca39c45494f74a5e9bf17380f05a417c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01dc87e2652f4cb5b9cbdad6f98f6296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3d25247ff5f4fc8a188616d2a8a854a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d236c189f4c4426b994a4b6fd61d2db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68a1e5e37a5a4a529d392f1154c0592b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac556c3bd81541f5a13cfddfbcc9410a",
              "IPY_MODEL_0156e97593ac46d185d81abe01b36cd1",
              "IPY_MODEL_7500a9d7bc134b0bbd4fd5f7a1c58ed3"
            ],
            "layout": "IPY_MODEL_2a8b4f26983848aa988b5265fe355c90"
          }
        },
        "ac556c3bd81541f5a13cfddfbcc9410a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dcf2a021b3c4f62a511091b5bfefbe5",
            "placeholder": "​",
            "style": "IPY_MODEL_0de93ada5793427e8d110a3ab1517df5",
            "value": "tokenizer.json: 100%"
          }
        },
        "0156e97593ac46d185d81abe01b36cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2feaab339959477086545764f6c50029",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a18093074801491ea0de4a1f5e031229",
            "value": 1842767
          }
        },
        "7500a9d7bc134b0bbd4fd5f7a1c58ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53e4320061e4eec811dbb34bafba1e0",
            "placeholder": "​",
            "style": "IPY_MODEL_489e8102e5ef42cfad52da289cae6a7d",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.60MB/s]"
          }
        },
        "2a8b4f26983848aa988b5265fe355c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcf2a021b3c4f62a511091b5bfefbe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de93ada5793427e8d110a3ab1517df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2feaab339959477086545764f6c50029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a18093074801491ea0de4a1f5e031229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a53e4320061e4eec811dbb34bafba1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489e8102e5ef42cfad52da289cae6a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0517e0e8491448782b74498f3f740f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba0720b62e1746c18434aa6c91ddc917",
              "IPY_MODEL_67d820fe04be4a33819ea67f9b84d561",
              "IPY_MODEL_0e7b0d398f324aa2adf7f558ca92ac08"
            ],
            "layout": "IPY_MODEL_4461e5191be147d3b761a6524a4899f1"
          }
        },
        "ba0720b62e1746c18434aa6c91ddc917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c356a6d3f3f946a9901c54c368945883",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ba72ae68b749f487b720c1c0677cad",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "67d820fe04be4a33819ea67f9b84d561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef9781f1afe4f53bd818d896517c761",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e1f219ec6b4498ab26b57620ef92d3f",
            "value": 414
          }
        },
        "0e7b0d398f324aa2adf7f558ca92ac08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b507fdfe55f145688ba15232cc571ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_7b730ae995514265b97fc65c42d02bdb",
            "value": " 414/414 [00:00&lt;00:00, 29.6kB/s]"
          }
        },
        "4461e5191be147d3b761a6524a4899f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c356a6d3f3f946a9901c54c368945883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ba72ae68b749f487b720c1c0677cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ef9781f1afe4f53bd818d896517c761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1f219ec6b4498ab26b57620ef92d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b507fdfe55f145688ba15232cc571ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b730ae995514265b97fc65c42d02bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b98eea0cf2c542a59b1c187f4c5041f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a54c5ab29a24f40a9a26e565759ea8e",
              "IPY_MODEL_71ffd8bbde7a427c9fd3d5f266ded642",
              "IPY_MODEL_b188bad312b8420ba13ac91c46fa4c05"
            ],
            "layout": "IPY_MODEL_d461363340874f43be9e477640f3c567"
          }
        },
        "4a54c5ab29a24f40a9a26e565759ea8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f1080a60bb45328afd2d2cc9ce2d1f",
            "placeholder": "​",
            "style": "IPY_MODEL_002cd73445f94b21b8ba329b8abb3abd",
            "value": "modules.json: 100%"
          }
        },
        "71ffd8bbde7a427c9fd3d5f266ded642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3adcae7b3ec442a1a6bb13c6b297c044",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54958dbe2d7b4bcfb4b351647f151eb7",
            "value": 349
          }
        },
        "b188bad312b8420ba13ac91c46fa4c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3463782eea9246af8d70420ef74d43a5",
            "placeholder": "​",
            "style": "IPY_MODEL_9934de929ddd4ab09ef87a2001036df4",
            "value": " 349/349 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "d461363340874f43be9e477640f3c567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f1080a60bb45328afd2d2cc9ce2d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002cd73445f94b21b8ba329b8abb3abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3adcae7b3ec442a1a6bb13c6b297c044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54958dbe2d7b4bcfb4b351647f151eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3463782eea9246af8d70420ef74d43a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9934de929ddd4ab09ef87a2001036df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0fb7c9cdaa8414a9cba2cbaa8ca0f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee08dfadef6741c18f94e4b65bb43da9",
              "IPY_MODEL_1844effe67214f07a93ac3e4dd5f6c1c",
              "IPY_MODEL_26826c7fa62a421d97c214c29b21eba6"
            ],
            "layout": "IPY_MODEL_b099974b652341548bc818ac95eb310a"
          }
        },
        "ee08dfadef6741c18f94e4b65bb43da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a981964f304bb5b5a497848ac07e03",
            "placeholder": "​",
            "style": "IPY_MODEL_4295cf9e843a4567afda2339c2b2b71a",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "1844effe67214f07a93ac3e4dd5f6c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d63b93dfc24e06af471841b7a8e76c",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfbea7e2769e4555b366a59e5f24cd6c",
            "value": 116
          }
        },
        "26826c7fa62a421d97c214c29b21eba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54eda63145814ac3ab0d9a8ddd63f865",
            "placeholder": "​",
            "style": "IPY_MODEL_98c0d71d88be4500bbeacfe6bd99ecf3",
            "value": " 116/116 [00:00&lt;00:00, 6.44kB/s]"
          }
        },
        "b099974b652341548bc818ac95eb310a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a981964f304bb5b5a497848ac07e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4295cf9e843a4567afda2339c2b2b71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d63b93dfc24e06af471841b7a8e76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbea7e2769e4555b366a59e5f24cd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54eda63145814ac3ab0d9a8ddd63f865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c0d71d88be4500bbeacfe6bd99ecf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e05fbc514b4b1ebcfe96e33240a66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8a574d7eb1a4c4881e1a48574b434a1",
              "IPY_MODEL_126d11b4ba9e4548844d1cb91ad0ff93",
              "IPY_MODEL_7857bdd5c8ca4feebe84c739a495d122"
            ],
            "layout": "IPY_MODEL_7316e97e03934f6ea9767cee840718ac"
          }
        },
        "f8a574d7eb1a4c4881e1a48574b434a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f98430c1f70401e9e5f08d490c302c5",
            "placeholder": "​",
            "style": "IPY_MODEL_6e3026ae17fc48f794cc67dba56da001",
            "value": "README.md: 100%"
          }
        },
        "126d11b4ba9e4548844d1cb91ad0ff93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9ff6484a724cc586015a7a0d4135c0",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0dc626d50cd4944b4f2d7c884476bf1",
            "value": 10621
          }
        },
        "7857bdd5c8ca4feebe84c739a495d122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82a2122f52a449d09486e02c833854da",
            "placeholder": "​",
            "style": "IPY_MODEL_899203a5b788489c87d2243b1458b1f8",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 752kB/s]"
          }
        },
        "7316e97e03934f6ea9767cee840718ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f98430c1f70401e9e5f08d490c302c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3026ae17fc48f794cc67dba56da001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9ff6484a724cc586015a7a0d4135c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dc626d50cd4944b4f2d7c884476bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82a2122f52a449d09486e02c833854da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899203a5b788489c87d2243b1458b1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1edc575f3663455c9bfef3b5ef254faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fed77a82631c491ea690c9f4d27c2f7e",
              "IPY_MODEL_99cbd83a7a564a569ead6959e11909fc",
              "IPY_MODEL_462f9f2ba4894d55b74a3606d3ae0a05"
            ],
            "layout": "IPY_MODEL_f5d397e0c2e64e2ba3b5f7d7e97f6a85"
          }
        },
        "fed77a82631c491ea690c9f4d27c2f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d641dd33dbc4e8786152ef687899065",
            "placeholder": "​",
            "style": "IPY_MODEL_e77821263ab0444b8e5322d56a2fac6f",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "99cbd83a7a564a569ead6959e11909fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d66356d02146e49af7e03c6df9f2d2",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1a69a1ddcd940788f79b5c739ab6ae4",
            "value": 53
          }
        },
        "462f9f2ba4894d55b74a3606d3ae0a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e3615d98aec4f3597e565fd681f6377",
            "placeholder": "​",
            "style": "IPY_MODEL_5f0e314e6a9144a8af37fed2ea495f0e",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.19kB/s]"
          }
        },
        "f5d397e0c2e64e2ba3b5f7d7e97f6a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d641dd33dbc4e8786152ef687899065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e77821263ab0444b8e5322d56a2fac6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d66356d02146e49af7e03c6df9f2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a69a1ddcd940788f79b5c739ab6ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e3615d98aec4f3597e565fd681f6377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f0e314e6a9144a8af37fed2ea495f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dda890948e24f0db140614534c10ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28932d4c375c4602aee7d42747b7b833",
              "IPY_MODEL_977503abbf414726ae12368076ace3b4",
              "IPY_MODEL_a10976b614ee4d8b835604b92bb11b84"
            ],
            "layout": "IPY_MODEL_8b9719d32b314690b649e5d420afa0f3"
          }
        },
        "28932d4c375c4602aee7d42747b7b833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2907163ad1834bf398d13b77d0282e13",
            "placeholder": "​",
            "style": "IPY_MODEL_59880240cb98433da2bdb89901cecaec",
            "value": "config.json: 100%"
          }
        },
        "977503abbf414726ae12368076ace3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_282d59d7fab548e3b53123ca29cb89fb",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed2cfc4575c44e49b27202120b0d473b",
            "value": 571
          }
        },
        "a10976b614ee4d8b835604b92bb11b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e003c1a6ed7d4576867b78b8092f18f0",
            "placeholder": "​",
            "style": "IPY_MODEL_7aaf66678a434c0795eac61b5594d977",
            "value": " 571/571 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "8b9719d32b314690b649e5d420afa0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2907163ad1834bf398d13b77d0282e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59880240cb98433da2bdb89901cecaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "282d59d7fab548e3b53123ca29cb89fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2cfc4575c44e49b27202120b0d473b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e003c1a6ed7d4576867b78b8092f18f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aaf66678a434c0795eac61b5594d977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54b355ebfdd541a39ca1390280037af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22f1e313d06c4dbfb17da513f8efcbc4",
              "IPY_MODEL_03a71e4168c147bba406f283db0526fe",
              "IPY_MODEL_4cf1202b3cf7427dbadf3b3cb3dbd99f"
            ],
            "layout": "IPY_MODEL_4df90ad7fbc54ba7a9b384bb5cd44a21"
          }
        },
        "22f1e313d06c4dbfb17da513f8efcbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_308ea81aa0d44d16949e636abf0574ad",
            "placeholder": "​",
            "style": "IPY_MODEL_21812bec821b4a19a543c7dc8d284fe5",
            "value": "model.safetensors: 100%"
          }
        },
        "03a71e4168c147bba406f283db0526fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ebe9c92cedc452a9062d0c253cf091a",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c636c3d00a904d74bd5f8c86e50e46a1",
            "value": 437971872
          }
        },
        "4cf1202b3cf7427dbadf3b3cb3dbd99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f741cc550546bc842380b46b3e18e8",
            "placeholder": "​",
            "style": "IPY_MODEL_0e8090350f8b44dcad1d9d5e9c87d4a7",
            "value": " 438M/438M [00:02&lt;00:00, 186MB/s]"
          }
        },
        "4df90ad7fbc54ba7a9b384bb5cd44a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308ea81aa0d44d16949e636abf0574ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21812bec821b4a19a543c7dc8d284fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ebe9c92cedc452a9062d0c253cf091a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c636c3d00a904d74bd5f8c86e50e46a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30f741cc550546bc842380b46b3e18e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8090350f8b44dcad1d9d5e9c87d4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aab078ef5b54d28868ff16fad125b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec546008f78844c58eb226937cdb1dec",
              "IPY_MODEL_05e84fd9f41646c794ad714061596959",
              "IPY_MODEL_c3af828f7d8148a8bfd46c995ead6dd2"
            ],
            "layout": "IPY_MODEL_d3c9692b3287493e88dccbec7ae96b64"
          }
        },
        "ec546008f78844c58eb226937cdb1dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b981fddd3b0548f7a0c6337ab168a676",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc81de916734be499e15df0735930b6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "05e84fd9f41646c794ad714061596959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a95868eb19949f78be9ebe96de6963c",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a78ce82e1034d2d90dce5ec8394f8a3",
            "value": 363
          }
        },
        "c3af828f7d8148a8bfd46c995ead6dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f945bac56d441ee8e0831b0b1d20081",
            "placeholder": "​",
            "style": "IPY_MODEL_7d8c672dcf4d4a3fabe23e169b8c1ca1",
            "value": " 363/363 [00:00&lt;00:00, 5.37kB/s]"
          }
        },
        "d3c9692b3287493e88dccbec7ae96b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b981fddd3b0548f7a0c6337ab168a676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc81de916734be499e15df0735930b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a95868eb19949f78be9ebe96de6963c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a78ce82e1034d2d90dce5ec8394f8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f945bac56d441ee8e0831b0b1d20081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8c672dcf4d4a3fabe23e169b8c1ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34a9a48cf8af420bbbce2f71340bcb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3973e59e30e48cbb1967cea457952ed",
              "IPY_MODEL_2abea1e1681d45d595beabab96dc5423",
              "IPY_MODEL_ffd887618b714bec81535fb0dbeca5a3"
            ],
            "layout": "IPY_MODEL_56915cb8f1ac407891d321f6a9bce34d"
          }
        },
        "f3973e59e30e48cbb1967cea457952ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d33adc09373a4171a009fb7b2339bb45",
            "placeholder": "​",
            "style": "IPY_MODEL_2cbc5c822af64f95aa21717ea183f675",
            "value": "vocab.txt: 100%"
          }
        },
        "2abea1e1681d45d595beabab96dc5423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15224f2a863c4b15b0b7e2c653a18fd0",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf45a3bd20534964951caa271247c6ce",
            "value": 231536
          }
        },
        "ffd887618b714bec81535fb0dbeca5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7afa57c1872d433fb3ad34f2e65561e0",
            "placeholder": "​",
            "style": "IPY_MODEL_8d92a351f8d84302beec08fb181dbca3",
            "value": " 232k/232k [00:00&lt;00:00, 6.56MB/s]"
          }
        },
        "56915cb8f1ac407891d321f6a9bce34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33adc09373a4171a009fb7b2339bb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbc5c822af64f95aa21717ea183f675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15224f2a863c4b15b0b7e2c653a18fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf45a3bd20534964951caa271247c6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7afa57c1872d433fb3ad34f2e65561e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d92a351f8d84302beec08fb181dbca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ef6afea27f34f89a47c324f095b850f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45996221c909415f808c8f94dc4d8bd1",
              "IPY_MODEL_6a489848fcc54c2885498c58c6fbd85e",
              "IPY_MODEL_a18e1dca7afc4b37837886b51c07a892"
            ],
            "layout": "IPY_MODEL_9e56a7bf53574a18b505f34cd204a137"
          }
        },
        "45996221c909415f808c8f94dc4d8bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b888a8bf7944f608d106232b7a5574b",
            "placeholder": "​",
            "style": "IPY_MODEL_55bc5f84c23a41ed813f86943c1fece7",
            "value": "tokenizer.json: 100%"
          }
        },
        "6a489848fcc54c2885498c58c6fbd85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0e730f01134f1986d0fdf8a17aa8e8",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a19594c0ca0c4bd996f783797abb12aa",
            "value": 466021
          }
        },
        "a18e1dca7afc4b37837886b51c07a892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696050ecde6847f6bda164f3ca3d0942",
            "placeholder": "​",
            "style": "IPY_MODEL_7bdfa030ded24a9c8923df81e27f61b8",
            "value": " 466k/466k [00:00&lt;00:00, 18.3MB/s]"
          }
        },
        "9e56a7bf53574a18b505f34cd204a137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b888a8bf7944f608d106232b7a5574b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55bc5f84c23a41ed813f86943c1fece7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0e730f01134f1986d0fdf8a17aa8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19594c0ca0c4bd996f783797abb12aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "696050ecde6847f6bda164f3ca3d0942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bdfa030ded24a9c8923df81e27f61b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41325a4a0b25429386b567df321f6c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_763412f5485d4dffa438baef6a6007a6",
              "IPY_MODEL_0b58597a59c6439f84a3cf89e2f7f744",
              "IPY_MODEL_48f5ebb133fd46f1948e5cf35d00a98f"
            ],
            "layout": "IPY_MODEL_d4041c53b8ff47148133a1602556f505"
          }
        },
        "763412f5485d4dffa438baef6a6007a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5397bbc12644ecba3ee31d372e8a6bd",
            "placeholder": "​",
            "style": "IPY_MODEL_ef71ba2c2a904b1db276644c5cb56c2c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0b58597a59c6439f84a3cf89e2f7f744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4cc542cc1441d2bc070e7f0fd975af",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_219c82d1e4974130ac60e20bd2863dd3",
            "value": 239
          }
        },
        "48f5ebb133fd46f1948e5cf35d00a98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e4b076ea194479b244bf171fb383a7",
            "placeholder": "​",
            "style": "IPY_MODEL_676663fa11a24f5c8a4b74139e04a306",
            "value": " 239/239 [00:00&lt;00:00, 3.19kB/s]"
          }
        },
        "d4041c53b8ff47148133a1602556f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5397bbc12644ecba3ee31d372e8a6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef71ba2c2a904b1db276644c5cb56c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4cc542cc1441d2bc070e7f0fd975af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219c82d1e4974130ac60e20bd2863dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3e4b076ea194479b244bf171fb383a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676663fa11a24f5c8a4b74139e04a306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28453b789e194689bbe68309e358a3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a9d581b30f34bc0a3571535a5e1cb48",
              "IPY_MODEL_cff4fb7672f241d4bdd20e59099b5a64",
              "IPY_MODEL_0b152220d68c4ef38cc18ea6f90d6898"
            ],
            "layout": "IPY_MODEL_9a68bf0ae9924142815d6446a3675692"
          }
        },
        "1a9d581b30f34bc0a3571535a5e1cb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856186cebe6b438d8b28409f102f94b6",
            "placeholder": "​",
            "style": "IPY_MODEL_e02097a1bfa34621825e2f2cbf3ad51c",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "cff4fb7672f241d4bdd20e59099b5a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f839790bfdc453f8d5ddf9fe0cf1cef",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6b0ae35fec14b09bbf3474c94999870",
            "value": 190
          }
        },
        "0b152220d68c4ef38cc18ea6f90d6898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd6902e0e0947c784c0b30ad2ab465b",
            "placeholder": "​",
            "style": "IPY_MODEL_2e495801928348f0887a5a7de399af50",
            "value": " 190/190 [00:00&lt;00:00, 3.67kB/s]"
          }
        },
        "9a68bf0ae9924142815d6446a3675692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856186cebe6b438d8b28409f102f94b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02097a1bfa34621825e2f2cbf3ad51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f839790bfdc453f8d5ddf9fe0cf1cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b0ae35fec14b09bbf3474c94999870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbd6902e0e0947c784c0b30ad2ab465b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e495801928348f0887a5a7de399af50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53db95818f7242b3b91a7e78d71da946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fb2b1a00db74a00b7386256ead382e7",
              "IPY_MODEL_c594fe3b029a457293c9c6fe13492cbf",
              "IPY_MODEL_491b9ea12f9a4291bf6b266fcbc921d0"
            ],
            "layout": "IPY_MODEL_0caa7a0892d84c8faa13a719c3c742d8"
          }
        },
        "0fb2b1a00db74a00b7386256ead382e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b763cbf9c26f487881f044f9d720afe7",
            "placeholder": "​",
            "style": "IPY_MODEL_3c5afecfe56744aa87080e49fa5d3b60",
            "value": "Parsing nodes: 100%"
          }
        },
        "c594fe3b029a457293c9c6fe13492cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f9310948d54e4281b045f672e0c10c",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ac68aca9c0a47eb846bdc0afcfaff05",
            "value": 15
          }
        },
        "491b9ea12f9a4291bf6b266fcbc921d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3507f8a17fa412fb9abf0714a2a9054",
            "placeholder": "​",
            "style": "IPY_MODEL_1364e0268bb54e39b3b4b249f57c926c",
            "value": " 15/15 [00:00&lt;00:00, 44.50it/s]"
          }
        },
        "0caa7a0892d84c8faa13a719c3c742d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b763cbf9c26f487881f044f9d720afe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c5afecfe56744aa87080e49fa5d3b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f9310948d54e4281b045f672e0c10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac68aca9c0a47eb846bdc0afcfaff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3507f8a17fa412fb9abf0714a2a9054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1364e0268bb54e39b3b4b249f57c926c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c33dda735c2485db7b0dbddfd89edf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a212b97fa7a419a9ef591a5eef00590",
              "IPY_MODEL_2643656e381a4e8e9a26e21c2230cf60",
              "IPY_MODEL_09f1e063ba4f471380ff2bec92306304"
            ],
            "layout": "IPY_MODEL_4ae39489747b44aab1dba2f03c4af84f"
          }
        },
        "8a212b97fa7a419a9ef591a5eef00590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cb97c6ccad748b285ff7c3a88704915",
            "placeholder": "​",
            "style": "IPY_MODEL_26d75c5b41454bcb946bb515f12892dc",
            "value": "Generating embeddings: 100%"
          }
        },
        "2643656e381a4e8e9a26e21c2230cf60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3edc3f151f2c45e289ba079496704977",
            "max": 107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89f26a20394141dab79dc566ee69cc23",
            "value": 107
          }
        },
        "09f1e063ba4f471380ff2bec92306304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c0aa869f63847b3a7371842dedb6089",
            "placeholder": "​",
            "style": "IPY_MODEL_c1fdf6947c9f48b28c07c1dc99aa01c4",
            "value": " 107/107 [00:04&lt;00:00, 30.86it/s]"
          }
        },
        "4ae39489747b44aab1dba2f03c4af84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb97c6ccad748b285ff7c3a88704915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d75c5b41454bcb946bb515f12892dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3edc3f151f2c45e289ba079496704977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f26a20394141dab79dc566ee69cc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c0aa869f63847b3a7371842dedb6089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fdf6947c9f48b28c07c1dc99aa01c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}